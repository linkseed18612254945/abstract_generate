machine translation	a computer natural language translation system inputs source language text and outputs target language text. the target language text is generated from the source language text using stored translation data generated from examples of source and corresponding target language texts. the stored translation data includes a plurality of translation components, each having surface data representative of the order of occurrence of language units in the component; dependency data related to the semantic relationship between language units in the component; and link data linking dependency data of language components of the source language with corresponding dependency data of language components of the target language. the surface data of the source language is used in analyzing the source language text, and the surface date of the target language is used in generating the target language text. the dependency data and link data is used in transforming the analysis of the source text into an analysis for the target language.	-4	71
bleu: a method for automatic evaluation of machine translation	human evaluations of machine translation are extensive but expensive. human evaluations can take months to finish and involve human labor that can not be reused. we propose a method of automatic machine translation evaluation that is quick, inexpensive, and languageindependent, that correlates highly with human evaluation, and that has little marginal cost per run. we present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.	-11	6773
ibm research report bleu: a method for automatic evaluation of machine translation	human evaluations of machine translation are extensive but expensive. human evaluations can take months to finish and involve human labor that can not be reused.	-11	5442
minimum error rate training in statistical machine translation	often, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria. a general problem of this approach is that there is only a loose relation to the final translation quality on unseen text. in this paper, we analyze various training criteria which directly optimize translation quality.	-10	2574
europarl: a parallel corpus for statistical machine translation	we collected a corpus of parallel text in 11 languages from the proceedings of the european parliament, which are published on the web 1 . this corpus has found widespread use in the nlp community. here, we focus on its acquisition and its application as training data for statistical machine translation (smt). we trained smt systems for 110 language pairs, which reveal interesting clues into the challenges ahead.	-8	2203
a parallel corpus for statistical machine translation	in this lecture we continue the study of machine translation in more details. in the previous lectrue, the translation model 3 was introduced. we will explain four other translation models and compare them with model 3. we also describe a computationally cheap learning algorithm for these models, given a set of bilingual texts. at the end, a hmmbased alignment model will be discussed briefly. 8.2 quick review as usual, we consider translation from source language f to the target language e, let’s say french to english. using base rule, we can rewrite p(e|f) as p(e)p(f|e). brown et al. [1] introduced wordbyword alignment between pairs of sentences f and e. one can think of alignment in different ways. we focus on manytoone alignment from f to e and vector a is used to represent this alignment. we assume e has length l and f has length m, so the size of a is also m. aj = i means that fj; the jth word of f is associated with ei; the ith word of e. to learn from pairs of translated sentences we should have some idea about the alignment of french and english words. we can consider all possible alignments and assign appropriate probabilities to them to accordingly compute other parameters of the model.	-8	2120
a statistical approach to machine translation	this chapter contains sections titled introduction, the language model, the translation model, searching, parameter estimation, two pilot experiments, plans, references	-23	2041
object recognition as machine translation: learning a lexicon for a fixed image vocabulary	we describe a model of object recognition as machine translation. in this model, recognition is a process of annotating image regions with words. firstly, images are segmented into regions, which are classified into region types using a variety of features. a mapping between region types and keywords supplied with the images, is then learned, using a method based around em. this process is analogous with learning a lexicon from an aligned bitext. for the implementation we describe, these words are nouns taken from a large vocabulary. on a large test set, the method can predict numerous words with high accuracy. simple methods identify words that cannot be predicted well. we show how to cluster words that individually are difficult to predict into clusters that can be predicted well 鈥 for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. the method is trained on a substantial collection of images. extensive experimental results illustrate the strengths and weaknesses of the approach.	-11	2184
automatic evaluation of machine translation quality using n-gram co-occurrence statistics	evaluation is recognized as an extremely helpful forcing function in human language technology r&d. unfortunately, evaluation has not been a very powerful tool in machine translation (mt) research because it requires human judgments and is thus expensive and timeconsuming and not easily factored into the mt research agenda. however, at the july 2001 tides pi meeting in philadelphia, ibm described an automatic mt evaluation technique that can provide immediate feedback and guidance in mt research. their idea, which they call an evaluation understudy, compares mt output with expert reference translations in terms of the statistics of short sequences of words (word ngrams). the more of these ngrams that a translation shares with the reference translations, the better the translation is judged to be. the idea is elegant in its simplicity. but far more important, ibm showed a strong correlation between these automatically generated scores and human judgments of translation quality. as a result, darpa commissioned nist to develop an mt evaluation facility based on the ibm work. this utility is now available from nist and serves as the primary evaluation measure for tides mt research.	-11	1410
a hierarchical phrase-based model for statistical machine translation.	we present a statistical phrasebased transla tion model that uses hierarchical phrases— phrases that contain subphrases. the model is formally a synchronous contextfree gram mar but is learned from a bitext without any syntactic information. thus it can be seen as a shift to the formal machinery of syntax based translation systems without any lin guistic commitment. in our experiments us ing bleu as a metric, the hierarchical phrase based model achieves a relative improve ment of 7.5% over pharaoh, a stateoftheart phrasebased system.	-8	1394
automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics	in this paper we describe two new objective automatic evaluation methods for machine translation. the first method is based on longest common subsequence between a candidate translation and a set of reference translations. longest common subsequence takes into account sentence level structure similarity naturally and identifies longest cooccurring insequence ngrams automatically. the second method relaxes strict ngram matching to skipbigram matching. skipbigram is any pair of words in their sentence order. skipbigram cooccurrence statistics measure the overlap of skipbigrams between a candidate translation and a set of reference translations. the empirical results show that both methods correlate with human judgments very well in both adequacy and fluency.	-9	1421
discriminative training and maximum entropy models for statistical machine translation	we present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source channel approach as a special case. all knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables.	-11	1402
machine translation and translation theory /	ve interpreting. it consists in the mapping of a text onto a cognitive macrostructural scene that specifies the communicative intentions and strategies of the speaker. knowing the latter is of considerable help in human interpreting, and is therefore likely to be useful for machine interpreting as well. unfortunately, since speakers seldom make their intentions explicit, the macrostructural scenes have to be provided manually to the translation system, presumably in a training or preediting phase, and on the specifics of this training phase the author is very brief if i have understood the literature correctly, a connectionist, selfadaptive system will be most suitable for the necessary training, or at least a hybrid model (p. 33). equally brief are the comments on the feasibility of this enterprise, but with the insistence on the importance of macrostructural properties of texts the author strikes a chord that reverberates throughout the entire volume. monika doherty's textual g	-16	1315
statistical significance tests for machine translation evaluation	if two translation systems differ differ in performance on a test set, can we trust that this indicates a difference in true system quality? to answer this question, we describe bootstrap resampling methods to compute statis.	-9	934
findings of the 2009 workshop on statistical machine translation	this paper presents the results of the wmt09 shared tasks, which included a translation task, a system combination task, and an evaluation task. we conducted a largescale manual evaluation of 87 machine translation systems and 22 system combination entries. we used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality, for more than 20 metrics. we present a new evaluation technique whereby system output is edited and judged for correctness.	-4	770
automatic evaluation of machine translation quality using n-gram co-occurrence statistics	evaluation plays a crucial role in development of machine translation systems. in order to judge the quality of an existing mt system i.e. if the translated output is of human translation quality or not, various automatic metrics exist. we here present the implementation results of different metrics when used on hindi language along with their comparisons, illustrating how effective are these...  /reacttext  reacttext 445   /reacttext [show full ]	-11	1310
the alignment template approach to statistical machine translation	a phrasebased statistical machine translation approach 鈥 the alignment template approach 鈥 is described. this translation approach allows for general manytomany relations between words. thereby, the context of words is taken into account in the translation model, and local changes in word order from source to target language can be learned explicitly. the model is described using a loglinear modeling approach, which is a generalization of the often used sourcechannel approach. thereby, the model is easier to extend than classical statistical machine translation systems. we describe in detail the process for learning phrasal translations, the feature functions used, and the search algorithm. the evaluation of this approach is performed on three different tasks. for the germanenglish speech verbmobil task, we analyze the effect of various sys tem components. on the frenchenglish canadian hansards task, the alignment template system obtains significantly better results than a singlewordbased translation model. in the chineseenglish 2002 national institute of standards and technology (nist) machine transla tion evaluation it yields statistically significantly better nist scores than all competing research and commercial translation systems.	-9	1071
a comparative study on reordering constraints in statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary wordreorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible wordreorderings in an appropriate way, we obtain a polynomialtime search algorithm.	-10	965
findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation	this paper presents the results of the wmt10 and metricsmatr10 shared tasks, which included a translation task, a system combination task, and an evaluation task. we conducted a largescale manual evaluation of 104 machine translation.	-3	713
further meta-evaluation of machine translation	this paper analyzes the translation quality of machine translation systems for 10 language pairs translating between czech, english, french, german, hungarian, and spanish. we report the translation quality of over 30 diverse translation systems based on a largescale manual evaluation involv ing hundreds of hours of effort. we use the human judgments of the systems to analyze automatic evaluation metrics for translation quality, and we report the strength of the cor relation with human judgments at both the systemlevel and at the sentencelevel. we validate our manual evaluation methodol ogy by measuring intra and interannotator agreement, and collecting timing information.	-5	436
clause restructuring for statistical machine translation	we describe a method for incorporating syntactic information in statistical machine translation systems. the first step of the method is to parse the source language string that is being translated. the second step is to apply a series of transformations to the parse tree, effectively reordering the surface string on the source language side of the translation system. the goal of this step is to recover an underlying word order that is closer to the target language wordorder than the original string. the reordering approach is applied as a preprocessing step in both the training and decoding phases of a phrasebased statistical mt system. we describe experiments on translation from german to english, showing an improvement from 25.2 % bleu score for a baseline system to 26.8 % bleu score for the system with reordering, a statistically significant improvement.	-8	545
improved alignment models for statistical machine translation	in this paper, we describe improved alignment models for statistical machine translation. the statistical translation approach uses two types of information a translation model and a language model. the language model used is a bigram or general mgram model. the translation model is decomposed into a lexical and an alignment model. we describe two different approaches for statistical translation and present experimental results. the first approach is based on dependencies between single words, the second approach explicitly takes shallow phrase structures into account, using two different alignment levels a phrase level alignment between phrases and a word level alignment between single words. we present results using the verbmobil task (germanenglish, 6000word vocabulary) which is a limiteddomain spokenlanguage task. the experimental tests were performed on both the text transcription and the speech recognizer output. 1 statistical machine translation the goal of machine trans...	-14	683
exploiting similarities among languages for machine translation	dictionaries and phrase tables are the basis of modern statistical machine translation systems. this paper develops a method that can automate the process of generating and extending dictionaries and phrase tables. our method can translate missing word and phrase entries by learning language structures based on large monolingual data and mapping between languages from small bilingual data. it uses distributed representation of words and learns a linear mapping between vector spaces of languages. despite its simplicity, our method is surprisingly effective we can achieve almost 90% precision@5 for translation of words between english and spanish. this method makes little assumption about the languages, so it can be used to extend and refine dictionaries and translation tables for any language pairs.	0	316
findings of the 2009 workshop on statistical machine translation	this paper presents the results of the wmt09 shared tasks, which included a translation task, a system combination task, and an evaluation task. we conducted a largescale manual evaluation of 87 machine translation systems and 22 system combination entries. we used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality, for more than 20 metrics. we present a new evaluation technique whereby system output is edited and judged for correctness.	-4	711
tree-to-string alignment template for statistical machine translation	we present a novel translation model based on treetostring alignment template (tat) which describes the alignment be tween a source parse tree and a target string. a tat is capable of generating both terminals and nonterminals and per forming reordering at both low and high levels. the model is linguistically syntax based because tats are extracted auto matically from wordaligned, source side parsed parallel texts. to translate a source sentence, we first employ a parser to pro duce a source parse tree and then ap ply tats to transform the tree into a tar get string. our experiments show that the tatbased model significantly outper forms pharaoh, a stateoftheart decoder for phrasebased models.	-7	506
a phrase-based, joint probability model for statistical machine translation	a machine translation (mt) system utilizes a phrasebased joint probability model. the model is used to generate source and target language sentences simultaneously. in an embodiment, the model learns phrasetophrase alignments from wordtoword alignments generated by a wordtoword statistical mt system. the system utilizes the joint probability model for both sourcetotarget and targettosource translation applications.	-11	552
pharaoh: a beam search decoder for phrase-based statistical machine translation models	we describe pharaoh, a freely available decoder for phrasebased statistical machine translation models. the decoder is the implement at ion of an efficient dynamic programming search algorithm with lattice generation and xml markup for external components.	-9	802
(meta-) evaluation of machine translation	this paper evaluates the translation quality of machine translation systems for 8 language pairs translating french, german, spanish, and czech to english and back. we carried out an extensive human evaluation which allowed us not only to rank the different mt systems, but also to perform higherlevel analysis of the evaluation process. we measured timing and intra and interannotator agreement for three types of subjective evaluation. we measured the correlation of automatic evaluation metrics with human judgments. this metaevaluation reveals surprising facts about the most commonly used methodologies.	-6	438
large language models in machine translation	this paper reports on the benefits of large scale statistical language modeling in ma chine translation. a distributed infrastruc ture is proposed which we use to train on up to 2 trillion tokens, resulting in language models having up to 300 billion ngrams. it is capable of providing smoothed probabil ities for fast, singlepass decoding. we in troduce a new smoothing method, dubbed	-6	391
building a large-scale knowledge base for machine translation	knowledgebased machine translation (kbmt) systems have achieved excellent results in constrained domains, but have not yet scaled up to newspaper text. the reason is that knowledge resources (lexicons, grammar rules, world models) must be painstakingly handcrafted from scratch. one of the hypotheses being tested in the pangloss machine translation project is whether or not these resources can be semiautomatically acquired on a very large scale. this paper focuses on the construction of a large ontology (or knowledge base, or world model) for supporting kbmt. it contains representations for some 70,000 commonly encountered objects, processes, qualities, and relations. the ontology was constructed by merging various online dictionaries, semantic networks, and bilingual resources, through semiautomatic methods. some of these methods (e.g., conceptual matching of semantic taxonomies) are broadly applicable to problems of importing/exporting knowledge from one kb to another. other methods (e.g., bilingual matching) allow a knowledge engineer to build up an index to a kb in a second language, such as spanish or japanese.	-19	538
findings of the 2013 workshop on statistical machine translation	this paper presents the results of the wmt13 shared tasks, which included a translation task, a task for runtime estimation of machine translation quality, and an unofficial metrics task. this year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. an additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. the quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries. 1	0	246
discriminative training and maximum entropy models for statistical machine translation	we present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source channel approach as a special case. all knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables.	-11	457
phrase-based statistical machine translation	this paper is based on the work carried out in the framework of the verbmobil project, which is a limiteddomain speech translation task (germanenglish).	-11	417
confidence estimation for machine translation	we present a detailed study of confidence estimation for machine translation. various methods for determining whether mt output is correct are investigated, for both whole sentences and words. since the notion of correctness is not intuitively clear in this context, different ways of defining it are proposed. we present results on data from the nist 2003 chinesetoenglish mt evaluation.	-4	308
improving machine translation performance by exploiting non-parallel corpora	we present a novel method for discovering parallel sentences in comparable, nonparallel corpora. we train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other. using this approach, we extract parallel data from large chinese, arabic, and english nonparallel newspaper corpora. we evaluate the quality of the extracted data by showing that it improves the performance of a stateoftheart statistical machine translation system. we also show that a goodquality mt system can be built from scratch by starting with a very small parallel corpus (100,000 words) and exploiting a large nonparallel corpus. thus, our method can be applied with great benefit to language pairs for which only scarce resources are available.	-8	390
improving statistical machine translation using word sense disambiguation	we show for the first time that incorporating the predictions of a word sense disambiguation system within a typical phrasebased statistical machine translation (smt) model consistently improves translation quality across all three different iwslt chineseenglish test sets, as well as producing statistically significant improvements on the larger nist chineseenglish mt task鈥 and moreover never hurts performance on any test set, according not only to bleu but to all eight most commonly used automatic evaluation metrics. recent work has challenged the assumption that word sense disambiguation (wsd) systems are useful for smt. yet smt translation quality still obviously suffers from inaccurate lexical choice. in this paper, we address this problem by investigating a new strategy for integrating wsd into an smt system, that performs fully phrasal multiword disambiguation. instead of directly incorporating a sensevalstyle wsd system, we redefine the wsd task to match the exact same phrasal translation disambiguation task faced by phrasebased smt systems. our results provide the first known empirical evidence that lexical semantics are indeed useful for smt, despite claims to the contrary.	-6	346
batch tuning strategies for statistical machine translation	there has been a proliferation of recent work on smt tuning algorithms capable of handling larger feature sets than the traditional mert approach. we analyze a number of these algorithms in terms of their sentencelevel loss functions, which motivates several new approaches, including a structured svm. we perform empirical comparisons of eight different tuning strategies, including mert, in a variety of settings. among other results, we find that a simple and efficient batch version of mira performs at least as well as training online, and consistently outperforms other options.	-1	224
minimum bayes-risk decoding for statistical machine translation	we present minimum bayesrisk (mbr) decoding for statistical machine translation. this statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance. we describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, wordtoword alignments from an mt system, and syntactic structure from parsetrees of source and target language sentences. we report the performance of the mbr decoders on a chinesetoenglish translation task. our results show that mbr decoding can be used to tune statistical mt performance for specific loss functions.	-9	386
lattice minimum bayes-risk decoding for statistical machine translation	we present minimum bayesrisk (mbr) de coding over translation lattices that compactly encode a huge number of translation hypothe ses. we describe conditions on the loss func tion that will enable efficient implementation of mbr decoders on lattices. we introduce an approximation to the bleu score (pap ineni et al., 2001) that satisfies these condi tions. the mbr decoding under this approx imate bleu is realized using weighted fi nite state automata. our experiments show that the lattice mbr decoder yields mod erate, consistent gains in translation perfor mance over nbest mbr decoding on arabic toenglish, chinesetoenglish and english tochinese translation tasks. we conduct a range of experiments to understand why lat tice mbr improves upon nbest mbr and study the impact of various parameters on mbr performance.	-5	312
maximum entropy based phrase reordering model for statistical machine translation	citeseerx  document details (isaac councill, lee giles, pradeep teregowda) we propose a novel reordering model for phrasebased statistical machine translation (smt) that uses a maximum entropy (maxent) model to predicate reorderings of neighbor blocks (phrase pairs). the model provides contentdependent, hierarchical phrasal reordering with generalization based on features automatically learned from a realworld bitext. we present an algorithm to extract all reordering events of neighbor blocks from bilingual data. in our experiments on chinesetoenglish translation, this maxentbased reordering model obtains significant improvements in bleu score on the nist mt05 and iwslt04 tasks. 1	-7	351
maximum entropy based phrase reordering model for statistical machine translation	we propose a novel reordering model for phrasebased statistical machine transla tion (smt) that uses a maximum entropy (maxent) model to predicate reorderings of neighbor blocks (phrase pairs). the model provides contentdependent, hier archical phrasal reordering with general ization based on features automatically learned from a realworld bitext. we present an algorithm to extract all reorder ing events of neighbor blocks from bilin gual data. in our experiments on chinese toenglish translation, this maxentbased reordering model obtains significant im provements in bleu score on the nist mt05 and iwslt04 tasks.	-7	347
the mathematics of machine translation: parameter estimation	we describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. we define a concept of wordbyword alignment between such pairs of sentences. for any given pair of such sentences each of our models assigns a probability to each of the possible wordbyword alignments. we give an algorithm for seeking the most probable of these alignments. although the algorithm is suboptimal, the alignment thus obtained accounts well for the wordbyword relationships in the pair of sentences. we have a great deal of data in french and english from the proceedings of the canadian parliament. accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. we also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that wordbyword alignments are inherent in any sufficiently large bilingual corpus.	-20	422
fast and optimal decoding for machine translation 	a good decoding algorithm is critical to the success of any statistical machine translation system. the decoder's job is to find the translation that is most likely according to a set of previously learned parameters (and a formula for combining them). since the space of possible translations is extremely large, typical decoding algorithms are only able to examine a portion of it, thus risking to miss good solutions. unfortunately, examining more of the space leads to unacceptably slow decodings. in this paper, we compare the speed and output quality of a traditional stackbased decoding algorithm with two new decoders a fast but nonoptimal greedy decoder and a slow but optimal decoder that treats decoding as an integerprogramming optimization problem.	-9	334
improving statistical machine translation using word sense disambiguation	citeseerx  document details (isaac councill, lee giles, pradeep teregowda) we show for the first time that incorporating the predictions of a word sense disambiguation system within a typical phrasebased statistical machine translation (smt) model consistently improves translation quality across all three different iwslt chineseenglish test sets, as well as producing statistically significant improvements on the larger nist chineseenglish mt task鈥 and moreover never hurts performance on any test set, according not only to bleu but to all eight most commonly used automatic evaluation metrics. recent work has challenged the assumption that word sense disambiguation (wsd) systems are useful for smt. yet smt translation quality still obviously suffers from inaccurate lexical choice. in this paper, we address this problem by investigating a new strategy for integrating wsd into an smt system, that performs fully phrasal multiword disambiguation. instead of directly incorporating a sensevalstyle wsd system, we redefine the wsd task to match the exact same phrasal translation disambiguation task faced by phrasebased smt systems.	-6	323
spmt: statistical machine translation with syntactified target language phrases	we introduce spmt, a new class of statistical translation models that use syntactified target language phrases. the spmt models outperform a state of the art phrasebased baseline model by 2.64 bleu points on the nist 2003 chineseenglish test corpus and 0.28 points on a humanbased quality metric that ranks translations on a scale from 1 to 5. 1	-7	332
batch tuning strategies for statistical machine translation	there has been a proliferation of recent work on smt tuning algorithms capable of handling larger feature sets than the traditional mert approach. we analyze a number of these algorithms in terms of their sentencelevel loss functions, which motivates several new approaches, including a structured svm. we perform empirical comparisons of eight different tuning strategies, including mert, in a variety of settings. among other results, we find that a simple and efficient batch version of mira performs at least as well as training online, and consistently outperforms other options.	-1	220
a smorgasbord of features for statistical machine translation	we describe a methodology for rapid experimentation in statistical machine translation which we use to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation.	-9	340
a new string-to-dependency machine translation algorithm with a target dependency language model	in this paper, we propose a novel stringto dependency algorithm for statistical machine translation. with this new framework, we em ploy a target dependency language model dur ing decoding to exploit long distance word relations, which are unavailable with a tra ditional ngram language model. our ex periments show that the stringtodependency decoder achieves 1.48 point improvement in bleu and 2.53 point improvement in ter compared to a standard hierarchical stringto string system on the nist 04 chineseenglish evaluation set.	-5	294
better hypothesis testing for statistical machine translation: controlling for optimizer instability	in statistical machine translation, a researcher seeks to determine whether some innovation (e.g., a new feature, model, or inference algorithm) improves translation quality in comparison to a baseline system. to answer this question, he runs an experiment to evaluate the behavior of the two systems on heldout data. in this paper, we consider how to make such experiments more statistically reliable. we provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accurately	-2	223
syntax augmented machine translation via chart parsing	we present translation results on the shared task exploiting parallel texts for statistical machine translation generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories. we use a target language parser to generate parse trees for each sentence on the target side of the bilingual training corpus, matching them with phrase table lattices built for the corresponding source sentence. considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar. we present results on the frenchtoenglish task for this workshop, representing significant improvements over the workshop's baseline system. our translation system is available opensource under the gnu general public license.	-7	301
syntax augmented machine translation via chart parsing	we present translation results on the shared task exploiting parallel texts for statistical machine translation generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories. we use a target language parser to generate parse trees for each sentence on the target side of the bilingual training corpus, matching them with phrase table lattices built for the corresponding source sentence. considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar. we present results on the frenchtoenglish task for this workshop, representing significant improvements over the workshop's baseline system. our translation system is available opensource under the gnu general public license.	-7	298
the mathematics of machine translation: parameter estimation	this paper, we focus on the translation modeling problem. before we turn to this problem, however, we should address an issue that may be a concern to some readers why do we estimate pr(e) and pr(fle) rather than estimate pr(elf ) directly? we are really interested in this latter probability. wouldn't we reduce our problems from three to two by this direct approach? if we can estimate pr(fle) adequately, why can't we just turn the whole process around to estimate pr(elf)? to understand this, imagine that we divide french and english strings into those that are wellformed and those that are illformed. this is not a precise notion. we have in mind that strings like il va la bibliothque, or i live in a house, or even colorless green ideas sleep furiously are wellformed, but that strings like lava i1 bibliothque or a i in live house are not. when we translate a french string into english, we can think of ourselves as springing from a wellformed french string into the sea of wellformed english strings with the hope of landing on a good one. it is important, therefore, that our model for pr(elf ) concentrate its probability as much as possible on wellformed english strings. but it is not important that our model for pr(fle ) concentrate its probability on wellformed french strings.	-20	392
improved statistical machine translation using paraphrases	parallel corpora are crucial for training smt systems. however, for many lan guage pairs they are available only in very limited quantities. for these lan guage pairs a huge portion of phrases en countered at runtime will be unknown. we show how techniques from paraphras ing can be used to deal with these oth erwise unknown source language phrases. our results show that augmenting a state oftheart smt system with paraphrases leads to significantly improved coverage and translation quality. for a training corpus with 10,000 sentence pairs we in crease the coverage of unique test set un igrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.	-7	301
learning non-isomorphic tree mappings for machine translation	often one may wish to learn a treetotree mapping, training it on unaligned pairs of trees, or on a mixture of trees and strings. unlike previous statistical formalisms (limited to isomorphic trees), allows local distortion of the tree topology. we reformulate it to permit dependency trees, and sketch em/viterbi algorithms for alignment, training, and decoding.	-10	337
word sense disambiguation improves statistical machine translation	recent research presents conflicting evidence on whether word sense disambiguation (wsd) systems can help to improve the performance of statistical machine translation (mt) systems. in this paper, we successfully integrate a stateoftheart wsd system into a stateoftheart hierarchical phrasebased mt system, hiero. we show for the first time that integrating a wsd system improves the performance of a stateoftheart statistical mt system on an actual translation task. furthermore, the improvement is statistically significant. 漏 2007 association for computational linguistics.	-6	288
optimizing chinese word segmentation for machine translation performance	previous work has shown that chinese word segmentation is useful for machine translation to english, yet the way different segmentation strategies affect mt is still poorly understood. in this paper, we demonstrate that optimizing segmentation for an existing segmentation standard does not always yield better mt performance. we find that other factors such as segmentation consistency and granularity of chinese words can be more important for machine translation. based on these findings, we implement methods inside a conditional random field segmenter that directly optimize segmentation granularity with respect to the mt task, providing an improvement of 0.73 bleu. we also show that improving segmentation consistency using external lexicon and proper noun features yields a 0.32 bleu increase. 1	-5	264
experiments in domain adaptation for statistical machine translation	the special challenge of the wmt 2007 shared task was domain adaptation. we took this opportunity to experiment with various ways of adapting a statistical machine translation systems to a special domain (here news commentary), when most of the training data is from a different domain (here european parliament speeches). this paper also gives a description of the submission of the university of edinburgh to the shared task.	-6	282
automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics.	in this paper we describe two new objective automatic evaluation methods for machine translation. the first method is based on long est common subsequence between a candidate translation and a set of reference translations. longest common subsequence takes into ac count sentence level structure similarity natu rally and identifies longest cooccurring in sequence ngrams automatically. the second method relaxes strict ngram matching to skip bigram matching. skipbigram is any pair of words in their sentence order. skipbigram co occurrence statistics measure the overlap of skipbigrams between a candidate translation and a set of reference translations. the empiri cal results show that both methods correlate with human judgments very well in both ade quacy and fluency.	-9	332
better hypothesis testing for statistical machine translation: controlling for optimizer instability	in statistical machine translation, a researcher seeks to determine whether some innovation (e.g., a new feature, model, or inference algorithm) improves translation quality in comparison to a baseline system. to answer this question, he runs an experiment to evaluate the behavior of the two systems on heldout data. in this paper, we consider how to make such experiments more statistically reliable. we provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accurately	-2	212
statistical machine translation by parsing	designers of statistical machine translation (smt) systems have begun trying to exploit treestructured syntactic information. this article offers a coherent algorithmic framework to facilitate such efforts. our main contribution is a generalization of the common notion of parsing. in an ordinary parser, the input is a single string, and the grammar ranges over strings. in order to use syntactic information, an smt system requires generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples. three particular generalizations, connected by some trivial glue, are all that is necessary for syntaxaware smt a synchronous parser is an algorithm that can infer the syntactic structure of each component text in a multitext and simultaneously infer the orrespondence relation between these structures. when a parser's input can have fewer dimensions than the parser's grammar, it is a translator. when a parser's grammar can have fewer dimensions than the parser's input, it is a synchronizer. this article offers a guided tour of these generalized parsing algorithms. it culminates with a recipe for using generalized parsing algorithms to train and apply a syntaxaware smt system.	-9	183
discriminative reranking for machine translation	this paper describes the application of discriminative reranking techniques to the problem of machine translation. for each sentence in the source language, we obtain from a baseline statistical machine translation system, a ranked n best list of candidate translations in the target language. we introduce two novel perceptroninspired reranking algorithms that improve on the quality of machine translation over the baseline system based on evaluation using the bleu metric. we provide experimental results on the nist 2003 chineseenglish large data track evaluation. we also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide stateoftheart performance in machine translation.	-9	183
synchronous binarization for machine translation	systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine transla tion output, but are often very computa tionally intensive.	-7	169
word-sense disambiguation for machine translation	in word sense disambiguation, a system attempts to determine the sense of a word from contextual fea tures. major barriers to building a highperforming word sense disambiguation system include the dif ficulty of labeling data for this task and of pre dicting finegrained sense distinctions. these is sues stem partly from the fact that the task is be ing treated in isolation from possible uses of au tomatically disambiguated data. in this paper, we consider the related task of word translation, where we wish to determine the correct translation of a word from context. we can use parallel language corpora as a large supply of partially labeled data for this task. we present algorithms for solving the word translation problem and demonstrate a signif icant improvement over a baseline system. we then show that the wordtranslation system can be used to improve performance on a simplified machine translation task and can effectively and accurately prune the set of candidate translations for a word.	-8	169
machine translation and telecommunications system using user id data to select dictionaries	a machine translation and telecommunications system includes a machine translation engine for translation of input text from a source language to a target language, a dictionary database including a core dictionary and a plurality of sublanguage (domain) dictionaries usable for translation from a source to a target language, a receiving interface for receiving text input from any of a plurality of users, each text input being accompanied by control information including user id data indicative of one or more sublanguages preferred by a particular user, an output interface, and a dictionary control module coupled to the receiving interface responsive to the user id data indicative of a sublanguage preference of a particular user for selecting a corresponding sublanguage dictionary of the dictionary database to be used by the machine translation engine along with the core dictionary for performing translation of the particular user's text input. user dictionaries can be maintained and selected to enhance translation accuracy in the same manner. the dictionary database encompassing core, sublanguage (domain), and user dictionaries is cumulated for greater capability over time through the use of dictionary maintenance utilities for updating the dictionaries.	-17	214
active learning and crowd-sourcing for machine translation.	in recent years, corpus based approaches to machine translation have become predominant, with statistical machine translation (smt) being the most actively progressing area. success of these approaches depends on the availability of parallel corpora. in this paper we propose active crowd translation (act), a new paradigm where active learning and crowdsourcing come together to enable automatic translation for lowresource language pairs. active learning aims at reducing cost of label acquisition by prioritizing the most informative data for annotation, while crowdsourcing reduces cost by using the power of the crowds to make do for the lack of expensive language experts. we experiment and compare our active learning strategies with strong baselines and see significant improvements in translation quality. similarly, our experiments with crowdsourcing on mechanical turk have shown that it is possible to create parallel corpora using nonexperts and with sufficient quality assurance, a translation system that is trained using this corpus approaches expert quality.	-3	133
hmm word and phrase alignment for statistical machine translation	estimation and alignment procedures for word and phrase alignment hidden markov models (hmms) are developed for the alignment of parallel text. the development of these models is motivated by an analysis of the desirable features of ibm model 4, one of the original and most effective models for word alignment. these models are formulated to capture the desirable aspects of model 4 in an hmm alignment formalism. alignment behavior is analyzed and compared to humangenerated reference alignments, and the ability of these models to capture different types of alignment phenomena is evaluated. in analyzing alignment performance, chineseenglish word alignments are shown to be comparable to those of ibm model 4 even when models are trained over large parallel texts. in translation performance, phrasebased statistical machine translation systems based on these hmm alignments can equal and exceed systems based on model 4 alignments, and this is shown in arabicenglish and chineseenglish translation. these alignment models can also be used to generate posterior statistics over collections of parallel text, and this is used to refine and extend phrase translation tables with a resulting improvement in translation quality.	-5	154
large-scale dictionary construction for foreign language tutoring and interlingual machine translation	this paper describes techniques for automatic construction of dictionaries for use in largescale foreign language tutoring (flt) and interlingual machine translation (mt) systems. the dictionaries are based on a languageindependent representation called “lexical conceptual structure” (lcs). a primary goal of the lcs research is to demonstrate that synonymous verb senses share distributional patterns. we show how the syntax–semantics relation can be used to develop a lexical acquisition approach that contributes both toward the enrichment of existing online resources and toward the development of lexicons containing more complete information than is provided in any of these resources alone. we start by describing the structure of the lcs and showing how this representation is used in flt and mt. we then focus on the problem of building lcs dictionaries for largescale flt and mt. first, we describe authoring tools for manual and semiautomatic construction of lcs dictionaries; we then present a more sophisticated approach that uses linguistic techniques for building word definitions automatically. these techniques have been implemented as part of a set of lexicondevelopment tools used in the milt flt project.	-16	202
machine translation: an introductory guide	the article provides insights for dental hygienists on using machine translation (mt). tips on using mt are enumerated, one of which is avoiding complex sentence to avoid confusing translation software. the methods through which mt operates include those based on dictionary entries and based statistical rules. also cited are popular and free mt sites such as yahoo! babel fish at http//translation2.paralink.com/ and http//www.systranet.com.	-19	315
machine translation and telecommunications system	a machine translation and telecommunications system automatically translates input text in a source language to output text in a target language using a dictionary database (22) containing core language dictionaries for general words, a plurality of sublanguage dictionaries for specialized words of different domains or user groups, and a plurality of user dictionaries for individualized words used by different users. the system includes a receiving interface (11) for receiving input from a sender, in the form of electronic text, facsimile (graphics) input, or page image data, and an output module (30) for sending translated output text to any designated recipient(s). the input text is accompanied by a cover page or header (50) identifying the sender, one or more recipients, their addresses, the source/target languages of the text, any sublanguage(s) applicable to the input text, and any formatting requirements for the output text. the system uses the cover page or header data to select the core language, sublanguage, and/or user dictionaries to be used for translation processing, to format the translated output text, and to send the output to the recipient(s) at the designated address(es).	-17	309
statistical machine translation for query expansion in answer retrieval	we present an approach to query expan sion in answer retrieval that uses statisti cal machine translation (smt) techniques to bridge the lexical gap between ques tions and answers. smtbased query ex pansion is done by i) using a fullsentence paraphraser to introduce synonyms in con text of the entire query, and ii) by trans lating query terms into answer terms us ing a fullsentence smt model trained on questionanswer pairs. we evaluate these global, contextaware query expansion tech niques on tfidf retrieval from 10 million questionanswer pairs extracted from faq pages. experimental results show that smt based expansion improves retrieval perfor mance over local expansion and over re trieval without expansion.	-5	235
loosely tree-based alignment for machine translation	we augment a model of translation based on reordering nodes in syntactic trees in order to allow alignments not conforming to the original tree structure, while keeping computational complexity polynomial in the sentence length. this is done by adding a new subtree cloning operation to either treetostring or treetotree alignment algorithms.	-10	279
chinese syntactic reordering for statistical machine translation	syntactic reordering approaches are an ef fective method for handling wordorder dif ferences between source and target lan guages in statistical machine translation (smt) systems. this paper introduces a re ordering approach for translation from chi nese to english. we describe a set of syntac tic reordering rules that exploit systematic differences between chinese and english word order. the resulting system is used as a preprocessor for both training and test sentences, transforming chinese sentences to be much closer to english in terms of their word order. we evaluated the reordering approach within the moses phrasebased smt system (koehn et al., 2007). the reordering approach improved the bleu score for the moses system from 28.52 to 30.86 on the nist 2006 evaluation data. we also conducted a series of experiments to an alyze the accuracy and impact of different types of reordering rules.	-6	241
manual and automatic evaluation of machine translation between european languages	we evaluated machine translation performance for six european language pairs that participated in a shared task translating french, german, spanish texts to english and back. evaluation was done automatically using the bleu score and manually on fluency and adequacy.	-7	246
a comparison of alignment models for statistical machine translation	in this paper, we present and compare various alignment models for statistical machine translation. we propose to measure the quality of an alignment model using the quality of the viterbi alignment compared to a manuallyproduced alignment and describe a rened annotation scheme to produce suitable reference alignments. the presented alignment models are then compared according to this error criterion. we also compare the impact of dierent alignment models on the translation quality of the alignment template system. 1 introduction in statistical machine translation (smt) it is necessary to model the translation probability p r(f j 1 je i 1 ). here f j 1 = f denotes the (french) source and e i 1 = e denotes the (english) target string. most smt models (brown et al., 1993; vogel et al., 1996) try to model wordtoword correspondences between source and target words using an alignment mapping from source position j to target position i = a j . formally, we can rewrite the pro...	-13	306
phrase-based joint probability model for statistical machine translation	a machine translation (mt) system utilizes a phrasebased joint probability model. the model is used to generate source and target language sentences simultaneously. in an embodiment, the model learns phrasetophrase alignments from wordtoword alignments generated by a wordtoword statistical mt system. the system utilizes the joint probability model for both sourcetotarget and targettosource translation applications.	-2	175
re-examining machine translation metrics for paraphrase identification	we propose to reexamine the hypothesis that automated metrics developed for mt evaluation can prove useful for paraphrase identification in light of the significant work on the development of new mt metrics over the last 4 years. we show that a metaclassifier trained using nothing but recent mt metrics outperforms all previous paraphrase identification approaches on the microsoft research paraphrase corpus. in addition, we apply our system to a second corpus developed for the task of plagiarism detection and obtain extremely positive results. finally, we conduct extensive error analysis and uncover the top systematic sources of error for a paraphrase identification approach relying solely on mt metrics. we release both the new dataset and the error analysis annotations for use by the community.	-1	91
recent advances in example-based machine translation	book review recent advances in examplebased machine translation michael carl and andy way (editors) (universitat des saarlandes and dublin city university) dordrecht  kluwer academic publishers (text, speech and language technology series, edited by nancy ide and jean veronis, volume 21), 2003 , xxxi+482 pp; hardbound, isbn 1402014007 , $173.00, f115.00, 180.00	-9	158
deeper sentiment analysis using machine translation technology	this paper proposes a new paradigm for sentiment analysis translation from text documents to a set of sentiment units. the techniques of deep language analysis for machine translation are applicable also to this kind of text mining task. we developed a highprecision sentiment analysis system at a low development cost, by making use of an existing transferbased machine translation engine.	-9	158
following directions using statistical machine translation	mobile robots that interact with humans in an intuitive way must be able to follow directions provided by humans in unconstrained natural language. in this work we investigate how statistical machine translation techniques can be used to bridge the gap between natural language route instructions and a map of an environment built by a robot. our approach uses training data to learn to translate from natural language instructions to an automaticallylabeled map. the complexity of the translation process is controlled by taking advantage of physical constraints imposed by the map. as a result, our technique can efficiently handle uncertainty in both map labeling and parsing. our experiments demonstrate the promising capabilities achieved by our approach.	-3	108
generation of word graphs in statistical machine translation	statistical machine translation systems usually compute the single sentence that has the highest probability according to the models that are trained on data. we describe a method for constructing a word graph to represent alternative hypotheses in an efficient way. the advantage is that these hypotheses can be rescored using a refined language or translation model.	-11	164
active learning and crowdsourcing for machine translation in low resource scenarios	corpus based approaches to automatic translation such as example based and statistical machine translation systems use large amounts of parallel data created by humans to train mathematical models for automatic language translation. large scale parallel data generation for new language pairs requires intensive human effort and availability of fluent bilinguals or expert translators. therefore it becomes immensely difficult and expensive to provide stateoftheart machine translation (mt) systems for rare languages.	-1	98
a comparative study on reordering constraints in statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary wordreorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible wordreorderings in an appropriate way, we obtain a polynomialtime search algorithm.in this paper, we compare two different reordering constraints, namely the itg constraints and the ibm constraints. this comparison includes a theoretical discussion on the permitted number of reorderings for each of these constraints. we show a connection between the itg constraints and the since 1870 known schröder numbers.we evaluate these constraints on two tasks the verbmobil task and the canadian hansards task. the evaluation consists of two parts first, we check how many of the viterbi alignments of the training corpus satisfy each of these constraints. second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.the experiments will show that the baseline itg constraints are not sufficient on the canadian hansards task. therefore, we present an extension to the itg constraints. these extended itg constraints increase the alignment coverage from about 87% to 96%.	-10	157
a novel string-to-string distance measure with applications to machine translation evaluation	we introduce a stringtostring distance measure which extends the edit distance by block transpositions as constant cost edit operation. an algorithm for the calculation of this distance measure in polynomial time is presented. we then demonstrate how this distance measure can be used as an evaluation criterion in machine translation. the correlation between this evaluation criterion and human judgment is systematically compared with that of other automatic evaluation measures on two translation tasks. in general, like other automatic evaluation measures, the criterion shows low correlation at sentence level, but good correlation at system level.	-10	161
the candide system for machine translation	we present an overview of candide, a system for automatic translation of french text to english text. candide uses methods of information theory and statistics to develop a probability model of the translation process. this model, which is made to accord as closely as possible with a large body of french and english sentence pairs, is then used to generate english translations of previously unseen french sentences. this paper provides a tutorial in these methods, discussions of the training and operation of the system, and a summary of test results. 1. introduction candide is an experimental computer program, now in its fifth year of development at ibm, for translation of french text to english text. our goal is to perform fullyautomatic, highquality texttotext translation. however, because we are still far from achieving this goal, the program can be used in both fullyautomatic and translator'sassistant modes. our approach is founded upon the statistical analysis of language....	-19	179
word-sense disambiguation for machine translation	in word sense disambiguation, a system attempts to determine the sense of a word from contextual fea tures. major barriers to building a highperforming word sense disambiguation system include the dif ficulty of labeling data for this task and of pre dicting finegrained sense distinctions. these is sues stem partly from the fact that the task is be ing treated in isolation from possible uses of au tomatically disambiguated data. in this paper, we consider the related task of word translation, where we wish to determine the correct translation of a word from context. we can use parallel language corpora as a large supply of partially labeled data for this task. we present algorithms for solving the word translation problem and demonstrate a signif icant improvement over a baseline system. we then show that the wordtranslation system can be used to improve performance on a simplified machine translation task and can effectively and accurately prune the set of candidate translations for a word.	-8	144
domain adaptation for machine translation by mining unseen words	we show that unseen words account for a large part of the translation error when moving to new domains. using an extension of a recent approach to mining translations from comparable corpora (haghighi et al., 2008), we are able to find translations for otherwise oov terms. we show several approaches to integrating such translations into a phrasebased translation system, yielding consistent improvements in translations quality (between 0.5 and 1.5 bleu points) on four domains and two language pairs. 1	-2	98
improving machine translation quality with automatic named entity recognition	named entities create serious problems for stateoftheart commercial machine translation (mt) systems and often cause translation failures beyond the local context, affecting both the overall morphosyntactic wellformedness of sentences and word sense disambiguation in the source text. we report on the results of an experiment in which mt input was processed using output from the named entity recognition module of sheffield's gate information extraction (ie) system. the gain in mt quality indicates that specific components of ie technology could boost the performance of current mt systems.	-10	147
translation engines: techniques for machine translation	machine translation (mt) is the area of computer science and applied linguistics dealing with the translation of human languages such as english and german. mt on the internet has become an important tool by providing fast, economical and useful translations. with globalisation and expanding trade, demand for translation is set to grow. translation engines covers theoretical and practical aspects of mt, both classic and new, including  character sets and formatting languages  translation memory  linguistic and computational foundations  basic computational linguistic techniques  transfer and interlingua mt  evaluation software accompanies the text, providing readers with hands on experience of the main algorithms.	-14	167
tailoring word alignments to syntactic machine translation	domain adaptationjohn blitzer and hal daumé iiiclassical “singledomain” learningpredicthorrible book, horrible. this book was horrible. i read half, suffering from a headache the entire time, and eventually i lit it on fire. 1 less copy in the world. don't waste your money. i wish i had the time spent reading this book back. it wasted my lifeso the topic of ah the talk today is online learningdomain adaptationso the topic of ah the talk today is online learningeverything is happening online. even the	-6	125
reordering constraints for phrase-based statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary reorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible reorderings in an appropriate way, we obtain a polynomialtime search algorithm. we investigate different reordering constraints for phrasebased statistical machine translation, namely the ibm constraints and the itg constraints. we present efficient dynamic programming algorithms for both constraints. we evaluate the constraints with respect to translation quality on two japanese鈥揈nglish tasks. we show that the reordering constraints improve translation quality compared to an unconstrained search that permits arbitrary phrase reorderings. the itg constraints preform best on both tasks and yield statistically significant improvements compared to the unconstrained search.	-9	149
consensus network decoding for statistical machine translation system combination	this paper presents a simple and robust consensus decoding approach for combining multiple machine translation (mt) system outputs. a consensus network is constructed from an nbest list by aligning the hypotheses against an alignment reference, where the alignment is based on minimising the translation edit rate (ter). the minimum bayes risk (mbr) decoding technique is investigated for the selection of an appropriate alignment reference. several alternative decoding strategies proposed to retain coherent phrases in the original translations. experimental results are presented primarily based on threeway combination of chineseenglish translation outputs, and also presents results for sixway system combination. it is shown that worthwhile improvements in translation performance can be obtained using the methods discussed.	-6	128
adaptation of the translation model for statistical machine translation based on information retrieval	. in this paper we present experiments concerning translation model adaptation for statistical machine translation. we develop a method to adapt translation models using information retrieval. the approach selects sentences similar to the test set.	-8	138
perplexity minimization for translation model domain adaptation in statistical machine translation	we investigate the problem of domain adaptation for parallel data in statistical machine translation (smt). while techniques for domain adaptation of monolingual data can be borrowed for parallel data, we explore conceptual differences between translation model and language model domain adaptation and their effect on performance, such as the fact that translation models typically consist of several features that have different characteristics and can be optimized separately. we also explore adapting multiple (4鈥10) data sets with no a priori distinction between indomain and outofdomain data except for an indomain development set.	-1	88
n-gram-based machine translation	this article describes in detail an ngram approach to statistical machine translation. this approach consists of a loglinear combination of a translation model based on ngrams of bilingual units, which are referred to as tuples, along with four specific feature functions. translation performance, which happens to be in the state of the art, is demonstrated with spanishtoenglish and englishtospanish translations of the european parliament plenary sessions (epps).	-7	200
machine translation with inferred stochastic finite-state transducers	summary finitestate transducers are models that are being used in different areas of pattern recognition and computational linguistics. one of these areas is machine translation, in which the approaches that are based on building models automatically from training examples are becoming more and more attractive. finitestate transducers are very adequate for use in constrained tasks in which training samples of pairs of sentences are available. a technique for inferring finitestate transducers is proposed in this article. this technique is based on formal relations between finitestate transducers and rational grammars. given a training corpus of sourcetarget pairs of sentences, the proposed approach uses statistical alignment methods to produce a set of conventional strings from which a stochastic rational grammar (e.g., an $n$gram) is inferred. this grammar is finally converted into a finitestate transducer. the proposed methods are assessed through a series of machine translation experiments within the framework of the eutrans project.	-7	199
machine translation divergences: a formal description and proposed solution	this paper demonstrates that a systematic solution to the divergence problem can be derived from the forrealization of two types of information (1) the linguistically grounded classes upon which lexicalsemantic divergences are based; and (2) the techniques by which lexicalsemantic divergences are resolved. this forrealization is advantageous in that it facilitates the design and implementation of the system, allows one to make an evaluation of the status of the system, and provides a basis for proving certain important properties about the system	-19	269
improvements in phrase-based statistical machine translation	in statistical machine translation, the currently best performing systems are based in some way on phrases or word groups. we describe the baseline phrasebased translation system and various refinements. we describe a highly efficient monotone search algorithm with a complexity linear in the input sentence length. we present translation results for three tasks verbmobil, xerox and the canadian hansards. for the xerox task, it takes less than 7 seconds to translate the whole test set consisting of more than 10k words. the translation results for the xerox and canadian hansards task are very promising. the system even outperforms the alignment template system.	-9	225
joshua: an open source toolkit for parsing-based machine translation	we describe joshua, an open source toolkit for statistical machine translation. joshua implements all of the algorithms required for synchronous context free grammars (scfgs) chartparsing, ngram language model integration, beamand cubepruning, and kbest extraction. the toolkit also implements suffixarray grammar extraction and minimum error rate training. it uses parallel and distributed computing techniques for scalability. we demonstrate that the toolkit achieves state of the art translation performance on the wmt09 frenchenglish translation task. 1	-4	164
europarl: a multilingual corpus for evaluation of machine translation	this paper reports results of the 1992 evaluation of machine translation (mt) systems in the darpa mt initiative and results of a pretest to the 1993 evaluation. the darpa initiative is unique in that the evaluated systems differ radically in languages translated, theoretical approach to system design, and intended enduser application. in the 1992 suite, a comprehension test compared the accuracy and interpretability of system and control outputs; a quality panel for each language pair judged the fidelity of translations from each source version. the 1993 suite evaluated adequacy and fluency and investigated three scoring methods.	-11	230
minimum error-rate training in statistical machine translation using structural svms	different works on training of loglinear interpolation models for statistical machine translation reported performance improvements by optimizing parameters with respect to translation quality.	-4	174
lattice-based minimum error rate training for statistical machine translation	minimum error rate training (mert) is an effective means to estimate the feature func tion weights of a linear model such that an automated evaluation criterion for measuring system performance can directly be optimized in training. to accomplish this, the training procedure determines for each feature func tion its exact error surface on a given set of candidate translations. the feature function weights are then adjusted by traversing the error surface combined over all sentences and picking those values for which the resulting error count reaches a minimum. typically, candidates in mert are represented as n  best lists which contain the n most probable translation hypotheses produced by a decoder. in this paper, we present a novel algorithm that allows for efficiently constructing and repre senting the exact error surface of all trans lations that are encoded in a phrase lattice. compared to n best mert, the number of candidate translations thus taken into account increases by several orders of magnitudes. the proposed method is used to train the feature function weights of a phrasebased statistical machine translation system. experi ments conducted on the nist 2008 translation tasks show significant runtime improvements and moderate bleu score gains over n best mert.	-5	178
orange: a method for evaluating automatic evaluation metrics for machine translation	comparisons of automatic evaluation metrics for machine translation are usually conducted on corpus level using correlation statistics such as pearson's product moment correlation coefficient or spearman's rank order correlation coefficient between human scores and automatic scores. however, such comparisons rely on human judgments of translation qualities such as adequacy and fluency. unfortunately, these judgments are often inconsistent and very expensive to acquire. in this paper, we introduce a new evaluation method, orange, for evaluating automatic machine translation evaluation metrics automatically without extra human involvement other than using a set of reference translations. we also show the results of comparing several existing automatic metrics and three new automatic metrics using orange.	-9	222
a non-contiguous tree sequence alignment-based model for statistical machine translation	the tree sequence based translation model al lows the violation of syntactic boundaries in a rule to capture nonsyntactic phrases, where a tree sequence is a contiguous sequence of sub trees. this paper goes further to present a trans lation model based on noncontiguous tree se quence alignment, where a noncontiguous tree sequence is a sequence of subtrees and gaps. compared with the contiguous tree sequence based model, the proposed model can well han dle noncontiguous phrases with any large gaps by means of noncontiguous tree sequence alignment. an algorithm targeting the non contiguous constituent decoding is also proposed. experimental results on the nist mt05 chi neseenglish translation task show that the pro posed model statistically significantly outper forms the baseline systems.	-4	176
synchronous binarization for machine translation	systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine transla tion output, but are often very computa tionally intensive. the complexity is ex ponential in the size of individual gram mar rules due to arbitrary reorderings be tween the two languages, and rules ex tracted from parallel corpora can be quite large. we devise a lineartime algorithm for factoring syntactic reorderings by bi narizing synchronous rules when possible and show that the resulting rule set signif icantly improves the speed and accuracy of a stateoftheart syntaxbased machine translation system.	-7	186
review article: example-based machine translation	in the last ten years there has been a significant amount ofresearch in machine translation within a ``new'' paradigm ofempirical approaches, often labelled collectively as``examplebased'' approaches. the first manifestation of thisapproach caused some surprise and hostility among observers moreused to different ways of working, but the techniques were quicklyadopted and adapted by many researchers, often creating hybridsystems. this paper reviews the various research efforts withinthis paradigm reported to date, and attempts a categorisation ofdifferent manifestations of the general approach.	-14	232
combining outputs from multiple machine translation systems	currently there are several approaches to machine translation (mt) based on differ ent paradigms; e.g., phrasal, hierarchical and syntaxbased. these three approaches yield similar translation accuracy despite using fairly different levels of linguistic knowledge. the availability of such a variety of systems has led to a growing interest toward finding better translations by combining outputs from multiple sys tems. this paper describes three differ ent approaches to mt system combina tion. these combination methods oper ate on sentence, phrase and word level exploiting information from best lists, system scores and targettosource phrase alignments. the wordlevel combination provides the most robust gains but the best results on the development test sets (nist mt05 and the newsgroup portion of gale 2006 dryrun) were achieved by combining all three methods.	-6	183
statistical machine translation : from single word models to alignment templates /	in diesear arbeit werden neue ans01tze zur sprachübersetzung basierend auf statistischen verfahren vorgestellt. als verallgemeinerung zu dem üblicherweise verwendeten sourcechannel modell wird ein allgemeineres modell basierend auf dem maximumentropieprinzip vorgeschlagen. es werden verschiedene verfahren zur bestimmung von wortalignments unter nutzung von statistischen und heuristischen modellen beschrieben. dabei werden insbesondere verschiedene gl01ttungsverfahren, methoden zur integration zus01tzlicher lexika und trainingsverfahren verglichen. eine detaillierte bewertung der alignmentqualit01t wird durchgeführt indem die automatisch erstellten wortalignments mit manuell erstellten alignments verglichen werden. aufbauend auf diesen grundlegenden einzelwortbasierten alignmentmodellen wird dann ein phrasenbasiertes statistisches 05bersetzungsmodell, das alignment template modell, vorgeschlagen. für dieses modell wird ein trainingsverfahren und ein effizienter suchalgorithmus basierend auf dem prinzip der dynamischer programmierung und strahlsuche entwickelt.	-11	207
a polynomial-time algorithm for statistical machine translation	we introduce a polynomialtime algorithm for statistical machine translation. this algorithm can be used in place of the expensive, slow bestfirst search strategies in current statistical translation architectures. the approach employs the stochastic bracketing transduction grammar (sbtg) model we recently introduced to replace earlier word alignment channel models, while retaining a bigram language model. the new algorithm in our experience yields major speed improvement with no significant loss of accuracy.	-17	226
online large-margin training for statistical machine translation	we achieved a state of the art performance in statistical machine translation by using a large number of features with an online largemargin training algorithm. the millions of parameters were tuned only on a small development set consisting of less than 1k sentences. experiments on arabictoenglish translation indicated that a model trained with sparse binary features outperformed a conventional smt system with a small number of features. 1	-6	182
learning for semantic parsing with statistical machine translation	we present a novel statistical approach to semantic parsing, wasp, for construct ing a complete, formal meaning represen tation of a sentence. a semantic parser is learned given a set of sentences anno tated with their correct meaning represen tations. the main innovation of wasp is its use of stateoftheart statistical ma chine translation techniques. a word alignment model is used for lexical acqui sition, and the parsing model itself can be seen as a syntaxbased translation model. we show that wasp performs favorably in terms of both accuracy and coverage compared to existing learning methods re quiring similar amount of supervision, and shows better robustness to variations in task complexity and word order.	-7	192
a tree-to-tree alignment-based model for statistical machine translation	this paper presents a novel statistical machine translation (smt) model that uses treetotree alignment between a source parse tree and a target parse tree. the model is formally a probabilistic synchronous treesubstitution grammar (stsg) that is a collection of aligned elementary tree pairs with mapping probabilities (which are automatically learned from wordaligned biparsed parallel texts). unlike previous syntaxbased smt models, this new model supports multilevel global structure distortion of the tree typology and can fully utilize the source and target parse tree structure features, which gives our system more expressive power and flexibility. the experimental results on the hit biparsed text show that our method performs significantly better than pharaoh, a stateoftheart phrasebased smt system, and other syntaxbased methods, such as the synchronous cfgbased method on the small dataset.	-6	184
computing consensus translation for multiple machine translation systems using enhanced hypothesis alignment	this paper describes a novel method for computing a consensus translation from the outputs of multiple machine translation (mt) systems. the outputs are combined and a possibly new translation hypothesis can be generated. similarly to the wellestablished rover approach of (fiscus, 1997) for combining speech recognition hypotheses, the consensus translation is computed by voting on a confusion network. to create the confusion network, we produce pairwise word alignments of the original machine translation hypotheses with an enhanced statistical alignment algorithm that explicitly models word reordering. the context of a whole document of translations rather than a single sentence is taken into account to produce the alignment.	-7	190
discriminative instance weighting for domain adaptation in statistical machine translation	we describe a new approach to smt adaptation that weights outofdomain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not. this extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure. we incorporate instance weighting into a mixturemodel framework, and find that it yields consistent improvements over a wide range of baselines.	-3	140
machine translation: past, present, future	most computational linguists are probably aware that machine translation (mt) has provided the impetus for a number of important advances in linguistics and computing over the past 40 years. but even those who have worked on mt could not have fully appreciated.	-27	237
machine translation and telecommunications system using user id data to select dictionaries	a machine translation and telecommunications system includes a machine translation engine for translation of input text from a source language to a target language, a dictionary database including a core dictionary and a plurality of sublanguage (domain) dictionaries usable for translation from a source to a target language, a receiving interface for receiving text input from any of a plurality of users, each text input being accompanied by control information including user id data indicative of one or more sublanguages preferred by a particular user, an output interface, and a dictionary control module coupled to the receiving interface responsive to the user id data indicative of a sublanguage preference of a particular user for selecting a corresponding sublanguage dictionary of the dictionary database to be used by the machine translation engine along with the core dictionary for performing translation of the particular user's text input. user dictionaries can be maintained and selected to enhance translation accuracy in the same manner. the dictionary database encompassing core, sublanguage (domain), and user dictionaries is cumulated for greater capability over time through the use of dictionary maintenance utilities for updating the dictionaries.	-17	214
active learning and crowd-sourcing for machine translation	in recent years, corpus based approaches to machine translation have become predominant, with statistical machine translation (smt) being the most actively progressing area. success of these approaches depends on the availability of parallel corpora. in this paper we propose active crowd translation (act), a new paradigm where active learning and crowdsourcing come together to enable automatic translation for lowresource language pairs. active learning aims at reducing cost of label acquisition by prioritizing the most informative data for annotation, while crowdsourcing reduces cost by using the power of the crowds to make do for the lack of expensive language experts. we experiment and compare our active learning strategies with strong baselines and see significant improvements in translation quality. similarly, our experiments with crowdsourcing on mechanical turk have shown that it is possible to create parallel corpora using nonexperts and with sufficient quality assurance, a translation system that is trained using this corpus approaches expert quality.	-3	135
predicting the sentence-level quality of machine translation systems	we investigate the problem of predicting the quality of sentences produced by machine translation systems when reference translations are not available. the problem is addressed as a regression task and a method that takes into account t...	-4	146
the meteor metric for automatic evaluation of machine translation	the meteor  automatic metric for machine translation evaluation, originally developed and released in 2004, was designed with the explicit goal of producing sentencelevel scores which correlate well with human judgments of translation quality. several key design decisions were incorporated into meteor  in support of this goal. in contrast with ibm鈥檚 bleu , which uses only precisionbased features, meteor  uses and emphasizes recall in addition to precision, a property that has been confirmed by several metrics as being critical for high correlation with human judgments. meteor  also addresses the problem of reference translation variability by utilizing flexible word matching, allowing for morphological variants and synonyms to be taken into account as legitimate correspondences. furthermore, the feature ingredients within meteor  are parameterized, allowing for the tuning of the metric鈥檚 free parameters in search of values that result in optimal correlation with human judgments. optimal parameters can be separately tuned for different types of human judgments and for different languages. we discuss the initial design of the meteor  metric, subsequent improvements, and performance in several independent evaluations in recent years.	-4	150
hmm word and phrase alignment for statistical machine translation	estimation and alignment procedures for word and phrase alignment hidden markov models (hmms) are developed for the alignment of parallel text. the development of these models is motivated by an analysis of the desirable features of ibm model 4, one of the original and most effective models for word alignment. these models are formulated to capture the desirable aspects of model 4 in an hmm alignment formalism. alignment behavior is analyzed and compared to humangenerated reference alignments, and the ability of these models to capture different types of alignment phenomena is evaluated. in analyzing alignment performance, chineseenglish word alignments are shown to be comparable to those of ibm model 4 even when models are trained over large parallel texts. in translation performance, phrasebased statistical machine translation systems based on these hmm alignments can equal and exceed systems based on model 4 alignments, and this is shown in arabicenglish and chineseenglish translation. these alignment models can also be used to generate posterior statistics over collections of parallel text, and this is used to refine and extend phrase translation tables with a resulting improvement in translation quality.	-5	154
apertium: a free/open-source platform for rule-based machine translation	apertium is a free/opensource platform for rulebased machine translation. it is being widely used to build machine translation systems for a variety of l...	-2	125
demonstration of joshua: an open source toolkit for parsing-based machine translation	we describe joshua, an open source toolkit for statistical machine transla tion. joshua implements all of the algo rithms required for synchronous context free grammars (scfgs) chartparsing, n gram language model integration, beam and cubepruning, and kbest extraction. the toolkit also implements suffixarray grammar extraction and minimum error rate training. it uses parallel and dis tributed computing techniques for scala bility. we demonstrate that the toolkit achieves state of the art translation per formance on the wmt09 frenchenglish translation task.	-4	147
statistical machine translation by parsing	designers of statistical machine translation (smt) systems have begun trying to exploit treestructured syntactic information. this article offers a coherent algorithmic framework to facilitate such efforts. our main contribution is a generalization of the common notion of parsing. in an ordinary parser, the input is a single string, and the grammar ranges over strings. in order to use syntactic information, an smt system requires generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples. three particular generalizations, connected by some trivial glue, are all that is necessary for syntaxaware smt a synchronous parser is an algorithm that can infer the syntactic structure of each component text in a multitext and simultaneously infer the orrespondence relation between these structures. when a parser's input can have fewer dimensions than the parser's grammar, it is a translator. when a parser's grammar can have fewer dimensions than the parser's input, it is a synchronizer. this article offers a guided tour of these generalized parsing algorithms. it culminates with a recipe for using generalized parsing algorithms to train and apply a syntaxaware smt system.	-9	183
discriminative reranking for machine translation	this paper describes the application of discriminative reranking techniques to the problem of machine translation. for each sentence in the source language, we obtain from a baseline statistical machine translation system, a ranked n best list of candidate translations in the target language. we introduce two novel perceptroninspired reranking algorithms that improve on the quality of machine translation over the baseline system based on evaluation using the bleu metric. we provide experimental results on the nist 2003 chineseenglish large data track evaluation. we also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide stateoftheart performance in machine translation.	-9	183
synchronous binarization for machine translation	systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine transla tion output, but are often very computa tionally intensive. the complexity is ex ponential in the size ...	-7	169
word-sense disambiguation for machine translation	in word sense disambiguation, a system attempts to determine the sense of a word from contextual fea tures. major barriers to building a highperforming word sense disambiguation system include the dif ficulty of labeling data for this task and of pre dicting finegrained sense distinctions. these is sues stem partly from the fact that the task is be ing treated in isolation from possible uses of au tomatically disambiguated data. in this paper, we consider the related task of word translation, where we wish to determine the correct translation of a word from context. we can use parallel language corpora as a large supply of partially labeled data for this task. we present algorithms for solving the word translation problem and demonstrate a signif icant improvement over a baseline system. we then show that the wordtranslation system can be used to improve performance on a simplified machine translation task and can effectively and accurately prune the set of candidate translations for a word.	-8	169
morphological analysis for statistical machine translation	we present a novel morphological analysis technique which induces a morphological and syntactic symmetry between two languages with highly asymmetrical morphological structures to improve statistical machine translation qualities. the technique presupposes finegrained segmentation of a word in the morphologically rich language into the sequence of prefix(es)stemsuffix(es) and partofspeech tagging of the parallel corpus. the algorithm identifies morphemes to be merged or deleted in the morphologically rich language to induce the desired morphological and syntactic symmetry. the technique improves arabictoenglish translation qualities significantly when applied to ibm model 1 and phrase translation models trained on the training corpus size ranging from 3,500 to 3.3 million sentence pairs.	-9	176
active learning and crowd-sourcing for machine translation.	in recent years, corpus based approaches to machine translation have become predominant, with statistical machine translation (smt) being the most actively progressing area. success of these approaches depends on the availability of parallel corpora. in this paper we propose active crowd translation (act), a new paradigm where active learning and crowdsourcing come together to enable automatic translation for lowresource language pairs. active learning aims at reducing cost of label acquisition by prioritizing the most informative data for annotation, while crowdsourcing reduces cost by using the power of the crowds to make do for the lack of expensive language experts. we experiment and compare our active learning strategies with strong baselines and see significant improvements in translation quality. similarly, our experiments with crowdsourcing on mechanical turk have shown that it is possible to create parallel corpora using nonexperts and with sufficient quality assurance, a translation system that is trained using this corpus approaches expert quality.	-3	133
experiments and prospects of example-based machine translation	ebmt (examplebased machine translation) is proposed. ebmt retrieves similar examples (pairs of source phrases, sentences, or texts and their translations) from a tahase of examples, adapting the examples to franslate a new input. ebmt has the following features (1) it is easily upgr, zled simply by inputting appropriate examples to the database; (2) it assigns a reliability factor to the translation result; (3) it is accelerated effectively by both indexing axi parallel computing; (4) it is robust because of bestmatch reasoning; (5) it well utilizes translator expertise. a prototype system has been implemented to deal with a difficult iranslation problem fee conventional rulebased machine translation (rbmt), i.e., translating japanese noun phrases of the form 'lq a no n2 into english. the system has achieved about a 78% success rate on average. this paper explains the basic idea of ebmt, illustrates the experiment in detail, explains the broad applicability of ebmt to several difficult translation problems fee rbmt discusses the advantages of integrating ebmt with rbmt.	-22	211
word reordering and a dynamic programming beam search algorithm for statistical machine translation	summary in this article, we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming (dp). the search algorithm uses the translation model presented in [{\it p. f. brown}, {\it s. a. della pietra}, {\it v. j. della pietra} and {\it r. l. mercer}, 鈥淭he mathematics of statistical machine translation parameter estimation, ibid. 19, no. 2, 263鈥311 (1993)]. starting from a dpbased solution to the travelingsalesman problem, we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm. word reordering restrictions especially useful for the translation direction german to english are presented. the restrictions are generalized, and a set of four parameters to control the word reordering is introduced, which then can easily be adopted to new translation directions. the beam search procedure has been successfully tested on the verbmobil task (german to english, 8,000word vocabulary) and on the canadian hansards task (french to english, 100,000word vocabulary). for the mediumsized verbmobil task, a sentence can be translated in a few seconds, only a small number of search errors occur	-10	178
large-scale dictionary construction for foreign language tutoring and interlingual machine translation	this paper describes techniques for automatic construction of dictionaries for use in largescale foreign language tutoring (flt) and interlingual machine translation (mt) systems. the dictionaries are based on a languageindependent representation called “lexical conceptual structure” (lcs). a primary goal of the lcs research is to demonstrate that synonymous verb senses share distributional patterns. we show how the syntax–semantics relation can be used to develop a lexical acquisition approach that contributes both toward the enrichment of existing online resources and toward the development of lexicons containing more complete information than is provided in any of these resources alone. we start by describing the structure of the lcs and showing how this representation is used in flt and mt. we then focus on the problem of building lcs dictionaries for largescale flt and mt. first, we describe authoring tools for manual and semiautomatic construction of lcs dictionaries; we then present a more sophisticated approach that uses linguistic techniques for building word definitions automatically. these techniques have been implemented as part of a set of lexicondevelopment tools used in the milt flt project.	-16	202
machine translation of languages	, machine translation of languages (pp. 1523). new york  john wiley & sons.w. weaver.translation (1949). machine translation of languages . 1955weaver w. (1955). translation (1949). in machine translation of languages, mit ...	-58	227
statistical machine translation by parsing	in an ordinary syntactic parser, the input is a string, and the grammar ranges over strings. this paper explores generalizations of ordinary parsing algo rithms that allow the input to consist of string tu ples and/or the grammar to range over string tu ples. such algorithms can infer the synchronous structures hidden in parallel texts. it turns out that these generalized parsers can do most of the work required to train and apply a syntaxaware statisti cal machine translation system.	-9	167
the cmu statistical machine translation system	in this paper we describe the components of our statistical machine translation system.	-10	169
distortion models for statistical machine translation.	in this paper, we argue that ngram lan guage models are not sufficient to address word reordering required for machine trans lation. we propose a new distortion model that can be used with existing phrasebased smt decoders ...	-7	157
word-level confidence estimation for machine translation	this article introduces and evaluates several different wordlevel confidence measures for ma chine translation. these measures provide a method for labeling each word in an automatically generated translation as correct or incorrect. all approaches to confidence estimation presented here are based on word posterior probabilities. different concepts of word posterior probabilities as well as different ways of calculating them will be introduced and compared. they can be divided into two categories systembased methods that explore knowledge provided by the translation system that generated the translations, and direct methods that are independent of the translation system. the systembased techniques make use of system output, such as word graphs or nbest lists. the word posterior probability is determined by summing the probabilities of the sentences in the translation hypothesis space that contains the target word. the direct confidence measures take other knowledge sources, such as word or phrase lexica, into account. they can be applied to output from nonstatistical machine translation systems as well. experimental assessment of the different confidence measures on various translation tasks and in several language pairs will be presented.	-6	150
computing consensus translation from multiple machine translation systems	we address the problem of computing a consensus translation given the outputs from a set of machine translation (mt) systems. the translations from the mt systems are aligned with a multiple string alignment algorithm and the consensus translation is then computed. we describe the multiple string alignment algorithm and the consensus mt hypothesis computation. we report on the subjective and objective performance of the multilingual acquisition approach on a limited domain spoken language application. we evaluate five domainindependent offtheshelf mt systems and show that the consensusbased translation performance is equal to or better than any of the given mt systems, in terms of both objective and subjective measures.	-12	179
a maximum entropy word aligner for arabic-english machine translation.	this paper presents a maximum entropy word alignment algorithm for arabic english based on supervised training data. we demonstrate that it is feasible to cre ate training material for problems in ma chine translation and that a mixture of su pervised and unsupervised methods yields superior performance. the probabilistic model used in the alignment directly mod els the link decisions. significant improve ment over traditional word alignment tech niques is shown as well as improvement on several machine translation tests. perfor mance of the algorithm is contrasted with human annotation performance.	-8	161
active learning and crowdsourcing for machine translation in low resource scenarios	ambati, v., vogel, s., carbonell, j. active learning and crowdsourcing for machine translation. language resources and evaluation (lrec) 7, 2169–2174 (2010)ambati, v., vogel, s., & carbonell j. 2010. active learning ...	-1	98
the world wide web as a resource for example-based machine translation tasks	the www is two orders of magnitude larger than the largest corpora. although noisy, web text presents language as it is used, and statistics derived from the web can have practical uses in many nlp applications. for this reason, the www should be seen and studied as any other computationally available linguistic resource. in this article, we illustrate this by showing that an examplebased approach to lexical choice for machine translation can use the web as an adequate and free resource.	-14	187
recent advances in example-based machine translation	book review recent advances in examplebased machine translation michael carl and andy way (editors) (universitat des saarlandes and dublin city university) dordrecht  kluwer academic publishers (text, speech and language technology series, edited by nancy ide and jean veronis, volume 21), 2003 , xxxi+482 pp; hardbound, isbn 1402014007 , $173.00, f115.00, 180.00	-9	158
deeper sentiment analysis using machine translation technology	this paper proposes a new paradigm for sentiment analysis translation from text documents to a set of sentiment units. the techniques of deep language analysis for machine translation are applicable also to this kind of text mining task. we developed a highprecision sentiment analysis system at a low development cost, by making use of an existing transferbased machine translation engine.	-9	158
generation of word graphs in statistical machine translation	statistical machine translation systems usually compute the single sentence that has the highest probability according to the models that are trained on data. we describe a method for constructing a word graph to represent alternative hypotheses in an efficient way. the advantage is that these hypotheses can be rescored using a refined language or translation model.	-11	164
two approaches to matching in example-based machine translation	this paper describes two approaches to matching input strings with strings from a translation archive in the examplebased machine translation paradigm  the more canonical chunking + matching + recombination method and an alternative method of matching at the level of complete sentences. the latter produces less exact matches while the former suffers from (often serious) translation quality lapses at the boundaries of recombined chunks. a set of text matching criteria was selected to reflect the tradeoff between utility and computational price of each criterion. a metric for comparing text passages was devised and calibrated with the help of a specially constructed diagnostic example set. a partitioning algorithm was developed for finding an optimum cover of an input string by a set of bestmatching shorter chunks. the results were evaluated in a monolingual setting using an existing mt postediting tool the distance between the input and its best match in the archive was calculated in terms of the number of keystrokes necessary to reduce the latter to the former. as a result, the metric was adjusted and an experiment was run to test the two ebmt methods, both on the training corpus and on the working corpus (or archive) of some 6,500 sentences.	-20	189
proceedings of the fourth workshop on statistical machine translation	we describe two systems for englishtoczech machine translation that took part in the wmt09 translation task. one of the systems is a tuned phrasebased system and the other one is based on a linguistically motivated analysistransfers...	-4	124
active learning and crowdsourcing for machine translation in low resource scenarios	corpus based approaches to automatic translation such as example based and statistical machine translation systems use large amounts of parallel data created by humans to train mathematical models for automatic language translation. large scale parallel data generation for new language pairs requires intensive human effort and availability of fluent bilinguals or expert translators. therefore it becomes immensely difficult and expensive to provide stateoftheart machine translation (mt) systems for rare languages.	-1	98
a productivity test of statistical machine translation post-editing in a typical localisation context	we evaluated the productivity increase of statistical mt postediting as compared to traditional translation in a twoday test involving twelve participants translating from english to french, italian, german, and spanish. the test setup followed an empirical methodology. a random subset of the entire new content produced in our company during a given year was translated with statistical mt engines trained on data from the previous year. the translation environment recorded translation and postediting times for each sentence. the results show a productivity increase for each participant, with significant variance across inviduals.	-3	118
a novel string-to-string distance measure with applications to machine translation evaluation	we introduce a stringtostring distance measure which extends the edit distance by block transpositions as constant cost edit operation. an algorithm for the calculation of this distance measure in polynomial time is presented. we then demonstrate how this distance measure can be used as an evaluation criterion in machine translation. the correlation between this evaluation criterion and human judgment is systematically compared with that of other automatic evaluation measures on two translation tasks. in general, like other automatic evaluation measures, the criterion shows low correlation at sentence level, but good correlation at system level.	-10	161
word reordering and a dynamic programming beam search algorithm for statistical machine translation	summary in this article, we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming (dp). the search algorithm uses the translation model presented in [{\it p. f. brown}, {\it s. a. della pietra}, {\it v. j. della pietra} and {\it r. l. mercer}, 鈥淭he mathematics of statistical machine translation parameter estimation, ibid. 19, no. 2, 263鈥311 (1993)]. starting from a dpbased solution to the travelingsalesman problem, we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm. word reordering restrictions especially useful for the translation direction german to english are presented. the restrictions are generalized, and a set of four parameters to control the word reordering is introduced, which then can easily be adopted to new translation directions. the beam search procedure has been successfully tested on the verbmobil task (german to english, 8,000word vocabulary) and on the canadian hansards task (french to english, 100,000word vocabulary).	-10	164
the candide system for machine translation	we present an overview of candide, a system for automatic translation of french text to english text. candide uses methods of information theory and statistics to develop a probability model of the translation process. this model, which is made to accord as closely as possible with a large body of french and english sentence pairs, is then used to generate english translations of previously unseen french sentences. this paper provides a tutorial in these methods, discussions of the training and operation of the system, and a summary of test results. 1. introduction candide is an experimental computer program, now in its fifth year of development at ibm, for translation of french text to english text. our goal is to perform fullyautomatic, highquality texttotext translation. however, because we are still far from achieving this goal, the program can be used in both fullyautomatic and translator'sassistant modes. our approach is founded upon the statistical analysis of language....	-19	179
word-sense disambiguation for machine translation	in word sense disambiguation, a system attempts to determine the sense of a word from contextual fea tures. major barriers to building a highperforming word sense disambiguation system include the dif ficulty of labeling dat...	-8	144
re-examining machine translation metrics for paraphrase identification	we propose to reexamine the hypothesis that automated metrics developed for mt evaluation can prove useful for paraphrase identification in light of the significant work on the development of new mt metrics over the last 4 years. we show that a metaclassifier trained using nothing but recent mt metrics outperforms all previous paraphrase identification approaches on the microsoft research paraphrase corpus. in addition, we apply our system to a second corpus developed for the task of plagiarism detection and obtain extremely positive results. finally, we conduct extensive error analysis and uncover the top systematic sources of error for a paraphrase identification approach relying solely on mt metrics. we release both the new dataset and the error analysis annotations for use by the community.	-1	91
translation engines: techniques for machine translation	machine translation (mt) is the area of computer science and applied linguistics dealing with the translation of human languages such as english and german. mt on the internet has become an important tool by providing fast, economical and useful translations. with globalisation and expanding trade, demand for translation is set to grow. translation engines covers theoretical and practical aspects of mt, both classic and new, including  character sets and formatting languages  translation memory  linguistic and computational foundations  basic computational linguistic techniques  transfer and interlingua mt  evaluation software accompanies the text, providing readers with hands on experience of the main algorithms.	-14	167
following directions using statistical machine translation	mobile robots that interact with humans in an intuitive way must be able to follow directions provided by humans in unconstrained natural language. in this work we investigate how statistical machine translation techniques can be used to bridge the gap between natural language route instructions and a map of an environment built by a robot. our approach uses training data to learn to translate from natural language instructions to an automaticallylabeled map. the complexity of the translation process is controlled by taking advantage of physical constraints imposed by the map. as a result, our technique can efficiently handle uncertainty in both map labeling and parsing. our experiments demonstrate the promising capabilities achieved by our approach.	-3	108
word sense disambiguation vs. statistical machine translation	we directly investigate a subject of much recent debate do word sense disambiga tion models help statistical machine trans lation quality? we present empirical re sults casting doubt on this common, but unproved, assumption. using a stateof theart chinese word sense disambigua tion model to choose translation candi dates for a typical ibm statistical mt system, we find that word sense disam biguation does not yield significantly bet ter translation quality than the statistical machine translation system alone. error analysis suggests several key factors be hind this surprising finding, including in herent limitations of current statistical mt architectures.	-8	149
lattice minimum bayes-risk decoding for statistical machine translation	we present minimum bayesrisk (mbr) decoding for statistical machine translation. this statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance. we describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, wordtoword alignments from an mt system, and syntactic structure from parsetrees of source and target language sentences. we report the performance of the mbr decoders on a chinesetoenglish translation task. our results show that mbr decoding can be used to tune statistical mt performance for specific loss functions.	-5	127
reordering constraints for phrase-based statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary reorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible reorderings in an appropriate way, we obtain a polynomialtime search algorithm. we investigate different reordering constraints for phrasebased statistical machine translation, namely the ibm constraints and the itg constraints. we present efficient dynamic programming algorithms for both constraints. we evaluate the constraints with respect to translation quality on two japanese鈥揈nglish tasks. we show that the reordering constraints improve translation quality compared to an unconstrained search that permits arbitrary phrase reorderings. the itg constraints preform best on both tasks and yield statistically significant improvements compared to the unconstrained search.	-9	149
a comparative study on reordering constraints in statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary wordreorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible wordreorderings in an appropriate way, we obtain a polynomialtime search algorithm.in this paper, we compare two different reordering constraints, namely the itg constraints and the ibm constraints. this comparison includes a theoretical discussion on the permitted number of reorderings for each of these constraints. we show a connection between the itg constraints and the since 1870 known schröder numbers.we evaluate these constraints on two tasks the verbmobil task and the canadian hansards task. the evaluation consists of two parts first, we check how many of the viterbi alignments of the training corpus satisfy each of these constraints. second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.the experiments will show that the baseline itg constraints are not sufficient on the canadian hansards task. therefore, we present an extension to the itg constraints. these extended itg constraints increase the alignment coverage from about 87% to 96%.	-10	157
machine translation evaluation versus quality estimation	most evaluation metrics for machine translation (mt) require reference translations for each sentence in order to produce a score reflecting certain aspects of its quality. the de facto metrics, bleu and nist, are known to have good correlation with human evaluation at the corpus level, but this is not the case at the segment level. as an attempt to overcome these two limitations, we address the problem of evaluating the quality of mt as a prediction task, where referenceindependent features are extracted from the input sentences and their translation, and a quality score is obtained based on models produced from training data. we show that this approach yields better correlation with human evaluation as compared to commonly used metrics, even with models trained on different mt systems, languagepairs and text domains.	-3	84
machine translation with a stochastic grammatical channel	we introduce a stochastic grammatical channel model for machine translation, that synthesizes several desirable characteristics of both statistical and grammatical machine translation. as with the pure statistical translation model described by wu (1996) (in which a bracketing transduction grammar models the channel), alternative hypotheses compete probabilistically, exhaustive search of the translation hypothesis space can be performed in polynomial time, and robustness heuristics arise naturally from a languageindependent inversiontransduction model. however, unlike pure statistical translation models, the generated output string is guaranteed to conform to a given target grammar. the model employs only (1) a translation lexicon, (2) a contextfree grammar for the target language, and (3) a bigram language model. the fact that no explicit bilingual translation rules are used makes the model easily portable to a variety of source languages. initial experiments show that it also achieves significant speed gains over our earlier model.	-15	131
multi-engine machine translation guided by explicit word matching	we describe a new approach for synthetically combining the output of several different machine translation (mt) engines operating on the same input. the goal is to pro duce a synthetic combination that surpasses all of the original systems in translation quality. our approach uses the individual mt engines as black boxes and does not require any explicit cooperation from the original mt systems. an explicit word matcher is first used in order to identify the words that are common between the mt engine outputs. a decoding algorithm then uses this information, in conjunction with confidence estimates for the vari ous engines and a trigram language model in order to score and rank a collection of sen tence hypotheses that are synthetic combinations of words from the various original en gines. the highest scoring sentence hypothesis is selected as the final output of our system. experiments conducted using three chinesetoenglish online translation systems demon strate that our multiengine combination system provides an improvement of about 6% over the best original system, and is about equal in translation quality to an oracle capable of selecting the best of the original systems on a sentencebysentence basis.	-8	108
machine translation by triangulation: making effective use of multi-parallel corpora	current phrasebased smt systems perform poorly when using small training sets. this is a consequence of unreliable translation es timates and low coverage over source and target phrases. this paper presents a method which alleviates this problem by exploit ing multiple translations of the same source phrase. central to our approach is triangula tion, the process of translating from a source to a target language via an intermediate third language. this allows the use of a much wider range of parallel corpora for train ing, and can be combined with a standard phrasetable using conventional smoothing methods. experimental results demonstrate bleu improvements for triangulated mod els over a standard phrasebased system.	-6	103
bilingual framenet dictionaries for machine translation	this paper describes issues surrounding the planning and design of germanframenet (gfn), a counterpart to the englishbased framenet project. the goals of gfn are (a) to create lexical entries for german nouns, verbs, and adjectives that correspond to existing framenet entries, and (b) to link the parallel lexicon fragments by means of common semantic frames and numerical indexing mechanisms. gfn will take a finegrained approach towards polysemy that seeks to split word senses based on the semantic frames that underlie their analysis. the parallel lexicon fragments represent an important step towards capturing valuable information about the different syntactic realizations of frame semantic concepts across languages, which is relevant for information retrieval, machine translation, and language generation.	-11	119
statistical machine translation with word- and sentence-aligned parallel corpora.	the parameters of statistical translation models are typically estimated from sentencealigned parallel corpora. we show that significant improvements in the alignment and translation quality of such models can be achieved by additionall...	-9	115
applying morphology generation models to machine translation	we improve the quality of statistical machine translation (smt) by applying models that predict word forms from their stems using extensive morphological and syntactic infor mation from both the source and target lan guages. our inflection generation models are trained independently of the smt system. we investigate different ways of combining the in flection prediction component with the smt system by training the base mt system on fully inflected forms or on word stems. we applied our inflection generation models in translating english into two morphologically complex languages, russian and arabic, and show that our model improves the quality of smt over both phrasal and syntaxbased smt systems according to bleu and human judge ments.	-5	94
a probabilistic approach to syntax-based reordering for statistical machine translation	inspired by previous preprocessing ap proaches to smt, this paper proposes a novel, probabilistic approach to reordering which combines the merits of syntax and phrasebased smt. given a source sentence and its parse tree, our method generates, by tree operations, an nbest list of re ordered inputs, which are then fed to stan dard phrasebased decoder to produce the optimal translation. experiments show that, for the nist mt05 task of chineseto english translation, the proposal leads to bleu improvement of 1.56%.	-6	103
word-dependent transition models in hmm based word alignment for statistical machine translation	a word alignment modeler uses probabilistic learning techniques to train “worddependent transition models” for use in constructing phrase level hidden markov model (hmm) based word alignment models. as defined herein, “worddependent transition models” provide a probabilistic model wherein for each source word in training data, a selftransition probability is modeled in combination with a probability of jumping from that particular word to a different word, thereby providing a full transition model for each word in a source phrase. hmm based word alignment models are then used for various word alignment and machine translation tasks. in additional embodiments sparse data problems (i.e., rarely used words) are addressed by using probabilistic learning techniques to estimate worddependent transition model parameters by maximum a posteriori (map) training.	-2	75
machine translation system	a machine translation system includes a database for storing various information, database management section for performing database management, a bilingual correspondence data record subsystem for performing recording/learning processing of translation examples, a translation subsystem for performing translation processing, and dictionary management utilities for performing dictionary management and database transmission/reception processing. the bilingual correspondence data recording section records english and japanese bilingual correspondences by using english and japanese sentences stored in the same file or different files. the recorded bilingual correspondences are linked in units of parts by a bilingual correspondence learning section. in performing translation, an englishtojapanese translation section and the like generate a translation of an original sentence as a translation target by using parts and the like which have undergone learning/recording processing. the dictionary management utilities perform database transmission/reception processing to/from another machine translation system.	-16	99
robust machine translation evaluation with entailment features	existing evaluation metrics for machine translation lack crucial robustness their correlations with hu man quality judgments vary considerably across lan guages and genres. we believe that the main reason is their inability to properly capturemeaning a good translation candidate means the same thing as the reference translation, regardless of formulation. we propose a metric that evaluates mt output based on a rich set of features motivated by textual entailment, such as lexicalsemantic (in)compatibility and ar gument structure overlap. we compare this metric against a combination metric of four stateofthe art scores (bleu, nist, ter, and meteor) in two different settings. the combination metric out performs the individual scores, but is bested by the entailmentbased metric. combining the entailment and traditional features yields further improvements.	-4	66
platform-independent automated machine translation system	a client computer program designed to run in operating systems with various primary character sets is provided. the client computer program further allows the user to choose a preferred destination for translated documents. for example, the translation can be appended to the original document, written into a new document, sent to the clipboard, or turned out to any other supported destination according to the specifications of the user. in addition, the client computer program provides a translation job queue window that lists documents awaiting analysis and transmission for translation. through the translation job queue window, the user can dynamically add to and delete from the translation job queue, as well as suspend or reorder jobs, and open completed files directly from the list. furthermore, the user can choose to display either the requested translation alone or the requested translation together with the untranslated email message in the same window. finally, the client computer program interacts with an email program so that the user can initiate translation directly from the email program's user interface.	-10	88
syntactic preprocessing for statistical machine translation	we describe an approach to automatic sourcelanguage syntactic preprocessing in the context of arabicenglish phrasebased machine translation. sourcelanguage labeled dependencies, that are word aligned with target language words in a parallel corpus, are used to automatically extract syntactic reordering rules in the same spirit of xia and mccord (2004) and zhang et al. (2007). the extracted rules are used to reorder the sourcelanguage side of the training and test data. our results show that when using monotonic decoding and translations for unigram sourcelanguage phrases only, sourcelanguage reordering gives very significant gains over no reordering (25% relative increase in bleu score). with decoder distortion turned on and with access to all phrase translations, the differences in bleu scores are diminished. however, an analysis of sentencelevel bleu scores shows reordering outperforms noreordering in over 40% of the sentences. these results suggest that the approach holds big promise but much more work on arabic parsing may be needed.	-6	75
phrase-based backoff models for machine translation of highly inflected languages	we propose a backoff model for phrase based machine translation that translates unseen word forms in foreignlanguage text by hierarchical morphological ab stractions at the word and the phrase level. the model is evaluated on the europarl corpus for germanenglish and finnish english translation and shows improve ments over stateoftheart phrasebased models.	-7	79
using multiple edit distances to automatically rank machine translation output	this paper addresses the challenging problem of automatically evaluating output from machine translation (mt) systems in order to support the developers of these systems. conventional approaches to the problem include methods that automatically assign a rank such as a, b, c, or d to mt output according to a single edit distance between this output and a correct translation example. the single edit distance can be differently designed, but changing its design makes assigning a certain rank more accurate, but another rank less accurate. this inhibits improving accuracy of rank assignment. to overcome this obstacle, this paper proposes an automatic ranking method that, by using multiple edit distances, encodes machinetranslated sentences with a rank assigned by humans into multidimensional vectors from which a classifier of ranks is learned in the form of a decision tree (dt). the proposed method assigns a rank to mt output through the learned dt. the proposed method is evaluated using transcribed texts of real conversations in the travel arrangement domain. experimental results show that the proposed method is more accurate than the singleeditdistancebased ranking methods, in both closed and open tests. moreover, the proposed method could estimate mt quality within 3% error in some cases.	-12	92
towards the use of word stems and suffixes for statistical machine translation	in this paper we present methods for improving the quality of translation from an inflected language into english by making use of partofspeech tags and word stems and suffixes in the source language. results for translations from spanish and catalan into english are presented on the lcstar trilingual corpus which consists of spontaneously spoken dialogues in the domain of travelling and appointment scheduling. results for translation from serbian into english are presented on the assimil language course, the bilingual corpus from unrestricted domain. we achieve up to 5% relative reduction of error rates for spanish and catalan and about 8% for serbian.	-6	75
cross-lingual ontology mapping --- an investigation of the impact of machine translation	ontologies are at the heart of knowledge management and make use of information that is not only written in english but also in many other natural languages. in order to enable knowledge discovery, sharing and reuse of these multilingual ontologies, it is necessary to support ontology mapping despite natural language barriers. this paper examines the soundness of a generic approach that involves machine translation tools and monolingual ontology matching techniques in crosslingual ontology mapping scenarios. in particular, experimental results collected from case studies which engage mappings of independent ontologies that are labeled in english and chinese are presented. based on findings derived from these studies, limitations of this generic approach are discussed. it is shown with evidence that appropriate translations of conceptual labels in ontologies are of crucial importance when applying monolingual matching techniques in crosslingual ontology mapping. finally, to address the identified challenges, a semanticoriented crosslingual ontology mapping (socom) framework is proposed and discussed.	-4	66
translation system, translation communication system, machine translation method, and medium embodying program	a translation means determination section of a translation system determines whether translation processing of language data input from an input section is to be performed in an internal translation section or on an external translation server connected by a communication line through a communication control section. in the latter case, it is also determined what processing the translation server is requested to perform. the translation means determination section flexibly switches between internal processing and processing on the translation server by using information such as a language pair to which translation is applied, the communication line state, and a comparison of abilities between the translation system and the translation server. a translation result of the translation section is output from an output section. this configuration allows easy implementation of function extension viewed from a user while minimizing communication cost and overhead.	-7	79
462 machine translation systems for europe	we built 462 machine translation systems for all language pairs of the acquis communautaire corpus. we report and analyse the performance of these system, and compare them against pivot translation and a number of system combination methods (multipivot, multisource) that are possible due to the available systems. 1	-4	65
statistical machine translation. final report	search all the public and authenticated articles in citeulike. include unauthenticated resultstoo (may include spam) enter a search phrase. you can also specify a citeulike article id(123456),. a doi (doi10.1234/12345678). or a pubmed id (pmid12345678).	-14	93
using lexicalized tags for machine translation	lexicalized tree adjoining grammar (ltag) is an attractive formalism for linguistic description mainly because of its extended domain of locality and its factoring recursion out from the domain of local dependencies (joshi, 1984, kroch and joshi, 1985, abeill茅, 1988). ltag's extended domain of locality enables one to localize syntactic dependencies (such as fillergap), as well as semantic dependencies (such as predicatearguments). the aim of this paper is to show that these properties combined with the lexicalized property of ltag are especially attractive for machine translation. the transfer between two languages, such as french and english, can be done by putting directly into correspondence large elementary universe without going through some interlingual representation and without major changes to the source and target grammars. the underlying formalism from the transfer is synchronous tree adjoining grammars (sheiber and schabes [1990]). transfer rules are stated as correspondences between nodes of trees of large domain of locality which are associated with words. we can thus define lexical transfer rules that avoid the defects of a mere wordtoword approach but still benefit from the simplicity and elegance of a lexical approach.	-23	102
target-text mediated interactive machine translation	the use of machine translation as a tool for professional or other highly skilled translators is for the most part currently limited to postediting arrangements in which the translator invokes mt when desired and then manually cleans up the results. a theoretically promising but hitherto largely unsuccessful alternative to postediting for this application is interactive machine translation (imt), in which the translator and mt system work in tandem. we argue that past failures to make imt viable as a tool for skilled translators have been the result of an infelicitous mode of interaction rather than any inherent flaw in the idea. as a solution, we propose a new style of imt in which the target text under construction serves as the medium of communication between an mt system and its user. we describe the design, implementation, and performance of an automatic word completion system for translators which is intended to demonstrate the feasibility of the proposed approach, albeit in a very rudimentary form.	-16	96
a matching technique in example-based machine translation	this paper addresses an important problem in examplebased machine translation (ebmt), namely how to measure similarity between a sentence fragment and a set of stored examples. a new method is proposed that measures similarity according to both surface structure and content. a second contribution is the use of clustering to make retrieval of the best matching example from the database more efficient. results on a large number of test cases from the celex database are presented.cranias, l; papageorgiou, h; piperidis, s	-19	100
an example-based method for transfer-driven machine translation	this paper presents a method called transferdriven machine translation (tdmt), which utilizes an examplebased framework for various process and combines multilevel knowledge. an examplebased framework can achieve quick processing and consistently describe knowledge. it is useful for spokenlanguage translation, which needs robust and efficient translation. tdmt strengthens the examplebased framework by integrating it with other frameworks. the feasibility of tdmt and the advantages of the examplebased framework have been confirmed with a prototype system, which translates spoken dialog sentences from japanese to english.	-21	102
the use of lexical semantics in interlingual machine translation	this paper describes the lexicalsemantic basis for unitran, an implemented scheme for translating spanish, english, and german bidirectionally. two claims made here are that the current representation handles many distinctions (or divergences ) across languages without recourse to languagespecific rules and that the lexicalsemantic framework provides the basis for a systematic mapping between the interlingua and the syntactic structure. the representation adopted is an extended version of lexical conceptual structure  which is suitable to the task of translating between divergent structures for two reasons (1) it provides an ion  of languageindependent properties from structural idiosyncrasies; and (2) it is compositional  in nature. the lexicalsemantic approach addresses the divergence problem by using a linguistically grounded mapping that has access to parameter settings in the lexicon. we will examine a number of relevant issues including the problem of defining primitives, the issue of interlinguality, the crosslinguistic coverage of the system, and the mapping between the syntactic structure and the interlingua. a detailed example of lexicalsemantic composition will be presented.	-21	102
maxsim: a maximum similarity metric for machine translation evaluation	we propose an automatic machine translation (mt) evaluation metric that calculates a sim ilarity score (based on precision and recall) of a pair of sentences. unlike most metrics, we compute a similarity score between items across the two sentences. we then find a maxi mum weight matching between the items such that each item in one sentence is mapped to at most one item in the other sentence. this general framework allows us to use arbitrary similarity functions between items, and to in corporate different information in our com parison, such as ngrams, dependency rela tions, etc. when evaluated on data from the acl07 mt workshop, our proposed metric achieves higher correlation with human judge ments than all 11 automatic mt evaluation metrics that were evaluated during the work shop.	-5	70
segmentation for english-to-arabic statistical machine translation	in this paper, we report on a set of ini tial results for englishtoarabic statistical machine translation (smt). we show that morphological decomposition of the arabic source is beneficial, especially for smallersize corpora, and investigate different recombina tion techniques. we also report on the use of factored translation models for english toarabic translation.	-5	70
novel reordering approaches in phrase-based statistical machine translation	this paper presents novel approaches to reordering in phrasebased statistical machine translation. we perform consistent reordering of source sentences in training and estimate a statistical translation model. using this model, we follow a phrasebased monotonic machine translation approach, for which we develop an efficient and flexible reordering framework that allows to easily introduce different reordering constraints. in translation, we apply source sentence reordering on word level and use a reordering automaton as input. we show how to compute reordering automata ondemand using ibm or itg constraints, and also introduce two new types of reordering constraints. we further add weights to the reordering automata. we present detailed experimental results and show that reordering significantly improves translation quality.	-8	80
machine translation system	methods and apparatus for machine translation are disclosed. in one embodiment of the invention, information is stored in a memory which is contained in a computer, or some other device. the stored information includes a set of eigens for a number of languages, a crosslanguage eigen dictionary, a pattern dictionary, and a crosslanguage pattern dictionary. the first step of the translation is the conversion of a sentence in a first language to an instantiated pattern form. a corresponding pattern is then found in the crosslanguage pattern dictionary. eigens are then found using the crosslanguage eigen dictionary, and a translation in a second language is assembled.	-10	85
the lrc machine translation system: linguistics research center	sourcelanguage text is analyzed according to phrasestructure grammar rules augmented with procedures incorporating syntactic and semantic restrictions, surface and deep case analysis, and transformations; transformed to targetlanguage structures and lexical items representing an equivalent utterance; then synthesized into targetlanguage text.	-31	106
example-based machine translation using dp-matching between word sequences	summary we propose a new approach to the examplebased machine translation paradigm. first, the proposed approach retrieves the most similar example by carrying out dpmatching of the input sentence and source sentences in an example database while measuring the semantic distances of the words. second, the approach adjusts the gap between the input and the most similar example by using a bilingual dictionary. we demonstrate its high coverage and accuracy through a computational experiment for a limited domain.	-12	88
machine translation system incorporating syntactic dependency treelets into a statistical framework	in one embodiment of the present invention, a decoder receives a dependency tree as a source language input and accesses a set of statistical models that produce outputs combined in a log linear framework. the decoder also accesses a table of treelet translation pairs and returns a target dependency tree based on the source dependency tree, based on access to the table of treelet translation pairs, and based on the application of the statistical models.	-3	59
shallow parsing for portuguese--spanish machine translation	to produce fast, reasonably intelligible and easily correctable translations between related languages, it suffices to use a machine translation strategy which uses shallow parsing techniques to refine what would usually be called wordforword machine translation. this paper describes the application of shallow parsing techniques (morphological analysis, lexical disambiguation, and flat, local parsing) in a portuguese–spanish, spanish–portuguese machine translation system which is currently being developed by our group and is publicly and freely available at http//copacabana.dlsi.ua.es.	-10	84
can crowds build parallel corpora for machine translation systems?	corpus based approaches to machine translation (mt) rely on the availability of parallel corpora. in this paper we explore the effectiveness of mechanical turk for creating parallel corpora. we explore the task of sentence translation, both into and out of a language. we also perform preliminary experiments for the task of phrase translation, where ambiguous phrases are provided to the turker for translation in isolation and in the context of the sentence it originated from.	-3	59
multiple-parts-of-speech disambiguating method and apparatus for machine translation system	a machine translation system comprises input means for inputting a sentence written in a natural language, processor for parsing the input sentence, a word dictionary memory referred to by the processor, and a memory for storing multiplepartsofspeech disambiguating rules in the form of a table. the parts of speech of words capable of functioning as multiple parts of speech should be in the inputted sentence are determined in consideration of an array of the parts of speech by applying the multiplepartsofspeech disambiguating rules. additionally, rate of appearance of each part of speech which the word of the input sentence can function as is previously calculated, and the part of speech which can not be determined by consulting the disambiguating rule table is determined in dependence on whether the rate of appearance exceeds a predetermined threshold value.	-26	102
cross-lingual ontology mapping – an investigation of the impact of machine translation	ontologies are at the heart of knowledge management and make use of information that is not only written in english but also in many other natural languages. in order to enable knowledge discovery, sharing and reuse of these multilingual ontologies, it is necessary to support ontology mapping despite natural language barriers. this paper examines the soundness of a generic approach that involves machine translation tools and monolingual ontology matching techniques in crosslingual ontology mapping scenarios. in particular, experimental results collected from case studies which engage mappings of independent ontologies that are labeled in english and chinese are presented. based on findings derived from these studies, limitations of this generic approach are discussed. it is shown with evidence that appropriate translations of conceptual labels in ontologies are of crucial importance when applying monolingual matching techniques in crosslingual ontology mapping. finally, to address the identified challenges, a semanticoriented crosslingual ontology mapping (socom) framework is proposed and discussed.	-4	64
dialectal to standard arabic paraphrasing to improve arabic-english statistical machine translation	this paper is interested in improving the quality of arabicenglish statistical machine translation (smt) on highly dialectal arabic text using morphological knowledge. we present a lightweight rulebased approach to producing modern standard arabic (msa) paraphrases of dialectal arabic outofvocabulary words and low frequency words. our approach extends an existing msa analyzer with a small number of morphological clitics and transfer rules. the generated paraphrase lattices are input to a stateoftheart phrasebased smt system resulting in improved bleu scores on a blind test set by 0.56 absolute bleu (or 1.5% relative).	-2	54
incremental hypothesis alignment for building confusion networks with application to machine translation system combination	confusion network decoding has been the most successful approach in combining out puts from multiple machine translation (mt) systems in the recent darpa gale and nist open mt evaluations. due to the vary ing word order between outputs from differ ent mt systems, the hypothesis alignment presents the biggest challenge in confusion network decoding. this paper describes an incremental alignment method to build confu sion networks based on the translation edit rate (ter) algorithm. this new algorithm yields significant bleu score improvements over other recent alignment methods on the gale test sets and was used in bbn's submission to the wmt08 shared translation task.	-5	68
syntax-based language models for machine translation	reacttext 435 we propose and evaluate computational techniques for deciphering unknown scripts. we focus on the case in which an unfamiliar script encodes a known language. the decipherment of a brief document or inscription is driven by data about the spoken language. we consider which scripts are easy or hard to decipher, how much data is required, and whether the techniques are robust against language...  /reacttext  reacttext 436   /reacttext [show full ]	-10	83
displaying and correcting method for machine translation system	in a system wherein a first text in a first natural language is translated into a second text in a second natural language; a text displaying and correcting system comprising a first memory area for storing parts of the first text divided in predetermined units, with identifications assigned to the respective parts, and a second memory area for storing predetermined units of the second text corresponding to the aforementioned units of the first text, with the same identifications assigned thereto, so that the first and second texts are simultaneously displayed on a screen of a display unit, and that the text is revised in each unit with identification assigned.	-27	99
online learning for interactive statistical machine translation	stateoftheart machine translation (mt) systems are still far from being perfect. an alternative is the socalled interactive machine translation (imt) framework. in this framework, the knowledge of a human translator is combined with a mt system. the vast majority of the existing work on imt makes use of the wellknown batch learning paradigm. in the batch learning paradigm, the training of the imt system and the interactive translation process are carried out in separate stages. this paradigm is not able to take advantage of the new knowledge produced by the user of the imt system. in this paper, we present an application of the online learning paradigm to the imt framework. in the online learning paradigm, the training and prediction stages are no longer separated. this feature is particularly useful in imt since it allows the user feedback to be taken into account. the online learning techniques proposed here incrementally update the statistical models involved in the translation process. empirical results show the great potential of online learning in the imt framework.	-3	57
e-services translation utilizing machine translation and translation memory	a system and method for translating data from a source language to a target language is provided wherein machine generated target translation of a source sentence is compared to a database of human generated target sentences. if a matching human generated target sentence is found, the human generated target sentence may be used instead of the machine generated sentence, since the human generated target sentence is more likely to be a wellformed sentence than the machine generated sentence. the system and method does not rely on a translation memory containing pairs of sentences in both source and target languages, and minimizes the reliance on a human translator to correct a translation generated by machine translation.	-2	52
translating with examples: a new approach to machine translation	atr interpreting telephony research laboratories sanpeidani, inuidani seikacho, sorakugun kyoto 61902, japan email sumita%atrla.atr.co.jp@uunet.uu.net    this paper proposes examplebased machine translation (ebmt). ebmt retrieves similar examples	-23	100
error detection for statistical machine translation using linguistic features	automatic error detection is desired in the postprocessing to improve machine translation quality. the previous work is largely based on confidence estimation using systembased features, such as word posterior probabilities calculated from nbest lists or word lattices. we propose to incorporate two groups of linguistic features, which convey information from outside machine translation systems, into error detection lexical and syntactic features. we use a maximum entropy classifier to predict translation errors by integrating word posterior probability feature and linguistic features. the experimental results show that 1) linguistic features alone outperform word posterior probability based confidence estimation in error detection; and 2) linguistic features can further provide complementary information when combined with word confidence scores, which collectively reduce the classification error rate by 18.52% and improve the f measure by 16.37%.	-3	58
maxsim: a maximum similarity metric for machine translation evaluation	we propose an automatic machine translation (mt) evaluation metric that calculates a similarity score (based on precision and recall) of a pair of sentences. unlike most metrics, we compute a similarity score between items across the two sentences. we then find a maximum weight matching between the items such that each item in one sentence is mapped to at most one item in the other sentence. this general framework allows us to use arbitrary similarity functions between items, and to incorporate different information in our comparison, such as ngrams, dependency relations, etc. when evaluated on data from the acl07 mt workshop, our proposed metric achieves higher correlation with human judgements than all 11 automatic mt evaluation metrics that were evaluated during the workshop. 漏 2008 association for computational linguistics.	-5	65
stochastic finite-state models for spoken language machine translation	the problem of machine translation can be viewed as consisting of twosubproblems (a) lexical selection and (b) lexical reordering. in thispaper, we propose stochastic finitestate models for these two subproblems. stochastic finitestate models are efficiently learnablefrom data, effective for decoding and are associated with a calculusfor composing models which allows for tight integration of constraintsfrom various levels of language processing. we present a method forlearning stochastic finitestate models for lexical selection andlexical reordering that are trained automatically from pairs of sourceand target utterances. we use this method to develop models forenglish–japanese and english–spanish translation and present the performance of these models for translation on speech and text. we also evaluate the efficacy of such a translation model in the context of a call routing task of unconstrained speech utterances.	-11	85
language model adaptation for statistical machine translation based on information retrieval	language modeling is an important part for both speech recognition and machine translation systems. adaptation has been successfully applied to language models for speech recognition. in this paper we present experiments concerning language model adaptation for statistical machine translation. we develop a method to adapt language models using information retrieval methods. the adapted language models drastically reduce perplexity over a general language model and we can show that it is possible to improve the translation quality of a statistical machine translation using those adapted language models instead of a general language model.	-9	79
handbook of natural language processing and machine translation: darpa global autonomous language exploitation	this comprehensive handbook, written by leading experts in the field, details the groundbreaking research conducted under the breakthrough gale program  the global autonomous language exploitation within the defense advanced research projects agency (darpa), while placing it in the context of previous research in the fields of natural language and signal processing, artificial intelligence and machine translation. the most fundamental contrast between gale and its predecessor programs was its holistic integration of previously separate or sequential processes. in earlier language research proolive, joseph p; christianson, caitlin; mccary, john	-2	53
machine translation using vector space representations	an embodiment of the present invention provides a method for automatically translating text. first, a conceptual representation space is generated based on sourcelanguage documents and targetlanguage documents, wherein respective terms from the sourcelanguage and targetlanguage documents have a representation in the conceptual representation space. second, a new sourcelanguage document is represented in the conceptual representation space, wherein a subset of terms in the new sourcelanguage document is represented in the conceptual representation space, such that each term in the subset has a representation in the conceptual representation space. then, a term in the new sourcelanguage document is automatically translated into a corresponding targetlanguage term based on a similarity between the representation of the term and the representation of the corresponding targetlanguage term.	-3	56
statistical machine translation gains respect	as business, finance, education, and the internet become increasingly international and multilingual, google and other organizations are investing more time, money, and talent into researching the effectiveness of machinetranslation technologies.	-8	75
generation-heavy hybrid machine translation	this paper describes generationheavy hybrid machine translation (ghmt), a novel approach for trans lating between structurallydivergent language pairs with asymmetrical resources. the approach depends on the existence of rich target language resources such as word lexical semantics, categorial variations and subcategorization frames. these resources are used to overgenerate multiple lexicostructural variations from a targetglossed syntactic dependency representation of the source language sentence. this symbolic overgeneration, which accounts for a wide range of possible variations, is constrained by a statistical targetlanguage model. the exploitation of target language resources (symbolic and statistical) to handle a problem usually reserved for transfer and interlingual mt is useful for translation from source languages with scarce linguistic resources. a preliminary evaluation on the application of this approach to spanishenglish mt is conducted with promising results.	-11	81
a finite-state approach to machine translation	the problem of machine translation can be viewed as consisting of two subproblems (a) lexical selection; (b) lexical reordering. we propose stochastic finitestate models for these two subproblems. stochastic finitestate models are efficiently able to learn from data, effective for decoding and are associated with a calculus for composing models which allows for tight integration of constraints from various levels of language processing. we present a method for learning stochastic finitestate models for lexical choice and lexical reordering that are trained automatically from pairs of source and target utterances. we use this method to develop models for englishjapanese translation and present the performance of these models for translation of speech and text. we also evaluate the efficacy of such a translation model in the context of a call routing task of unconstrained speech utterances.	-12	84
the lrc machine translation system: an overview of the linguistic component of metal	the lrc machine translation system an overview of the linguistic component of metaldoi10.3115/990100.990105winfield s. bennettthe university of texas at austinacademia prahaconference on computational linguisticsbennett, w. and slocum, j., the lrc machine translation system, computational linguistics, vol. 11, no. 23, pp. 111121, 1985....	-31	100
cache-based document-level statistical machine translation	statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time, ignoring documentlevel information. in this paper, we propose a cachebased approach to documentlevel translation. since caches mainly depend on relevant data to supervise subsequent decisions, it is critical to fill the caches with highlyrelevant data of a reasonable size. in this paper, we present three kinds of caches to store relevant documentlevel information 1) a dynamic cache, which stores bilingual phrase pairs from the best translation hypotheses of previous sentences in the test document; 2) a static cache, which stores relevant bilingual phrase pairs extracted from similar bilingual document pairs (i.e. source documents similar to the test document and their corresponding target documents) in the training parallel corpus; 3) a topic cache, which stores the targetside topic words related with the test document in the sourceside. in particular, three new features are designed to explore various kinds of documentlevel information in above three kinds of caches.	-2	51
purest ever example-based machine translation: detailed presentation and assessment	we have designed, implemented and assessed an ebmt system that can be dubbed the 'purest ever built' it strictly does not make any use of variables, templates or patterns, does not have any explicit transfer component, and does not require any preprocessing or training of the aligned examples. it only uses a specific operation, proportional analogy, that implicitly neutralises divergences between languages and captures lexical and syntactical variations along the paradigmatic and syntagmatic axes without explicitly decomposing sentences into fragments. exactly the same genuine implementation of such a core engine was evaluated on different tasks and language pairs. to begin with, we compared our system on two tasks of a previous mt evaluation campaign to rank it among other current stateoftheart systems. then, we illustrated the 'universality' of our system by participating in a recent mt evaluation campaign, with exactly the same core engine, for a wide variety of language pairs. finally, we studied the in uence of extra data like dictionaries and paraphrases on the system performance.	-6	68
cohesive phrase-based decoding for statistical machine translation	phrasebased decoding produces stateofthe art translations with no regard for syntax. we add syntax to this process with a cohesion constraint based on a dependency tree for the source sentence. the constraint allows the decoder to employ arbitrary, nonsyntactic phrases, but ensures that those phrases are translated in an order that respects the source tree's structure. in this way, we target the phrasal decoder's weakness in order model ing, without affecting its strengths. to fur ther increase flexibility, we incorporate cohe sion as a decoder feature, creating a soft con straint. the resulting cohesive, phrasebased decoder is shown to produce translations that are preferred over noncohesive output in both automatic and human evaluations.	-5	64
system and method for machine learning a confidence metric for machine translation	a machine translation system is trained to generate confidence scores indicative of a quality of a translation result. a source string is translated with a machine translator to generate a target string. features indicative of translation operations performed are extracted from the machine translator. a trusted entityassigned translation score is obtained and is indicative of a trusted entityassigned translation quality of the translated string. a relationship between a subset of the extracted features and the trusted entityassigned translation score is identified.	-4	60
neural machine translation of rare words with subword units	neural machine translation (nmt) models typically operate with a fixed vocabulary, but translation is an openvocabulary problem. previous work addresses the translation of outofvocabulary words by backing off to a dictionary. in this paper, we introduce a simpler and more effective approach, making the nmt model capable of openvocabulary translation by encoding rare and unknown words as sequences of subword units. this is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). we discuss the suitability of different word segmentation techniques, including simple character ngram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a backoff dictionary baseline for the wmt 15 translation tasks englishgerman and englishrussian by 1.1 and 1.3 bleu, respectively.	3	169
neural machine translation by jointly learning to align and translate	neural machine translation is a recently proposed approach to machine translation. unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. the models proposed recently for neural machine translation often belong to a family of encoderdecoders and consists of an encoder that encodes a source sentence into a fixedlength vector from which a decoder generates a translation. in this paper, we conjecture that the use of a fixedlength vector is a bottleneck in improving the performance of this basic encoderdecoder architecture, and propose to extend this by allowing a model to automatically (soft)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. with this new approach, we achieve a translation performance comparable to the existing stateoftheart phrasebased system on the task of englishtofrench translation. furthermore, qualitative analysis reveals that the (soft)alignments found by the model agree well with our intuition.	1	1890
on the properties of neural machine translation: encoder-decoder approaches	neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. the neural machine translation models often consist of an encoder and a decoder. the encoder extracts a fixedlength representation from a variablelength input sentence, and the decoder generates a correct translation from this representation. in this paper, we focus on analyzing the properties of the neural machine translation using two models; rnn encoderdecoder and a newly proposed gated recursive convolutional neural network. we show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.	1	467
findings of the 2014 workshop on statistical machine translation	this paper presents the results of the wmt14 shared tasks, which included a standard news translation task, a separate medical translation task, a task for runtime estimation of machine translation quality, and a metrics task. this year, 143 machine translation systems from 23 institutions were submitted to the ten translation directions in the standard translation task. an additional 6 anonymized systems were included, and were then evaluated both automatically and manually. the quality estimation task had four subtasks, with a total of 10 teams, submitting 57 entries	1	391
effective approaches to attention-based neural machine translation	an attentional mechanism has lately been used to improve neural machine translation (nmt) by selectively focusing on parts of the source sentence during translation. however, there has been little work exploring useful architectures for attentionbased nmt. this paper examines two simple and effective classes of attentional mechanism a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. we demonstrate the effectiveness of both approaches over the wmt translation tasks between english and german in both directions. with local attention, we achieve a significant gain of 5.0 bleu points over nonattentional systems which already incorporate known techniques such as dropout. our ensemble model using different attention architectures has established a new stateoftheart result in the wmt'15 english to german translation task with 25.9 bleu points, an improvement of 1.0 bleu points over the existing best system backed by nmt and an ngram reranker.	2	301
google's neural machine translation system: bridging the gap between human and machine translation	neural machine translation (nmt) is an endtoend learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrasebased translation systems. unfortunately, nmt systems are known to be computationally expensive both in training and in translation inference. also, most nmt systems have difficulty with rare words. these issues have hindered nmt's use in practical deployments and services, where both accuracy and speed are essential. in this work, we present gnmt, google's neural machine translation system, which attempts to address many of these issues. our model consists of a deep lstm network with 8 encoder and 8 decoder layers using attention and residual connections. to improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. to accelerate the final translation speed, we employ lowprecision arithmetic during inference computations. to improve handling of rare words, we divide words into a limited set of common subword units (wordpieces) for both input and output. this method provides a good balance between the flexibility of characterdelimited models and the efficiency of worddelimited models.	3	223
on using very large target vocabulary for neural machine translation	neural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrasebased statistical machine translation. despite its recent success, neural machine translation has its limitation in handling a larger vocabulary, as training complexity as well as decoding complexity increase proportionally to the number of target words. in this paper, we propose a method that allows us to use a very large target vocabulary without increasing training complexity, based on importance sampling. we show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. the models trained by the proposed approach are empirically found to outperform the baseline models with a small vocabulary as well as the lstmbased neural machine translation models. furthermore, when we use the ensemble of a few models with very large target vocabularies, we achieve the stateoftheart translation performance (measured by bleu) on the english>german translation and almost as high performance as stateoftheart english>french translation system.	1	188
fast and robust neural network joint models for statistical machine translation	proceedings of the 52nd annual meeting of the association for computational linguistics, pages 1370–1380, baltimore, maryland, usa, june 2325 2014. co2014 association for computational linguisticsfast and robust neural network joint models for statistical machine translationjacob devlin, rabih zbib, zhongqiang huang, thomas lamar, richard schwartz, and john makhoul raytheon bbn technologies, 10 moulton st, cambridge, ma 02138, usa {jdevlin,rzbib,zhuang,tlamar,schwartz,makhoul}@bbn.com recent work	1	234
learning phrase representations using rnn encoder-decoder for statistical machine translation	in this paper, we propose a novel neural network model called rnn encoderdecoder that consists of two recurrent neural networks (rnn). one rnn encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. the encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. the performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the rnn encoderdecoder as an additional feature in the existing loglinear model. qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.	1	1174
modeling coverage for neural machine translation	attention mechanism advanced stateoftheart neural machine translation (nmt) by jointly learning to align and translate. however, attentionbased nmt ignores past alignment information, which often leads to overtranslation and undertranslation. in response to this problem, we maintain a coverage vector to keep track of the attention history. the coverage vector is fed to the attention model to help adjust future attention, which guides nmt to consider more about the untranslated source words. experiments show that the proposed approach significantly improves both translation quality and alignment quality over traditional attentionbased nmt.	3	53
minimum risk training for neural machine translation	we propose minimum risk training for endtoend neural machine translation. unlike conventional maximum likelihood estimation, minimum risk training is capable of optimizing model parameters directly with respect to arbitrary evaluation metrics, which are not necessarily differentiable. experiments show that our approach achieves significant improvements over maximum likelihood estimation on a stateoftheart neural machine translation system across various languages pairs. transparent to architectures, our approach can be applied to more neural networks and potentially benefit more nlp tasks.	2	70
findings of the 2016 conference on machine translation	this paper presents the results of the wmt16 shared tasks, which included five machine translation (mt) tasks (standard news, itdomain, biomedical, multimodal, pronoun), three evaluation tasks (metrics, tuning, runtime estimation of mt qual ity), and an automatic postediting task and bilingual document alignment task. this year, 102 mt systems from 24 in stitutions (plus 36 anonymized online sys tems) were submitted to the 12 translation directions in the news translation task. the itdomain task received 31 submissions from 12 institutions in 7 directions and the biomedical task received 15 submissions systems from 5 institutions. evaluation was both automatic and manual (relative ranking and 100point scale assessments).	3	60
addressing the rare word problem in neural machine translation	neural machine translation (nmt) is a new approach to machine translation that has shown promising results that are comparable to traditional approaches. a significant weakness in conventional nmt systems is their inability to correctly translate very rare words endtoend nmts tend to have relatively small vocabularies with a single unk symbol that represents every possible outofvocabulary (oov) word. in this paper, we propose and implement an effective technique to address this problem. we train an nmt system on data that is augmented by the output of a word alignment algorithm, allowing the nmt system to emit, for each oov word in the target sentence, the position of its corresponding word in the source sentence. this information is later utilized in a postprocessing step that translates every oov word using a dictionary. our experiments on the wmt14 english to french translation task show that this method provides a substantial improvement of up to 2.8 bleu points over an equivalent nmt system that does not use this technique. with 37.5 bleu points, our nmt system is the first to surpass the best result achieved on a wmt14 contest task.	1	156
findings of the 2015 workshop on statistical machine translation	this paper presents the results of the wmt15 shared tasks, which included a standard news translation task, a metrics task, a tuning task, a task for runtime estimation of machine translation quality, and an automatic postediting task. this year, 68 machine translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. an additional 7 anonymized systems were included, and were then evaluated both automatically and manually. the quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. the pilot automatic post editing task had a total of 4 teams, submitting 7 entries.	2	133
optimizing chinese word segmentation for machine translation performance	previous work has shown that chinese word segmentation is useful for machine translation to english, yet the way different segmentation strategies affect mt is still poorly understood. in this paper, we demonstrate that optimizing segment.	3	56
multi-way, multilingual neural machine translation with a shared attention mechanism	we propose multiway, multilingual neural machine translation. the proposed approach enables a single neural translation model to translate between multiple languages, with a number of parameters that grows only linearly with the number of languages. this is made possible by having a single attention mechanism that is shared across all language pairs. we train the proposed multiway, multilingual model on ten language pairs from wmt'15 simultaneously and observe clear performance improvements over models trained on only one language pair. in particular, we observe that the proposed model significantly improves the translation quality of lowresource language pairs.	3	60
improved statistical machine translation for resource-poor languages using related resource-rich languages	we propose a novel languageindependent approach for improving machine translation for resourcepoor languages by exploiting their similarity to resourcerich ones. more precisely, we improve the translation from a resourcepoor source language x_1 into a resourcerich language y given a bitext containing a limited number of parallel sentences for x_1y and a larger bitext for x_2y for some resourcerich language x_2 that is closely related to x_1. this is achieved by taking advantage of the opportunities that vocabulary overlap and similarities between the languages x_1 and x_2 in spelling, word order, and syntax offer (1) we improve the word alignments for the resourcepoor language, (2) we further augment it with additional translation options, and (3) we take care of potential spelling differences through appropriate transliteration. the evaluation for indonesian >english using malay and for spanish > english using portuguese and pretending spanish is resourcepoor shows an absolute gain of up to 1.35 and 3.37 bleu points, respectively, which is an improvement over the best rivaling approaches, while using much less additional data. overall, our method cuts the amount of necessary real training data by a factor of 25.	1	82
a character-level decoder without explicit segmentation for neural machine translation	the existing machine translation systems, whether phrasebased or neural, have relied almost exclusively on wordlevel modelling with explicit segmentation. in this paper, we ask a fundamental question can neural machine translation generate a character sequence without any explicit segmentation? to answer this question, we evaluate an attentionbased encoderdecoder with a subwordlevel encoder and a characterlevel decoder on four language pairsencs, ende, enru and enfi using the parallel corpora from wmt'15. our experiments show that the models with a characterlevel decoder outperform the ones with a subwordlevel decoder on all of the four language pairs. furthermore, the ensembles of neural models with a characterlevel decoder outperform the stateoftheart nonneural machine translation systems on encs, ende and enfi and perform comparably on enru.	3	86
is machine translation ready yet?	the default option of the google translator toolkit (gtt), released in june 2009, is to prefill with machine translation all segments for which a 'no match' has been returned by the memories, while the window clearly advises that most users should not modify this. to confirm whether this approach indeed benefits translators and translation quality, we designed and performed tests whereby trainee translators used the gtt to translate passages from english into chinese either entirely from the source text, or after seeding of empty segments by the google translate engine as recommended. the translations were timed, and their quality assessed by independent experienced markers following australian naati test criteria. our results show that, while time differences were not significant, the machine translation seeded passages were more favourably assessed by the markers in thirty three of fifty six cases. this indicates that, at least for certain tasks and language combinations — and against the received wisdom of translation professionals and translator trainers — translating by proofreading machine translation may be advantageous.	3	43
neural machine translation in linear time	we present a novel neural network for processing sequences. the bytenet is a onedimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. the two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. to address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. the bytenet uses dilation in the convolutional layers to increase its receptive field. the resulting network has two core properties it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. the bytenet decoder attains stateoftheart performance on characterlevel language modelling and outperforms the previous best results obtained with recurrent networks. the bytenet also achieves stateoftheart performance on charactertocharacter machine translation on the englishtogerman wmt translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. we find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens.	3	41
character-based neural machine translation	we introduce a neural machine translation model that views the input and output sentences as sequences of characters rather than words. since wordlevel information provides a crucial source of bias, our input model composes representations of character sequences into representations of words (as determined by whitespace boundaries), and then these are translated using a joint attention/translation model. in the target language, the translation is modeled as a sequence of word vectors, but each word is generated one character at a time, conditional on the previous character generations in each word. as the representation and generation of words is performed at the character level, our model is capable of interpreting and generating unseen word forms. a secondary benefit of this approach is that it alleviates much of the challenges associated with preprocessing/tokenization of the source and target languages. we show that our model can achieve translation results that are on par with conventional wordbased models.	2	70
character-based neural machine translation	neural machine translation (mt) has reached stateoftheart results. however, one of the main challenges that neural mt still faces is dealing with very large vocabularies and morphologically rich languages. in this paper, we propose a neural mt system using characterbased embeddings in combination with convolutional and highway layers to replace the standard lookupbased word representations. the resulting unlimitedvocabulary and affixaware source word embeddings are tested in a stateoftheart neural mt based on an attentionbased bidirectional recurrent neural network. the proposed mt scheme provides improved results even when the source language is not morphologically rich. improvements up to 3 bleu points are obtained in the germanenglish wmt task.	3	47
edinburgh neural machine translation systems for wmt 16	we participated in the wmt 2016 shared news translation task by building neural translation systems for four language pairs, each trained in both directions english2czech, english2german, english2romanian and english2russian. our systems are based on an attentional encoderdecoder, using bpe subword segmentation for openvocabulary translation with a fixed vocabulary. we experimented with using automatic backtranslations of the monolingual news corpus as additional training data, pervasive dropout, and targetbidirectional models. all reported methods give substantial improvements, and we see improvements of 4.311.2 bleu over our baseline systems. in the human evaluation, our systems were the (tied) best constrained system for 7 out of 8 translation directions in which we participated.	3	40
on using monolingual corpora in neural machine translation	recent work on endtoend neural networkbased architectures for machine translation has shown promising results for enfr and ende translation. arguably, one of the major factors behind this success has been the availability of high quality parallel corpora. in this work, we investigate how to leverage abundant monolingual corpora for neural machine translation. compared to a phrasebased and hierarchical baseline, we obtain up to $1.96$ bleu improvement on the lowresource language pair turkishenglish, and $1.59$ bleu on the focused domain task of chineseenglish chat messages. while our method was initially targeted toward such tasks with less parallel data, we show that it also extends to high resource languages such as csen and deen where we obtain an improvement of $0.39$ and $0.47$ bleu scores over the neural machine translation baselines, respectively.	2	58
google's multilingual neural machine translation system: enabling zero-shot translation	we propose a simple solution to use a single neural machine translation (nmt) model to translate between multiple languages. our solution requires no change in the model architecture from our base system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. the rest of the model, which includes encoder, decoder and attention, remains unchanged and is shared across all languages. using a shared wordpiece vocabulary, our approach enables multilingual nmt using a single model without any increase in parameters, which is significantly simpler than previous proposals for multilingual nmt. our method often improves the translation quality of all involved language pairs, even while keeping the total number of model parameters constant. on the wmt'14 benchmarks, a single multilingual model achieves comparable performance for english$\rightarrow$french and surpasses stateoftheart results for english$\rightarrow$german. similarly, a single multilingual model surpasses stateoftheart results for french$\rightarrow$english and german$\rightarrow$english on wmt'14 and wmt'15 benchmarks respectively.	3	49
achieving open vocabulary neural machine translation with hybrid word-character models	nearly all previous work in neural machine translation (nmt) has used quite restricted vocabularies, perhaps with a subsequent method to patch in unknown words. this paper presents a novel wordcharacter solution to achieving open vocabulary nmt. we build hybrid systems that translate mostly at the word level and consult the character components for rare words. our characterlevel recurrent neural networks compute source word representations and recover unknown target words when needed. the twofold advantage of such a hybrid approach is that it is much faster and easier to train than characterbased ones; at the same time, it never produces unknown words as in the case of wordbased models. on the wmt'15 english to czech translation task, this hybrid approach offers a boost of up to +7.9 bleu points over models that do not handle unknown words. our best hybrid system has established a new stateoftheart result with 19.9 bleu score. we demonstrate that our character models can successfully learn to not only generate wellformed words for czech, a highlyinflected language with a very complex vocabulary, but also build correct representations for english source words.	3	51
character-based neural machine translation	neural machine translation (mt) has reached stateoftheart results. however, one of the main challenges that neural mt still faces is dealing with very large vocabularies and morphologically rich languages. in this paper, we propose a neural mt system using characterbased embeddings in combination with convolutional and highway layers to replace the standard lookupbased word representations. the resulting unlimitedvocabulary and affix aware source word embeddings are tested in a stateoftheart neural mt based on an attentionbased bidirectional recurrent neural network. the proposed mt scheme completely avoids the problem of unknown source words and provides improved results even when the source language is not morphologically rich. the number of target words is still limited by the standard wordbased softmax output layer. however the number of unknowns at the output of the translation network is dramatically reduced (by a relative 66%) with a significant overall improvement over both neural and phrasebased baselines. improvements up to 3 bleu points are obtained in the germanenglish wmt task.	3	33
improving neural machine translation models with monolingual data	neural machine translation (nmt) has obtained stateofthe art performance for several language pairs, while only using parallel data for training. targetside monolingual data plays an important role in boosting fluency for phrasebased statistical machine translation, and we investigate the use of monolingual data for nmt. in contrast to previous work, which combines nmt models with separately trained language models, we note that encoderdecoder nmt architectures already have the capacity to learn the same information as a language model, and we explore strategies to train with monolingual data without changing the neural network architecture. by pairing monolingual training data with an automatic backtranslation, we can treat it as additional parallel training data, and we obtain substantial improvements on the wmt 15 task englishgerman (+2.83.7 bleu), and for the lowresourced iwslt 14 task turkish>english (+2.13.4 bleu), obtaining new stateoftheart results. we also show that finetuning on indomain monolingual and parallel data gives substantial improvements for the iwslt 15 task english>german.	2	53
minimum risk training for neural machine translation	we propose minimum risk training for endtoend neural machine translation. unlike conventional maximum likelihood estimation, minimum risk training is capable of optimizing model parameters directly with respect to evaluation metrics. experiments on chineseenglish and englishfrench translation show that our approach achieves significant improvements over maximum likelihood estimation on a stateoftheart neural machine translation system.	3	39
computerized statistical machine translation with phrasal decoder	a computerized system for performing statistical machine translation with a phrasal decoder is provided. the system may include a phrasal decoder trained prior to runtime on a monolingual parallel corpus, the monolingual parallel corpus including a machine translation output of source language documents of a bilingual parallel corpus and a corresponding target human translation output of the source language documents, to thereby learn mappings between the machine translation output and the target human translation output. the system may further include a statistical machine translation engine configured to receive a translation input and to produce a raw machine translation output, at runtime. the phrasal decoder may be configured to process the raw machine translation output, and to produce a corrected translation output based on the learned mappings for display on a display associated with the system.	2	44
neural versus phrase-based machine translation quality: a case study	within the field of statistical machine translation (smt), the neural approach (nmt) has recently emerged as the first technology able to challenge the longstanding dominance of phrasebased approaches (pbmt). in particular, at the iwslt 2015 evaluation campaign, nmt outperformed well established stateoftheart pbmt systems on englishgerman, a language pair known to be particularly hard because of morphology and syntactic differences. to understand in what respects nmt provides better translation quality than pbmt, we perform a detailed analysis of neural versus phrasebased smt outputs, leveraging high quality postedits performed by professional translators on the iwslt data. for the first time, our analysis provides useful insights on what linguistic phenomena are best modeled by neural models  such as the reordering of verbs  while pointing out other aspects that remain to be improved.	3	37
knowledge-based question answering as machine translation	a typical knowledgebased question answering (kbqa) system faces two challenges one is to transform natural language questions into their meaning representations (mrs); the other is to retrieve answers from knowledge bases (kbs) using generated mrs. unlike previous methods which treat them in a cascaded manner, we present a translationbased approach to solve these two tasks in one unified framework. we translate questions to answers based on cyk parsing. answers as translations of the span covered by each cyk cell are obtained by a question translation method, which first generates formal triple queries as mrs for the span based on question patterns and relation expressions, and then retrieves answers from a given kb based on triple queries generated. a linear model is defined over derivations, and minimum error rate training is used to tune feature weights based on a set of questionanswer pairs. compared to a kbqa system using a stateoftheart semantic parser, our method achieves better results.	1	49
bilingually-constrained phrase embeddings for machine translation	we propose bilinguallyconstrained recursive autoencoders (brae) to learn phrase embeddings (compact vector representations for phrases), which can distinguish the phrases in different semantic meanings. the brae is trained with the objective to minimize the semantic distance of translation equivalents and maximize the semantic distance of nontranslation pairs. the learned model can embed any phrase semantically in two languages and can transform semantic space in one language to the other. we evaluate the brae on two endtoend smt tasks (phrase table pruning and translation hypotheses reranking) which need to measure semantic similarity between a source phrase and its translation candidates. extensive experiments show that the brae is spectacularly successful in these two tasks.	1	58
comparative experiments using supervised learning and machine translation for multilingual sentiment analysis	sentiment analysis is the natural language processing task dealing with sentiment detection and classification from texts. in recent years, due to the growth in the quantity and fast spreading of usergenerated contents online and the impact such information has on events, people and companies worldwide, this task has been approached in an important body of research in the field. despite different methods having been proposed for distinct types of text, the research community has concentrated less on developing methods for languages other than english. in the abovementioned context, the present work studies the possibility to employ machine translation systems and supervised methods to build models able to detect and classify sentiment in languages for which less/no resources are available for this task when compared to english, stressing upon the impact of translation quality on the sentiment classification performance. our extensive evaluation scenarios show that machine translation systems are approaching a good level of maturity and that they can, in combination to appropriate machine learning algorithms and carefully chosen features, be used to build sentiment analysis systems that can obtain comparable performances to the one obtained for english.	1	48
dual learning for machine translation	while neural machine translation (nmt) is making good progress in the past two years, tens of millions of bilingual sentence pairs are needed for its training. however, human labeling is very costly. to tackle this training data bottleneck, we develop a duallearning mechanism, which can enable an nmt system to automatically learn from unlabeled data through a duallearning game. this mechanism is inspired by the following observation any machine translation task has a dual task, e.g., englishtofrench translation (primal) versus frenchtoenglish translation (dual); the primal and dual tasks can form a closed loop, and generate informative feedback signals to train the translation models, even if without the involvement of a human labeler. in the duallearning mechanism, we use one agent to represent the model for the primal task and the other agent to represent the model for the dual task, then ask them to teach each other through a reinforcement learning process. based on the feedback signals generated during this process (e.g., the languagemodel likelihood of the output of a model, and the reconstruction error of the original sentence after the primal and dual translations), we can iteratively update the two models until convergence (e.g., using the policy gradient methods). we call the corresponding approach to neural machine translation \emph{dualnmt}.	3	31
lium smt machine translation system for wmt 2010	this paper describes the development of frenchenglish and englishfrench machine translation systems for the 2010 wmt shared task evaluation. these systems were standard phrasebased statistical systems based on the moses decoder, trained on the provided data only. most of our efforts were devoted to the choice and extraction of bilingual data used for training. we filtered out some bilingual corpora and pruned the phrase table. we also investigated the impact of adding two types of additional bilingual texts, extracted automatically from the available monolingual data. we first collected bilingual data by performing automatic translations of monolingual texts. the second type of bilingual text was harvested from comparable corpora with information retrieval techniques.	4	29
nematus: a toolkit for neural machine translation	we present nematus, a toolkit for neural machine translation. the toolkit prioritizes high translation accuracy, usability, and extensibility. nematus has been used to build topperforming submissions to shared translation tasks at wmt and iwslt, and has been used to train systems for production environments.	4	29
opennmt: open-source toolkit for neural machine translation	we describe an opensource toolkit for neural machine translation (nmt). the toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting nmt research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. the toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques.	4	31
linguistic input features improve neural machine translation	neural machine translation has recently achieved impressive results, while using little in the way of external linguistic information. in this paper we show that the strong learning capability of neural mt models does not make linguistic features redundant; they can be easily incorporated to provide further improvements in performance. we generalize the embedding layer of the encoder in the attentional encoderdecoder architecture to support the inclusion of arbitrary features, in addition to the baseline word feature. we add morphological features, partofspeech tags, and syntactic dependency labels as input features to englishgerman, and english>romanian neural machine translation systems. in experiments on wmt16 training and test sets, we find that linguistic input features improve model quality according to three metrics perplexity, bleu and chrf3. an opensource implementation of our neural mt system is available, as are sample files and configurations.	3	31
achieving open vocabulary neural machine translation with hybrid word-character models	reacttext 428 in this paper, we describe fbk's neural machine translation (nmt) systems submitted at the international workshop on spoken language translation (iwslt) 2016. the systems are based on the stateoftheart nmt architecture that is equipped with a bidirectional encoder and an attention mechanism in the decoder. they leverage linguistic information such as lemmas and partofspeech tags of the...  /reacttext  reacttext 429   /reacttext [show full ]	3	29
a recursive recurrent neural network for statistical machine translation	in this paper, we propose a novel recursive recurrent neural network (r2nn) to model the endtoend decoding process for statistical machine translation. r2nn is a combination of recursive neural network and recurrent neural network, and in turn integrates their respective capabilities (1) new information can be used to generate the next hidden state, like recurrent neural networks, so that language model and translation model can be integrated naturally; (2) a tree structure can be built, as recursive neural networks, so as to generate the translation candidates in a bottom up manner. a semisupervised training approach is proposed to train the parameters, and the phrase pair embedding is explored to model translation confidence directly. experiments on a chinese to english translation task show that our proposed r2nn can outperform the stateof theart baseline by about 1.5 points in bleu.	1	46
integrating an unsupervised transliteration model into statistical machine translation	we investigate three methods for integrating an unsupervised transliteration model into an endtoend smt system. we induce a transliteration model from parallel data and use it to translate oov words. our approach is fully unsupervised and language independent. in the methods to integrate transliterations, we observed improvements from 0.230.75 (62 0.41) bleu points across 7 language pairs. we also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora.	1	43
integrating an unsupervised transliteration model into statistical machine translation	reduced mechanical stress to bone in bedridden patients and astronauts leads to bone loss and increase in fracture risk which is one of the major medical and health issues in modern aging society and space medicine. however, no molecule involved in the mechanisms underlying this phenomenon has been identified to date. osteopontin (opn) is one of the major noncollagenous proteins in bone matrix, but its function in mediating physicalforce effects on bone in vivo has not been known. to investigate the possible requirement for opn in the transduction of mechanical signaling in bone metabolism in vivo, we examined the effect of unloading on the bones of opn 61/ 61 mice using a tail suspension model. in contrast to the tail suspension–induced bone loss in wildtype mice, opn 61/ 61 mice did not lose bone. elevation of urinary deoxypyridinoline levels due to unloading was observed in wildtype but not in opn 61/ 61 mice. analysis of the mechanisms of opn deficiency–dependent reduction in bone on the cellular basis resulted in two unexpected findings. first, osteoclasts, which were increased by unloading in wildtype mice, were not increased by tail suspension in opn 61/ 61 mice. second, measures of osteoblastic bone formation, which were decreased in wildtype mice by unloading, were not altered in opn 61/ 61 mice.	1	43
nematus: a toolkit for neural machine translation	reacttext 452 neural machine translation (nmt) models are able to partially learn syntactic information from sequential lexical information. still, some complex syntactic phenomena such as prepositional phrase attachment are poorly modeled. this work aims to answer two questions 1) does explicitly modeling source or target language syntax help nmt? 2) is tight integration of words and syntax better than...  /reacttext  reacttext 453   /reacttext [show full ]	4	26
tree-to-sequence attentional neural machine translation	most of the existing neural machine translation (nmt) models focus on the conversion of sequential data and do not directly take syntax into consideration. we propose a novel endtoend syntactic nmt model, extending a sequencetosequence model with the sourceside phrase structure. our model has an attention mechanism that enables the decoder to generate a translated word while softly aligning it with phrases as well as words of the source sentence. experimental results on the wat'15 englishtojapanese dataset demonstrate that our proposed model outperforms sequencetosequence attentional nmt models and compares favorably with the stateoftheart treetostring smt system.	3	25
coverage embedding models for neural machine translation	in this paper, we enhance the attentionbased neural machine translation (nmt) by adding explicit coverage embedding models to alleviate issues of repeating and dropping translations in nmt. for each source word, our model starts with a full coverage embedding vector to track the coverage status, and then keeps updating it with neural networks as the translation goes. experiments on the largescale chinesetoenglish task show that our enhanced model improves the translation quality significantly on various test sets over the strong large vocabulary nmt system.	3	27
linguistic input features improve neural machine translation	neural machine translation has recently achieved impressive results, while using little in the way of external linguistic information. in this paper we show that the strong learning capability of neural mt models does not make linguistic features redundant; they can be easily incorporated to provide further improvements in performance. we generalize the embedding layer of the encoder in the attentional encoderdecoder architecture to support the inclusion of arbitrary features, in addition to the baseline word feature. we add morphological features, partofspeech tags, and syntactic dependency labels as input features to englishgerman neural machine translation systems. in experiments on wmt16 training and test sets, we find that linguistic input features improve model quality according to three metrics perplexity, bleu and chrf3.	3	26
fully character-level neural machine translation without explicit segmentation	most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens. we introduce a neural machine translation (nmt) model that maps a source character sequence to a target character sequence without any segmentation. we employ a characterlevel convolutional network with maxpooling at the encoder to reduce the length of source representation, allowing the model to be trained at a speed comparable to subwordlevel models while capturing local regularities. our charactertocharacter model outperforms a recently proposed baseline with a subwordlevel encoder on wmt'15 deen and csen, and gives comparable performance on fien and ruen. we then demonstrate that it is possible to share a single characterlevel encoder across multiple languages by training a model on a manytoone translation task. in this multilingual setting, the characterlevel encoder significantly outperforms the subwordlevel encoder on all the language pairs. we observe that on csen, fien and ruen, the quality of the multilingual characterlevel translation even surpasses the models specifically trained on that language pair alone, both in terms of bleu score and human judgment.	4	28
incorporating discrete translation lexicons into neural machine translation	neural machine translation (nmt) often makes mistakes in translating lowfrequency content words that are essential to understanding the meaning of the sentence. we propose a method to alleviate this problem by augmenting nmt systems with discrete translation lexicons that efficiently encode translations of these lowfrequency words. we describe a method to calculate the lexicon probability of the next word in the translation candidate by using the attention vector of the nmt model to select which source word lexical probabilities the model should focus on. we test two methods to combine this probability with the standard nmt probability (1) using it as a bias, and (2) linear interpolation. experiments on two corpora show an improvement of 2.02.3 bleu and 0.130.44 nist score, and faster convergence time.	3	24
deep recurrent models with fast-forward connections for neural machine translation	neural machine translation (nmt) aims at solving machine translation (mt) problems using neural networks and has exhibited promising results in recent years. however, most of the existing nmt models are shallow and there is still a performance gap between a single nmt model and the best conventional mt system. in this work, we introduce a new type of linear connections, named fastforward connections, based on deep long shortterm memory (lstm) networks, and an interleaved bidirectional architecture for stacking the lstm layers. fastforward connections play an essential role in propagating the gradients and building a deep topology of depth 16. on the wmt'14 englishtofrench task, we achieve bleu=37.7 with a single attention model, which outperforms the corresponding single shallow model by 6.2 bleu points. this is the first time that a single nmt model achieves stateoftheart performance and outperforms the best conventional model by 0.7 bleu points. we can still achieve bleu=36.3 even without using an attention mechanism. after special handling of unknown words and model ensembling, we obtain the best score reported to date on this task with bleu=40.4. our models are also validated on the more difficult wmt'14 englishtogerman task.	3	24
encoding source language with convolutional neural network for machine translation	the recently proposed neural network joint model (nnjm) (devlin et al., 2014) augments the ngram target language model with a heuristically chosen source context window, achieving stateoftheart performance in smt. in this paper, we give a more systematic treatment by summarizing the relevant source information through a convolutional architecture guided by the target information. with different guiding signals during decoding, our specifically designed convolution+gating architectures can pinpoint the parts of a source sentence that are relevant to predicting a target word, and fuse them with the context of entire source sentence to form a unified representation. this representation, together with target language words, are fed to a deep neural network (dnn) to form a stronger nnjm. experiments on two nist chineseenglish translation tasks show that the proposed model can achieve significant improvements over the previous nnjm by up to +1.08 bleu points on average	2	32
machine translation instant messaging applications	an instant messaging translation plugin interacts with an instant messaging program to intercept incoming messages and forward these messages to a language translation service. the plugin then displays a translation received from the service along with the original message. this provides translation which can be used by instant messaging users to communicate across language barriers, and without local translation or knowledge of the internal workings of the translation services used. additionally, the translation plugin also provides for manual translation of messages, which allows communication with users who use a different language but do not use the translation plugin. messages are modified before translation in order to correct spelling, to prevent particular words or phrases from being translated, and to change instant messaging language into standard language form. the techniques can be performed on various messaging services, including instant messaging on computers or mobile devices, as well as sms.	1	34
montreal neural machine translation systems for wmt’15	reacttext 555 we propose a neural machine translation architecture that models the surrounding text in addition to the source sentence. these models lead to better performance, both in terms of general translation quality and pronoun prediction, when trained on small corpora, although this improvement largely disappears when trained with a larger corpus. we also discover that attentionbased neural machine...  /reacttext  reacttext 556   /reacttext [show full ]	2	30
syntactically guided neural machine translation	we investigate the use of hierarchical phrasebased smt lattices in endtoend neural machine translation (nmt). weight pushing transforms the hiero scores.	3	23
vocabulary manipulation for neural machine translation	in order to capture rich language phenomena, neural machine translation models have to use a large vocabulary size, which requires high computing time and large memory usage. in this paper, we alleviate this issue by introducing a sentencelevel or batchlevel vocabulary, which is only a very small subset of the full output vocabulary. for each sentence or batch, we only predict the target words in its sentencelevel or batchlevel vocabulary. thus, we reduce both the computing time and the memory usage. our method simply takes into account the translation options of each word or phrase in the source sentence, and picks a very small target vocabulary for each sentence based on a wordtoword translation model or a bilingual phrase library learned from a traditional machine translation model. experimental results on the largescale englishtofrench task show that our method achieves better translation performance by 1 bleu point over the large vocabulary neural machine translation system of jean et al. (2015).	3	20
semi-supervised learning for neural machine translation	while endtoend neural machine translation (nmt) has made remarkable progress recently, nmt systems only rely on parallel corpora for parameter estimation. since parallel corpora are usually limited in quantity, quality, and coverage, especially for lowresource languages, it is appealing to exploit monolingual corpora to improve nmt. we propose a semisupervised approach for training nmt models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. the central idea is to reconstruct the monolingual corpora using an autoencoder, in which the sourcetotarget and targettosource translation models serve as the encoder and decoder, respectively. our approach can not only exploit the monolingual corpora of the target language, but also of the source language. experiments on the chineseenglish dataset show that our approach achieves significant improvements over stateoftheart smt and nmt systems.	3	20
a coverage embedding model for neural machine translation	in this paper, we enhance the attentionbased neural machine translation by adding an explicit coverage embedding model to alleviate issues of repeating and dropping translations in nmt. for each source word, our model starts with a full coverage embedding vector, and then keeps updating it with a gated recurrent unit as the translation goes. all the initialized coverage embeddings and updating matrix are learned in the training procedure. experiments on the largescale chinesetoenglish task show that our enhanced model improves the translation quality significantly on various test sets over the strong large vocabulary nmt system.	3	23
transfer learning for low-resource neural machine translation	the encoderdecoder framework for neural machine translation (nmt) has been shown effective in large data scenarios, but is much less effective for lowresource languages. we present a transfer learning method that significantly improves bleu scores across a range of lowresource languages. our key idea is to first train a highresource language pair (the parent model), then transfer some of the learned parameters to the lowresource pair (the child model) to initialize and constrain training. using our transfer learning method we improve baseline nmt models by an average of 5.6 bleu on four lowresource language pairs. ensembling and unknown word replacement add another 2 bleu which brings the nmt performance on lowresource machine translation close to a strong syntax based machine translation (sbmt) system, exceeding its performance on one language pair. additionally, using the transfer learning model for rescoring, we can improve the sbmt system by an average of 1.3 bleu, improving the stateoftheart on lowresource machine translation.	3	21
is neural machine translation ready for deployment? a case study on 30 translation directions	in this paper we provide the largest published comparison of translation quality for phrasebased smt and neural machine translation across 30 translation directions. for ten directions we also include hierarchical phrasebased mt. experiments are performed for the recently published united nations parallel corpus v1.0 and its large sixway sentencealigned subcorpus. in the second part of the paper we investigate aspects of translation speed, introducing amunmt, our efficient neural machine translation decoder. we demonstrate that current neural machine translation could already be used for inproduction systems when comparing wordspersecond ratios.	3	20
learning from post-editing: online model adaptation for statistical machine translation	using machine translation output as a starting point for human translation has become an increasingly common application of mt.we propose and evaluate three computationally efficient online methods for updating statistical mt systems in a scenario where postedited mt output is constantly being returned to the system (1) adding new rules to the translation model from the postedited content, (2) updating a bayesian language model of the target language that is used by the mt system, and (3) updating the mt system's discriminative parameters with a mira step. individually, these techniques can substantially improve mt quality, even over strong baselines. moreover, we see superadditive improvements when all three techniques are used in tandem.	1	30
customizable machine translation service	embodiments of the present invention provide a system and method for providing a translation service. the method comprises providing a translation interface accessible via a network. the translation interface receives specialized data associated with a domain from a member. a text string written in a source language is received from the member via the translation interface. a domainbased translation engine is selected. the domainbased translation engine may be associated with a source language, a target language, and a domain. the text string is translated into the target language using, at least in part, the selected domainbased translation engine. the translated text string is transmitted to the member via the internet. in some embodiments, a translation memory is generated based on the specialized data.	1	25
optimizing parameters for machine translation	methods, systems, and apparatus, including computer program products, for language translation are disclosed. in one implementation, a method is provided. the method includes accessing a hypothesis space, where the hypothesis space represents a plurality of candidate translations; performing decoding on the hypothesis space to obtain a translation hypothesis that minimizes an expected error in classification calculated relative to an evidence space; and providing the obtained translation hypothesis for use by a user as a suggested translation in a target translation.	1	27
supervised attentions for neural machine translation	in this paper, we improve the attention or alignment accuracy of neural machine translation by utilizing the alignments of training sentence pairs. we simply compute the distance between the machine attentions and the true alignments, and minimize this cost in the training procedure. our experiments on largescale chinesetoenglish task show that our model improves both translation and alignment qualities significantly over the largevocabulary neural machine translation system, and even beats a stateoftheart traditional syntaxbased system.	3	17
edinburgh's phrase-based machine translation systems for wmt-14	this paper describes the university of edinburgh's (uedin) phrasebased submissions to the translation and medical translation shared tasks of the 2014 workshop on statistical machine translation (wmt). we participated in all language pairs. we have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of english, ii) using unsupervised characterbased models to translate unknown words in russianenglish and hindienglish pairs, iii) synthesizing hindi data from closelyrelated urdu data, and iv) building huge language models on the common crawl corpus.	1	26
a shared task on multimodal machine translation and crosslingual image description	this paper introduces and summarises the findings of a new shared task at the in tersection of natural language process ing and computer vision the generation of image descriptions in a target language, given an image and/or one or more de scriptions in a different (source) language. this challenge was organised along with the conference on machine translation (wmt16), and called for system submis sions for two task variants (i) a transla tion task, in which a source language im age description needs to be translated to a target language, (optionally) with addi tional cues from the corresponding image, and (ii) a description generation task, in which a target language description needs to be generated for an image, (optionally) with additional cues from source language descriptions of the same image. in this first edition of the shared task, 16 systems were submitted for the translation task and seven for the image description task, from a total of 10 teams.	3	19
on the elements of an accurate tree-to-string machine translation system	while treetostring (t2s) translation theoretically holds promise for efficient, accurate translation, in previous reports t2s systems have often proven inferior to other machine translation (mt) methods such as phrasebased or hierarchical phrasebased mt. in this paper, we attempt to clarify the reason for this performance gap by investigating a number of peripheral elements that affect the accuracy of t2s systems, including parsing, alignment, and search. based on detailed experiments on the englishjapanese and japanese english pairs, we show how a basic t2s system that performs on par with phrasebased systems can be improved by 2.64.6 bleu, greatly exceeding existing stateof theart methods. these results indicate that t2s systems indeed hold much promise, but the abovementioned elements must be taken seriously in construction of these systems.	1	24
zero-resource translation with multi-lingual neural machine translation	in this paper, we propose a novel finetuning algorithm for the recently introduced multiway, mulitlingual neural machine translate that enables zeroresource machine translation. when used together with novel manytoone translation strategies, we empirically show that this finetuning algorithm allows the multiway, multilingual model to translate a zeroresource language pair (1) as well as a singlepair neural translation model trained with up to 1m direct parallel sentences of the same language pair and (2) better than pivotbased translation strategy, while keeping only one additional copy of attentionrelated parameters.	3	17
mutual information and diverse decoding improve neural machine translation	sequencetosequence neural translation models learn semantic and syntactic relations between sentence pairs by optimizing the likelihood of the target given the source, i.e., $p(y|x)$, an objective that ignores other potentially useful sources of information. we introduce an alternative objective function for neural mt that maximizes the mutual information between the source and target sentences, modeling the bidirectional dependency of sources and targets. we implement the model with a simple reranking method, and also introduce a decoding algorithm that increases diversity in the nbest list produced by the first pass. applied to the wmt german/english and french/english tasks, both mechanisms offer a consistent performance boost on both standard lstm and attentionbased neural mt architectures. the result is the best published performance for a single (nonensemble) neural mt system, as well as the potential application of our diverse decoding algorithm to other nlp reranking tasks.	3	17
agreement-based joint training for bidirectional attention-based neural machine translation	the attentional mechanism has proven to be effective in improving endtoend neural machine translation. however, due to the intricate structural divergence between natural languages, unidirectional attentionbased models might only capture partial aspects of attentional regularities. we propose agreementbased joint training for bidirectional attentionbased endtoend neural machine translation. instead of training sourcetotarget and targettosource translation models independently,our approach encourages the two complementary models to agree on word alignment matrices on the same training data. experiments on chineseenglish and englishfrench translation tasks show that agreementbased joint training significantly improves both alignment and translation quality over independent training.	3	19
systran's pure neural machine translation systems	since the first online demonstration of neural machine translation (nmt) by lisa, nmt development has recently moved from laboratory to production systems as demonstrated by several entities announcing rollout of nmt engines to replace their existing technologies. nmt systems have a large number of training configurations and the training process of such systems is usually very long, often a few weeks, so role of experimentation is critical and important to share. in this work, we present our approach to productionready systems simultaneously with release of online demonstrators covering a large variety of languages (12 languages, for 32 language pairs). we explore different practical choices an efficient and evolutive opensource framework; data preparation; network architecture; additional implemented features; tuning for production; etc. we discuss about evaluation methodology, present our first findings and we finally outline further work. our ultimate goal is to share our expertise to build competitive production systems for generic translation. we aim at contributing to set up a collaborative framework to speedup adoption of the technology, foster further research efforts and enable the delivery and adoption to/by industry of usecase specific engines integrated in real production workflows.	3	14
semi-supervised learning for neural machine translation	while endtoend neural machine translation (nmt) has made remarkable progress recently, nmt systems only rely on parallel corpora for parameter estimation. since parallel corpora are usually limited in quantity, quality, and coverage, especially for lowresource languages, it is appealing to exploit monolingual corpora to improve nmt. we propose a semisupervised approach for training nmt models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. the central idea is to reconstruct the monolingual corpora using an autoencoder, in which the sourcetotarget and targettosource translation models serve as the encoder and decoder, respectively. our approach can not only exploit the monolingual corpora of the target language, but also of the source language. experiments on the chineseenglish dataset show that our approach achieves significant improvements over stateoftheart smt and nmt systems.	3	14
is neural machine translation ready for deployment? a case study on 30 translation directions	reacttext 471 this paper presents a machine translation tool – based on moses – developed for the international maritime organization (imo) for the automatic translation of documents from spanish, french, russian and arabic to/from english. the main challenge lies in the insufficient size of inhouse corpora (especially for russian and arabic). the united nations (un) granted imo the right to use un...  /reacttext  reacttext 472   /reacttext [show full ]	3	15
hybrid simplification using deep semantics and machine translation	we present a hybrid approach to sentence simplification which combines deep semantics and monolingual machine translation to derive simple sentences from complex ones. the approach differs from previous work in two main ways. first, it is semantic based in that it takes as input a deep semantic representation rather than e.g., a sentence or a parse tree. second, it combines a simplification model for splitting and deletion with a monolingual translation model for phrase substitution and reordering. when compared against current state of the art methods, our model yields significantly simpler output that is both grammatical and meaning preserving.	2	21
a sense-based translation model for statistical machine translation	the sense in which a word is used determines the translation of the word. in this paper, we propose a sensebased translation model to integrate word senses into statistical machine translation. we build a broadcoverage sense tagger based on a nonparametric bayesian topic model that automatically learns sense clusters for words in the source language. the proposed sensebased translation model enables the decoder to select appropriate translations for source words according to the inferred senses for these words using maximum entropy classifiers. our method is significantly different from previous word sense disambiguation reformulated for machine translation in that the latter neglects word senses in nature. we test the effectiveness of the proposed sensebased translation model on a largescale chinesetoenglish translation task. results show that the proposed model substantially outperforms not only the baseline but also the previous reformulated word sense disambiguation.	1	23
zero-resource translation with multi-lingual neural machine translation	reacttext 452 researchers in computer science discipline put a great effort for developing machine intelligence techniques, inspired from human intelligence and to cultivate elegant mathematical tools to design …  /reacttext  reacttext 453   /reacttext [more]	3	14
collecting and using comparable corpora for statistical machine translation	lack of sufficient parallel data for many languages and domains is currently one of the major obstacles to further advancement of automated translation. the accurat project is addressing this issue by researching methods how to improve machine translation systems by using comparable corpora. in this paper we present tools and techniques developed in the accurat project that allow additional data needed for statistical machine translation to be extracted from comparable corpora. we present methods and tools for acquisition of comparable corpora from the web and other sources, for evaluation of the comparability of collected corpora, for multilevel alignment of comparable corpora and for extraction of lexical and terminological data for machine translation. finally, we present initial evaluation results on the utility of collected corpora in domainadapted machine translation and reallife applications.	2	20
neural reranking improves subjective quality of machine translation: naist at wat2015	this year, the nara institute of science and technology (naist)'s submission to the 2015 workshop on asian translation was based on syntaxbased statistical machine translation, with the addition of a reranking component using neural attentional machine translation models. experiments reconfirmed results from previous work stating that neural mt reranking provides a large gain in objective evaluation measures such as bleu, and also confirmed for the first time that these results also carry over to manual evaluation. we further perform a detailed analysis of reasons for this increase, finding that the main contributions of the neural models lie in improvement of the grammatical correctness of the output, as opposed to improvements in lexical choice of content words.	2	21
um-corpus: a large english-chinese parallel corpus for statistical machine translation	parallel corpus is a valuable resource for crosslanguage information retrieval and datadriven natural language processing systems,especially for statistical machine translation (smt). however, most existing parallel corpora to chinese are subject to inhouse use,while others are domain specific and limited in size. to a certain degree, this limits the smt research. this paper describes the acquisitionof a large scale and high quality parallel corpora for english and chinese. the corpora constructed in this paper contain about 15 millionenglishchinese (ec) parallel sentences, and more than 2 million training data and 5,000 testing sentences are made publicly available.different from previous work, the corpus is designed to embrace eight different domains. some of them are further categorized intodifferent topics. the corpus will be released to the research community, which is available at the nlp 2 ct 1 website.	1	22
combination of stochastic understanding and machine translation systems for language portability of dialogue systems	in this paper, several approaches for language portability of dialogue systems are investigated with a focus on the spoken language understanding (slu) component. we show that the use of statistical machine translation (smt) can greatly reduce the time and cost of porting an existing system from a source to a target language. using automatically translated training data we study phrasebased machine translation as an alternative to conditional random fields for conceptual decoding to compensate for the loss of a precise conceptword alignment. also two ways to increase slu robustness to translation errors (smeared training data and translation post editing) are shown to improve performance when test data are translated then decoded in the source language. overall the combination of all these approaches allows to reduce even further the concept error rate. experiments were carried out on the french media dialogue corpus with a subset manually translated into italian.	1	22
improved neural machine translation with smt features	neural machine translation (nmt) conducts endtoend translation with a source language encoder and a target language decoder, making promising translation performance. however, as a newly emerged approach, the method has some limitation...	3	14
improving evaluation of machine translation quality estimation	quality estimation evaluation commonly takes the form of measurement of the error that exists between predictions and gold standard labels for a particular test set of translations. issues can arise during comparison of quality estimation prediction score distributions and gold label distributions, however. in this paper, we provide an analysis of methods of comparison and identify areas of concern with respect to widely used measures, such as the ability to gain by prediction of aggregate statistics specific to gold label distributions or by optimally conservative variance in prediction score distributions. as an alternative, we propose the use of the unitfree pearson correlation, in addition to providing an appropriate method of significance testing improvements over a baseline. components ofwmt13 andwmt14 quality estimation shared tasks are replicated to reveal substantially increased conclusivity in system rankings, including identification of outright winners of tasks.	2	18
attention-based multimodal neural machine translation	reacttext 467 in this work, synthesis of facial animation is done by modelling the mapping between facial motion and speech using the shared gaussian process latent variable model. both data are processed separately and subsequently coupled together to yield a shared latent space. this method allows coarticulation to be modelled by having a dynamical model on the latent space. synthesis of novel animation...  /reacttext  reacttext 468   /reacttext [show full ]	3	13
towards zero unknown word in neural machine translation	neural machine translation has shown promising results in recent years. in order to control the com putational complexity, nmt has to employ a small vocabulary, and massive rare words outside the vo cabulary are all replaced with a single unk symbol. besides the inability to translate rare words, this kind of simple approach leads to much increased ambiguity of the sentences since meaningless unks break the structure of sentences, and thus hurts the translation and reordering of the invocabulary words. to tackle this problem, we propose a novel substitutiontranslationrestoration method. in sub stitution step, the rare words in a testing sen tence are replaced with similar invocabulary words based on a similarity model learnt from monolin gual data. in translation and restoration steps, the sentence will be translated with a model trained on new bilingual data with rare words replaced, and finally the translations of the replaced words will be substituted by that of original ones. exper iments on chinesetoenglish translation demon strate that our proposed method can achieve more than 4 bleu points over the attentionbased nmt. when compared to the recently proposed method handling rare words in nmt, our method can also obtain an improvement by nearly 3 bleu points.	3	14
edinburgh’s phrase-based machine translation systems for wmt-14.	this paper describes the university of edinburgh's (uedin) phrasebased submissions to the translation and medical translation shared tasks of the 2014 workshop on statistical machine translation (wmt). we participated in all language pairs. we have improved upon our 2013 system by i) using generalized representations, specifically automatic word clusters for translations out of english, ii) using unsupervised characterbased models to translate unknown words in russianenglish and hindienglish pairs, iii) synthesizing hindi data from closelyrelated urdu data, and iv) building huge language models on the common crawl corpus.	1	20
hybrid simplification using deep semantics and machine translation	we present a hybrid approach to sentence simplification which combines deep semantics and monolingual machine translation to derive simple sentences from complex ones. the approach differs from previous work in two main ways. first, it is semantic based in that it takes as input a deep semantic representation rather than e.g., a sentence or a parse tree. second, it combines a simplification model for splitting and deletion with a monolingual translation model for phrase substitution and reordering. when compared against current state of the art methods, our model yields significantly simpler output that is both grammatical and meaning preserving.	1	21
guided alignment training for topic-aware neural machine translation	in this paper, we propose an effective way for biasing the attention mechanism of a sequencetosequence neural machine translation (nmt) model towards the wellstudied statistical word alignment models. we show that our novel guided alignment training approach improves translation quality on reallife ecommerce texts consisting of product titles and descriptions, overcoming the problems posed by many unknown words and a large type/token ratio. we also show that metadata associated with input texts such as topic or category information can significantly improve translation quality when used as an additional signal to the decoder part of the network. with both novel features, the bleu score of the nmt system on a product title set improves from 18.6 to 21.3%. even larger mt quality gains are obtained through domain adaptation of a general domain nmt system to ecommerce data. the developed nmt system also performs well on the iwslt speech translation task, where an ensemble of four variant systems outperforms the phrasebased baseline by 2.1% bleu absolute.	3	13
overcoming the curse of sentence length for neural machine translation using automatic segmentation	the authors of (cho et al., 2014a) have shown that the recently introduced neural network translation systems suffer from a significant drop in translation quality when translating long sentences, unlike existing phrasebased translation systems. in this paper, we propose a way to address this issue by automatically segmenting an input sentence into phrases that can be easily translated by the neural network translation model. once each segment has been independently translated by the neural machine translation model, the translated clauses are concatenated to form a final translation. empirical results show a significant improvement in translation quality for long sentences.	1	21
learning to generate pseudo-code from source code using statistical machine translation (t)	pseudocode written in natural language can aid the comprehension of source code in unfamiliar programming languages. however, the great majority of source code has no corresponding pseudocode, because pseudocode is redundant and laborious to create. if pseudocode could be generated automatically and instantly from given source code, we could allow for ondemand production of pseudocode without human effort. in this paper, we propose a method to automatically generate pseudocode from source code, specifically adopting the statistical machine translation (smt) framework. smt, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudocode pairs, making it possible to create a pseudocode generator with less human effort. in experiments, we generated english or japanese pseudocode from python statements using smt, and find that the generated pseudocode is largely accurate, and aids code understanding.	2	19
arabic machine translation: a survey	although there is no machine learning technique that fully meets human requirements, finding a quick and efficient translation mechanism has become an urgent necessity, due to the differences between the languages spoken in the world鈥檚 communities and the vast development that has occurred worldwide, as each technique demonstrates its own advantages and disadvantages. thus, the purpose of this paper is to shed light on some of the techniques that employ machine translation available in literature, to encourage researchers to study these techniques. we discuss some of the linguistic characteristics of the arabic language. features of arabic that are related to machine translation are discussed in detail, along with possible difficulties that they might present. this paper summarizes the major techniques used in machine translation from arabic into english, and discusses their strengths and weaknesses.	1	19
neural machine translation with reconstruction	although endtoend neural machine translation (nmt) has achieved remarkable progress in the past two years, it suffers from a major drawback translations generated by nmt systems often lack of adequacy. it has been widely observed that nmt tends to repeatedly translate some source words while mistakenly ignoring other words. to alleviate this problem, we propose a novel encoderdecoderreconstructor framework for nmt. the reconstructor, incorporated into the nmt model, manages to reconstruct the input source sentence from the hidden layer of the output target sentence, to ensure that the information in the source side is transformed to the target side as much as possible. experiments show that the proposed framework significantly improves the adequacy of nmt output and achieves superior translation result over stateoftheart nmt and statistical mt systems.	3	12
fast domain adaptation for neural machine translation	neural machine translation (nmt) is a new approach for automatic translation of text from one human language into another. the basic concept in nmt is to train a large neural network that maximizes the translation performance on a given parallel corpus. nmt is gaining popularity in the research community because it outperformed traditional smt approaches in several translation tasks at wmt and other evaluation tasks/benchmarks at least for some language pairs. however, many of the enhancements in smt over the years have not been incorporated into the nmt framework. in this paper, we focus on one such enhancement namely domain adaptation. we propose an approach for adapting a nmt system to a new domain. the main idea behind domain adaptation is that the availability of large outofdomain training data and a small indomain training data. we report significant gains with our proposed method in both automatic metrics and a human subjective evaluation metric on two language pairs. with our adaptation method, we show large improvement on the new domain while the performance of our general domain only degrades slightly. in addition, our approach is fast enough to adapt an already trained system to a new domain within few hours without the need to retrain the nmt model on the combined data which usually takes several days/weeks depending on the volume of the data.	3	13
massive exploration of neural machine translation architectures	neural machine translation (nmt) has shown remarkable progress over the past few years with production systems now being deployed to endusers. one major drawback of current architectures is that they are expensive to train, typically requiring days to weeks of gpu time to converge. this makes exhaustive hyperparameter search, as is commonly done with other neural network architectures, prohibitively expensive. in this work, we present the first largescale analysis of nmt architecture hyperparameters. we report empirical results and variance numbers for several hundred experimental runs, corresponding to over 250,000 gpu hours on the standard wmt english to german translation task. our experiments lead to novel insights and practical advice for building and extending nmt architectures. as part of this contribution, we release an opensource nmt framework that enables researchers to easily experiment with novel techniques and reproduce state of the art results.	4	13
vocabulary selection strategies for neural machine translation	classical translation models constrain the space of possible outputs by selecting a subset of translation rules based on the input sentence. recent work on improving the efficiency of neural translation models adopted a similar strategy by restricting the output vocabulary to a subset of likely candidates given the source. in this paper we experiment with context and embeddingbased selection methods and extend previous work by examining speed and accuracy tradeoffs in more detail. we show that decoding time on cpus can be reduced by up to 90% and training time by 25% on the wmt15 englishgerman and wmt16 englishromanian tasks at the same or only negligible change in accuracy. this brings the time to decode with a state of the art neural translation system to just over 140 msec per sentence on a single cpu core for englishgerman.	3	12
polish - english speech statistical machine translation systems for the iwslt 2014	in this paper, we attempt to improve statistical machine translation (smt) systems on a very diverse set of language pairs (in both directions) czech  english, vietnamese  english, french  english and german  english. to accomplish this, we performed translation model training, created adaptations of training settings for each language pair, and obtained comparable corpora for our smt systems. innovative tools and data adaptation techniques were employed. the ted parallel text corpora for the iwslt 2015 evaluation campaign were used to train language models, and to develop, tune, and test the system. in addition, we prepared wikipediabased comparable corpora for use with our smt system. this data was specified as permissible for the iwslt 2015 evaluation. we explored the use of domain adaptation techniques, symmetrized word alignment models, the unsupervised transliteration models and the kenlm language modeling tool. to evaluate the effects of different preparations on translation results, we conducted experiments and used the bleu, nist and ter metrics. our results indicate that our approach produced a positive impact on smt quality.	2	17
proceedings of the 15th annual conference of the european association for machine translation	the blood coagulation mechanism consists of a series of concatenated chemical reactions, governed by the coagulation factors present in the blood plasma, after the activation of the clot mechanism. the last reaction corresponds to the fibrinogen conversion into fibrin, followed by the fibrin polymerisation and production of a stable fibrin network. during the clotting process, there is a solgel transformation of the medium. the subject of the present paper is the measurement of the ultrasonic attenuation coefficient for human blood plasma during the coagulation process, in the frequency range of 8 to 22 mhz. the clot was obtained after the procedure to measure the prothrombin time (6512 s) mixing 150 μl of reconstituted lyophilised normal plasma with 300 μl of reconstituted lyophilised thromboplastin immersed in a water bath with the temperature controlled at 36.5°c. the attenuation coefficient for pure plasma remained constant within the measurement period of 10 s and at frequencies of 8, 9, 10, 15, 20, 21 and 22 mhz. on the other hand, there is a detectable timedecay of the attenuation coefficient for samples of plasma going through the coagulation process and at frequencies of 8, 9, 10 and 15 mhz. the timedecay becomes less and less detectable as the frequency increases and it becomes completely undetectable at 20, 21 and 22 mhz.	1	19
log-linear combinations of monolingual and bilingual neural machine translation models for automatic post-editing	this paper describes the submission of the amu (adam mickiewicz university) team to the automatic postediting (ape) task of wmt 2016. we explore the application of neural translation models to the ape problem and achieve good results by treating different models as components in a loglinear model, allowing for multiple inputs (the mtoutput and the source) that are decoded to the same target language (postedited translations). a simple stringmatching penalty integrated within the loglinear model can be used to control for higher faithfulness with regard to the tobecorrected machine translation input. our submission outperforms the uncorrected baseline on the unseen test set by 3.2% ter and +5.5% bleu.	3	12
selection and use of nonstatistical translation components in a statistical machine translation framework	a system with a nonstatistical translation component integrated with a statistical translation component engine. the same corpus may be used for training the statistical engine and also for determining when to use the statistical engine and when to use the translation component. this training may use probabilistic techniques. both the statistical engine and the translation components may be capable of translating the same information, however the system determines which component to use based on the training. retraining can be carried out to add additional components, or when after additional translator training.	1	19
arabic machine translation: a survey	although there is no machine learning technique that fully meets human requirements, finding a quick and efficient translation mechanism has become an urgent necessity, due to the differences between the languages spoken in the world鈥檚 communities and the vast development that has occurred worldwide, as each technique demonstrates its own advantages and disadvantages. thus, the purpose of this paper is to shed light on some of the techniques that employ machine translation available in literature, to encourage researchers to study these techniques. we discuss some of the linguistic characteristics of the arabic language. features of arabic that are related to machine translation are discussed in detail, along with possible difficulties that they might present. this paper summarizes the major techniques used in machine translation from arabic into english, and discusses their strengths and weaknesses.	1	18
factored neural machine translation	we present a new approach for neural machine translation (nmt) using the morphological and grammatical decomposition of the words (factors) in the output side of the neural network. this architecture addresses two main problems occurring in mt, namely dealing with a large target language vocabulary and the out of vocabulary (oov) words. by the means of factors, we are able to handle larger vocabulary and reduce the training time (for systems with equivalent target language vocabulary size). in addition, we can produce new words that are not in the vocabulary. we use a morphological analyser to get a factored representation of each word (lemmas, part of speech tag, tense, person, gender and number). we have extended the nmt approach with attention mechanism in order to have two different outputs, one for the lemmas and the other for the rest of the factors. the final translation is built using some \textit{a priori} linguistic information. we compare our extension with a wordbased nmt system. the experiments, performed on the iwslt'15 dataset translating from english to french, show that while the performance do not always increase, the system can manage a much larger vocabulary and consistently reduce the oov rate. we observe up to 2% bleu point improvement in a simulated out of domain translation setup.	3	11
variational neural machine translation	models of neural machine translation are often from a discriminative family of encoderdecoders that learn a conditional distribution of a target sentence given a source sentence. in this paper, we propose a variational model to learn this conditional distribution for neural machine translation a variational encoderdecoder model that can be trained endtoend. different from the vanilla encoderdecoder model that generates target translations from hidden representations of source sentences alone, the variational model introduces a continuous latent variable to explicitly model underlying semantics of source sentences and to guide the generation of target translations. in order to perform efficient posterior inference and largescale training, we build a neural posterior approximator conditioned on both the source and the target sides, and equip it with a reparameterization technique to estimate the variational lower bound. experiments on both chineseenglish and english german translation tasks show that the proposed variational neural machine translation achieves significant improvements over the vanilla neural machine translation baselines.	3	11
jane: open source machine translation system combination	different machine translation engines can be remarkably dissimilar not only with respect to their technical paradigm, but also with respect to the translation output they yield. system combination is a method for combining the output.	1	16
using discourse structure improves machine translation evaluation	we present experiments in using discourse structure for improving machine translation evaluation. we first design two discourseaware similarity measures, which use allsubtree kernels to compare discourse parse trees in accordance with the rhetorical structure theory. then, we show that these measures can help improve a number of existing machine translation evaluation metrics both at the segmentand at the systemlevel. rather than proposing a single new metric, we show that discourse information is complementary to the stateoftheart evaluation metrics, and thus should be taken into account in the development of future richer evaluation metrics.	1	16
maximal lattice overlap in example-based machine translation	examplebased machine translation (ebmt) retrieves pretranslated phrases from a sentencealigned bilingual training corpus to translate new input sentences. ebmt uses long pretranslated phrases effectively but is subject to disfluencies at phrasal translation boundaries. we address this problem by introducing a novel method that exploits overlapping phrasal translations and the increased confidence in translation accuracy they imply. we specify an efficient algorithm for producing translations using overlap. finally, our empirical analysis indicates that this approach produces higher quality translations than the standard method of ebmt in a peaktopeak comparison.	4	11
exploiting source-side monolingual data in neural machine translation	neural machine translation (nmt) based on the encoderdecoder architecture has recently become a new paradigm. researchers have proven that the targetside monolingual data can greatly enhance the decoder model of nmt. however, the sourceside monolingual data is not fully explored although it should be useful to strengthen the encoder model of nmt, especially when the parallel corpus is far from sufficient. in this paper, we propose two approaches to make full use of the source side monolingual data in nmt. the first ap proach employs the selflearning algorithm to generate the synthetic largescale parallel data for nmt training. the second approach ap plies the multitask learning framework using two nmts to predict the translation and the reordered sourceside monolingual sentences simultaneously. the extensive experiments demonstrate that the proposed methods ob tain significant improvements over the strong attentionbased nmt.	3	11
neural network based bilingual language model growing for statistical machine translation	since larger ngram language model (lm) usually performs better in statistical machine translation (smt), how to con struct efficient large lm is an important topic in smt. however, most of the ex isting lm growing methods need an extra monolingual corpus, where additional lm adaption technology is necessary. in this paper, we propose a novel neural network based bilingual lm growing method, only using the bilingual parallel corpus in smt. the results show that our method can im prove both the perplexity score for lm e valuation and bleu score for smt, and significantly outperforms the existing lm growing methods without extra corpus.	1	16
don’t until the final verb wait: reinforcement learning for simultaneous machine translation	reacttext 434 we describe an approach to domain adaptation that is appropriate exactly in the case when one has enough ``target'' data to do slightly better than just using only ``source'' data. our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of perl!) and outperforms stateoftheart approaches on a range of datasets. moreover, it is trivially extended to a...  /reacttext  reacttext 435   /reacttext [show full ]	1	17
neural machine translation with supervised attention	the attention mechanisim is appealing for neural machine translation, since it is able to dynam ically encode a source sentence by generating a alignment between a target word and source words. unfortunately, it has been proved to be worse than conventional alignment models in aligment accuracy. in this paper, we analyze and explain this issue from the point view of re ordering, and propose a supervised attention which is learned with guidance from conventional alignment models. experiments on two chinesetoenglish translation tasks show that the super vised attention mechanism yields better alignments leading to substantial gains over the standard attention based nmt.	3	10
coverage-based neural machine translation	however, attentional nmt ignores past alignment information, which leads to overtranslation and undertranslation problems. in response to this problem, we maintain a coverage vector to keep track of the attention history. the coverage vector is fed to the attention model to help adjust the future attention, which guides nmt to pay more attention to the untranslated source words. experiments show that coveragebased nmt significantly improves both alignment and translation quality over nmt without coverage.	3	10
edinburgh's statistical machine translation systems for wmt16	this paper describes the university of ed inburgh's phrasebased and syntaxbased submissions to the shared translation tasks of the acl 2016 first conference on ma chine translation (wmt16). we sub mitted five phrasebased and five syntax based systems for the news task, plus one phrasebased system for the biomedical task.	3	10
pragmatic neural language modelling in machine translation	this paper presents an indepth investigation on integrating neural language models in translation systems. scaling neural language models is a difficult task, but crucial for realworld applications. this paper evaluates the impact on endtoend mt quality of both new and existing scaling techniques. we show when explicitly normalising neural models is necessary and what optimisation tricks one should use in such scenarios. we also focus on scalable training algorithms and investigate noise contrastive estimation and diagonal contexts as sources for further speed improvements. we explore the tradeoffs between neural models and backoff ngram models and find that neural models make strong candidates for natural language applications in memory constrained environments, yet still lag behind traditional models in raw translation quality. we conclude with a set of recommendations one should follow to build a scalable neural language model for mt.	2	14
incorporating pronoun function into statistical machine translation	pronouns are used frequently in language, and perform a range of functions. some pronouns are used to express coreference, and others are not. languages and genres differ in how and when they use pronouns and this poses a problem for statistical machine translation (smt) systems (le nagard and koehn, 2010; hardmeier and federico, 2010; novák, 2011; guillou, 2012; weiner, 2014; hardmeier, 2014). attention to date has focussed on coreferential (anaphoric) pronouns with np antecedents, which when translated from english into a language with grammatical gender, must agree with the translation of the head of the antecedent. despite growing attention to this problem, little progress has been made, and little attention has been given to other pronouns. the central claim of this thesis is that pronouns performing different functions in text should be handled differently by smt systems and when evaluating pronoun translation. this motivates the introduction of a new framework to categorise pronouns according to their function anaphoric/cataphoric reference, event reference, extratextual reference, pleonastic, addressee reference, speaker reference, generic reference, or other function.	3	10
proceedings of the second workshop on statistical machine translation	the special challenge of the wmt 2007 shared task was domain adaptation. we took this opportunity to experiment with various ways of adapting a statistical machine translation systems to a special domain (here news commentary), when most of the training data is from a different domain (here european parliament speeches). this paper also gives a description of the submission of the university of edinburgh to the shared task.	2	13
assessing the discourse factors that influence the quality of machine translation	we present a study of aspects of discourse structure  specifically discourse devices used to organize information in a sentence that significantly impact the quality of machine translation. our analysis is based on manual evaluations of translations of news from chinese and arabic to english. we find that there is a particularly strong mismatch in the notion of what constitutes a sentence in chinese and english, which occurs often and is associated with significant degradation in translation quality. also related to lower translation quality is the need to employ multiple explicit discourse connectives (because, but, etc.), as well as the presence of ambiguous discourse connectives in the english translation. furthermore, the mismatches between discourse expressions across languages significantly impact translation quality.	1	14
an empirical analysis of data selection techniques in statistical machine translation.	[en] domain adaptation has recently gained interest in statistical machine translation. one of the adaptation techniques is based in the selection data. data selection aims to select the best subset of the bilingual sentences from an available pool of sentences, with which to train a smt system. in this paper, we study how affect the bilingual corpora used for the data selection methods in the translation quality	2	14
neural machine translation with external phrase memory	in this paper, we propose phrasenet, a neural machine translator with a phrase memory which stores phrase pairs in symbolic form, mined from corpus or specified by human experts. for any given source sentence, phrasenet scans the phrase memory to determine the candidate phrase pairs and integrates tagging information in the representation of source sentence accordingly. the decoder utilizes a mixture of wordgenerating component and phrasegenerating component, with a specifically designed strategy to generate a sequence of multiple words all at once. the phrasenet not only approaches one step towards incorporating external knowledge into neural machine translation, but also makes an effort to extend the wordbyword generation mechanism of recurrent neural network. our empirical study on chinesetoenglish translation shows that, with carefullychosen phrase table in memory, phrasenet yields 3.45 bleu improvement over the generic neural machine translator.	3	9
syntax-aware neural machine translation using ccg	neural machine translation (nmt) models are able to partially learn syntactic information from sequential lexical information. still, some complex syntactic phenomena such as prepositional phrase attachment are poorly modeled. this work aims to answer two questions 1) does explicitly modeling source or target language syntax help nmt? 2) is tight integration of words and syntax better than multitask training? we introduce syntactic information in the form of ccg supertags either in the source as an extra feature in the embedding, or in the target, by interleaving the target supertags with the word sequence. our results on wmt data show that explicitly modeling syntax improves machine translation quality for englishgerman, a highresource pair, and for englishromanian, a lowresource pair and also several syntactic phenomena including prepositional phrase attachment. furthermore, a tight coupling of words and syntax improves translation quality more than multitask training.	4	9
embedding word similarity with neural machine translation	neural language models learn word representations, or embeddings, that capture rich linguistic and conceptual information. here we investigate the embeddings learned by neural machine translation models, a recentlydeveloped class of neural language model. we show that embeddings from translation models outperform those learned by monolingual models at tasks that require knowledge of both conceptual similarity and lexicalsyntactic role. we further show that these effects hold when translating from both english to french and english to german, and argue that the desirable properties of translation embeddings should emerge largely independently of the source and target languages. finally, we apply a new method for training neural translation models with very large vocabularies, and show that this vocabulary expansion algorithm results in minimal degradation of embedding quality. our embedding spaces can be queried in an online demo and downloaded from our web page. overall, our analyses indicate that translationbased embeddings should be used in applications that require concepts to be organised according to similarity and/or lexical function, while monolingual embeddings are better suited to modelling (nonspecific) interword relatedness.	1	14
a convolutional encoder model for neural machine translation	the prevalent approach to neural machine translation relies on bidirectional lstms to encode the source sentence. in this paper we present a faster and simpler architecture based on a succession of convolutional layers. this allows to encode the entire source sentence simultaneously compared to recurrent networks for which computation is constrained by temporal dependencies. on wmt'16 englishromanian translation we achieve competitive accuracy to the stateoftheart and we outperform several recently published results on the wmt'15 englishgerman task. our models obtain almost the same accuracy as a very deep lstm setup on wmt'14 englishfrench translation. our convolutional encoder speeds up cpu decoding by more than two times at the same or higher accuracy as a strong bidirectional lstm baseline.	3	9
standardizing tweets with character-level machine translation	this paper presents the results of the standardization procedure of slovene tweets that are full of colloquial, dialectal and foreignlanguage elements. with the aim of minimizing the human input required we produced a manually normalized lexicon of the most salient outofvocabulary (oov) tokens and used it to train a characterlevel statistical machine translation system (csmt). best results were obtained by combining the manually constructed lexicon and csmt as fallback with an overall improvement of 9.9% increase on all tokens and 31.3% on oov tokens. manual preparation of data in a lexicon manner has proven to be more efficient than normalizing running text for the task at hand. finally we performed an extrinsic evaluation where we automatically lemmatized the test corpus taking as input either original or automatically standardized wordforms, and achieved 75.1% pertoken accuracy with the former and 83.6% with the latter, thus demonstrating that standardization has significant benefits for upstream processing.	1	14
adaptation of machine translation for multilingual information retrieval in the medical domain	we investigate machine translation (mt) of user search queries in the context of crosslingual information retrieval (ir) in the medical domain. the main focus is on techniques to adapt mt to increase translation quality; however, we also explore mt adaptation to improve effectiveness of crosslingual ir. our mt system is moses, a stateoftheart phrasebased statistical machine translation system. the ir system is based on the bm25 retrieval model implemented in the lucene search engine. the mt techniques employed in this work include indomain training and tuning, intelligent training data selection, optimization of phrase table configuration, compound splitting, and exploiting synonyms as translation variants. the ir methods include morphological normalization and using multiple translation variants for query expansion. the experiments are performed and thoroughly evaluated on three language pairs czech–english, german–english, and french–english. mt quality is evaluated on data sets created within the khresmoi project and ir effectiveness is tested on the clef ehealth 2013 data sets.	1	14
learning to parse and translate improves neural machine translation	there has been relatively little attention to incorporating linguistic prior to neural machine translation. much of the previous work was further constrained to considering linguistic prior on the source side. in this paper, we propose a hybrid model, called nmt+rnng, that learns to parse and translate by combining the recurrent neural network grammar into the attentionbased neural machine translation. our approach encourages the neural machine translation model to incorporate linguistic prior during training, and lets it translate on its own afterward. extensive experiments with four language pairs show the effectiveness of the proposed nmt+rnng.	4	9
an empirical comparison of simple domain adaptation methods for neural machine translation	in this paper, we propose a novel domain adaptation method named mixed fine tuning for neural machine translation (nmt). we combine two existing approaches namely fine tuning and multi domain nmt. we first train an nmt model on an outofdomain parallel corpus, and then fine tune it on a parallel corpus which is a mix of the indomain and outofdomain corpora. all corpora are augmented with artificial tags to indicate specific domains. we empirically compare our proposed method against fine tuning and multi domain methods and discuss its benefits and shortcomings.	4	9
machine translation: mining text for social theory	more of the social world lives within electronic text than ever before, from collective activity on the web, social media, and instant messaging to online trans.	3	8
neural machine translation with recurrent attention modeling	knowing which words have been attended to in previous time steps while generating a translation is a rich source of information for predicting what words will be attended to in the future. we improve upon the attention model of bahdanau et al. (2014) by explicitly modeling the relationship between previous and subsequent attention levels for each word using one recurrent network per input word. this architecture easily captures informative features, such as fertility and regularities in relative distortion. in experiments, we show our parameterization of attention improves translation quality.	3	8
neural machine translation advised by statistical machine translation	neural machine translation (nmt) is a new approach to machine translation that has made great progress in recent years. however, recent studies show that nmt generally produces fluent but inadequate translations (tu et al. 2016b; tu et al. 2016a; he et al. 2016; tu et al. 2017). this is in contrast to conventional statistical machine translation (smt), which usually yields adequate but nonfluent translations. it is natural, therefore, to leverage the advantages of both models for better translations, and in this work we propose to incorporate smt model into nmt framework. more specifically, at each decoding step, smt offers additional recommendations of generated words based on the decoding information from nmt (e.g., the generated partial translation and attention history). then we employ an auxiliary classifier to score the smt recommendations and a gating function to combine the smt recommendations with nmt generations, both of which are jointly trained within the nmt architecture in an endtoend manner. experimental results on chineseenglish translation show that the proposed approach achieves significant and consistent improvements over stateoftheart nmt and smt systems on multiple nist test sets.	3	9
towards string-to-tree neural machine translation	we present a simple method to incorporate syntactic information about the target language in a neural machine translation system by translating into linearized, lexicalized constituency trees. an experiment on the wmt16 germanenglish news translation task resulted in an improved bleu score when compared to a syntaxagnostic nmt baseline trained on the same dataset. an analysis of the translations from the syntaxaware system shows that it performs more reordering during translation in comparison to the baseline. a smallscale human evaluation also showed an advantage to the syntaxaware system.	4	9
doubly-attentive decoder for multi-modal neural machine translation	we introduce a multimodal neural machine translation model in which a doublyattentive decoder naturally incorporates spatial visual features obtained using pretrained convolutional neural networks, bridging the gap between image description and translation. our decoder learns to attend to sourcelanguage words and parts of an image independently by means of two separate attention mechanisms as it generates words in the target language. we find that our model can efficiently exploit not just backtranslated indomain multimodal data but also large generaldomain textonly mt corpora. we also report stateoftheart results on the multi30k data set.	4	8
nmtpy: a flexible toolkit for advanced neural machine translation systems	in this paper, we present nmtpy, a flexible python toolkit based on theano for training neural machine translation and other neural sequencetosequence architectures. nmtpy decouples the specification of a network from the training and inference utilities to simplify the addition of a new architecture and reduce the amount of boilerplate code to be written. nmtpy has been used for lium's topranked submissions to wmt multimodal machine translation and news translation tasks in 2016 and 2017.	4	8
context-dependent word representation for neural machine translation 	we first observe a potential weakness of continuous vector representations of symbols in neural machine translation. that is, the continuous vector representation, or a word embedding vector, of a symbol encodes multiple dimensions of similarity, equivalent to encoding more than one meaning of the word. this has the consequence that the encoder and decoder recurrent networks in neural machine translation need to spend substantial amount of their capacity in disambiguating source and target words based on the context which is defined by a source sentence. based on this observation, in this paper we propose to contextualize the word embedding vectors using a nonlinear bagofwords representation of the source sentence. additionally, we propose to represent special tokens (such as numbers, proper nouns and acronyms) with typed symbols to facilitate translating those words that are not wellsuited to be translated via continuous vectors. the experiments on en–fr and en–de reveal that the proposed approaches of contextualization and symbolization improves the translation quality of neural machine translation systems significantly.	4	8
systems and methods for tuning parameters in statistical machine translation	a method for tuning translation parameters in statistical machine translation based on ranking of the translation parameters is disclosed. according to one embodiment, the method includes sampling pairs of candidate translation units from a set of candidate translation units corresponding to a source unit, each candidate translation unit corresponding to numeric values assigned to one or more features, receiving an initial weighting value for each feature, comparing the pairs of candidate translation units to produce binary results, and using the binary results to adjust the initial weighting values to produce modified weighting values.	1	13
bilingual continuous-space language model growing for statistical machine translation	larger ngram language models (lms) perform better in statistical machine translation (smt). however, the existing approaches have two main drawbacks for constructing larger lms 1) it is not convenient to obtain larger corpora in the same domain as the bilingual parallel corpora in smt; 2) most of the previous studies focus on monolingual information from the target corpora only, and redundant ngrams have not been fully utilized in smt. nowadays, continuousspace language model (cslm), especially neural network language model (nnlm), has been shown great improvement in the estimation accuracies of the probabilities for predicting the target words. however, most of these cslm and nnlm approaches still consider monolingual information only or require additional corpus. in this paper, we propose a novel neural network based bilingual lm growing method. compared to the existing approaches, the proposed method enables us to use bilingual parallel corpus for lm growing in smt. the results show that our new method outperforms the existing approaches on both smt performance and computational efficiency significantly.	2	11
the operation sequence model – combining n-gram-based and phrase-based statistical machine translation	in this article, we present a novel machine translation model, the operation sequence model (osm), which combines the benefits of phrasebased and ngrambased statistical machine translation (smt) and remedies their drawbacks. the model represents the translation process as a linear sequence of operations. the sequence includes not only translation operations but also reordering operations. as in ngrambased smt, the model is (i) based on minimal translation units, (ii) takes both source and target information into account, (iii) does not make a phrasal independence assumption, and (iv) avoids the spurious phrasal segmentation problem. as in phrasebased smt, themodel (i) has the ability to memorize lexical reordering triggers, (ii) builds the search graph dynamically, and (iii) decodes with large translation units during search. the unique properties of the model are (i) its strong coupling of reordering and translation where translation and reordering decisions are conditioned on n previous translation and reordering decisions, and (ii) the ability to model local and longrange reorderings consistently.	2	12
machine translation for query expansion	methods, systems and apparatus, including computer program products, for expanding search queries. one method includes receiving a search query, selecting a synonym of a term in the search query based on a context of occurrence of the term in the received search query, the synonym having been derived from statistical machine translation of the term, and expanding the received search query with the synonym and using the expanded search query to search a collection of documents. alternatively, another method includes receiving a request to search a corpus of documents, the request specifying a search query, using statistical machine translation to translate the specified search query into an expanded search query, the specified search query and the expanded search query being in the same natural language, and in response to the request, using the expanded search query to search a collection of documents.	2	11
eu-bridge mt: combined machine translation	this paper describes one of the collaborative efforts within eubridge to further advance the state of the art in machine translation between two european language pairs, german→english and english→german. three research institutes involved in the eubridge project combined their individual machine translation systems and participated with a joint setup in the shared translation task of the evaluation campaign at the acl 2014 eighth workshop on statistical machine translation (wmt 2014). we combined up to nine different machine translation engines via system combination. rwth aachen university, the university of edinburgh, and karlsruhe institute of technology developed several individual systems which serve as system combination input. we devoted special attention to building syntaxbased systems and combining them with the phrasebased ones. the joint setups yield empirical gains of up to 1.6 points in bleu and 1.0 points in ter on the wmt newstest2013 test set compared to the best single systems.	1	12
submodularity for data selection in machine translation	we introduce submodular optimization to the problem of training data subset selection for statistical machine translation (smt). by explicitly formulating data selection as a submodular program, we ob tain fast scalable selection algorithms with mathematical performance guarantees, re sulting in a unified framework that clarifies existing approaches and also makes both new and many previous approaches easily accessible. we present a new class of submodular functions designed specifically for smt and evaluate them on two differ ent translation tasks. our results show that our best submodular method significantly outperforms several baseline methods, including the widelyused crossentropy based data selection method. in addition, our approach easily scales to large data sets and is applicable to other data selection problems in natural language processing.	1	12
statistical machine translation enhancements through linguistic levels: a survey	machine translation can be considered a highly interdisciplinary and multidisciplinary field because it is approached from the point of view of human trans.	1	12
the edinburgh/jhu phrase-based machine translation systems for wmt~2015	this paper describes the submission of the university of edinburgh and the johns hopkins university for the shared translation task of the emnlp 2015 tenth workshop on statistical machine translation (wmt 2015). we set up phrasebased statistical machine translation systems for all ten language pairs of this year鈥檚 evaluation campaign, which are english paired with czech, finnish, french, german, and russian in both translation directions.novel research directions we investigated include neural network language models and bilingual neural network language models, a comprehensive use of word classes, and sparse lexicalized reordering features.	2	11
the edinburgh/jhu phrase-based machine translation systems for wmt 2015	this paper describes the submission of the university of edinburgh and the johns hopkins university for the shared transla tion task of the emnlp 2015 tenth work shop on statistical machine translation (wmt 2015). we set up phrasebased sta tistical machine translation systems for all ten language pairs of this year's evaluation campaign, which are english paired with czech, finnish, french, german, and rus sian in both translation directions.	2	11
phrasal: a toolkit for new directions in statistical machine translation	we present a new version of phrasal, an opensource toolkit for statistical phrasebased machine translation. this revision includes features that support emerging research trends such as (a) tuning with large feature sets, (b) tuning on large datasets like the bitext, and (c) webbased interactive machine translation. a direct comparison with moses shows favorable results in terms of decoding speed and tuning time. 1	1	12
using joint models for domain adaptation in statistical machine translation	joint models have recently shown to improve the stateoftheart in machine translation (mt). we apply embased mixture modeling and data selection techniques using two joint models, namely the operation sequence model or osm — an ngrambased translation and reordering model, and the neural network joint model or nnjm — a continuous space translation model, to carry out domain adaptation for mt. the diversity of the two models, osm with inherit reordering information and nnjm with continuous space modeling makes them interesting to be explored for this task. our contribution in this paper is fusing the existing known techniques (linear interpolation, crossentropy) with the stateoftheart mt models (osm, nnjm). on a standard task of translating germantoenglish and arabictoenglish iwslt ted talks, we observed statistically significant improvements of up to +0.9 bleu points.	2	11
an empirical comparison of features and tuning for phrase-based machine translation	scalable discriminative training methods are now broadly available for estimating phrasebased, featurerich translation models. however, the sparse feature sets typically appearing in research evaluations are less attractive than standard dense features such as language and translation model probabilities they often overfit, do not generalize, or require complex and slow feature extractors. this paper introduces extended features, which are more specific than dense features yet more general than lexicalized sparse features. largescale experiments show that extended features yield robust bleu gains for both arabicenglish (+1.05) and chineseenglish (+0.67) relative to a strong featurerich baseline. we also specialize the feature set to specific data domains, identify an objective function that is less prone to overfitting, and release fast, scalable, and languageindependent tools for implementing the features. 1	1	12
towards string-to-tree neural machine translation	goldberg. towards stringtotree neural machine translation. in acl, 2017.roee aharoni and yoav goldberg. 2017. towards stringtotree neural machine translation. arxiv eprints.aharoni and goldberg 2017] aharoni, r., and goldberg, ...	4	7
machine translation post-editing and effort. empirical studies on the post-editing process	this dissertation investigates the practice of machine translation postediting and the various aspects of effort involved in postediting work. through analyses of edits made by posteditors, the work described here examines three main questions 1) what types of machine translation errors or source text features cause particular effort in postediting, 2) what types of errors can or cannot be corrected without the help of the source text, and 3) how different indicators of effort vary between different posteditors. the dissertation consists of six previously published articles, and an introductory summary. five of the articles report original research, and involve analyses of postediting data to examine questions related to postediting effort as well as differences between posteditors. the sixth article is a survey presenting an overview of the research literature. the research reported is based on multiple datasets consisting of machine translations and their postedited versions, as well as process and evaluation data related to postediting effort. the dissertation presents a mixed methods study combining qualitative and quantitative approaches, as well as theoretical and analytical tools from the fields of language technology and translation studies. data on edits performed by posteditors, postediting time, keylogging data.	3	7
latest trends in hybrid machine translation and its applications	this survey provides a detailed overview of the modification of the standard rulebased architecture to include statistical knowledge, the introduction of rules in corpusbased approaches, and the hybridization of approaches within this last single category. the principal aim here is to cover the leading research and progress in this field of mt and in several related applications.	2	10
an evaluation of machine translation for multilingual sentence-level sentiment analysis	sentiment analysis has become a key tool for several social media applications, including analysis of user's opinions about products and services, support to politics during campaigns and even for market trending. there are multiple existing sentiment analysis methods that explore different techniques, usually relying on lexical resources or learning approaches. despite the large interest on this theme and amount of research efforts in the field, almost all existing methods are designed to work with only english content. most existing strategies in specific languages consist of adapting existing lexical resources, without presenting proper validations and basic baseline comparisons. in this paper, we take a different step into this field. we focus on evaluating existing efforts proposed to do language specific sentiment analysis. to do it, we evaluated twentyone methods for sentencelevel sentiment analysis proposed for english, comparing them with two languagespecific methods. based on nine languagespecific datasets, we provide an extensive quantitative analysis of existing multilanguage approaches. our main result suggests that simply translating the input text on a specific language to english and then using one of the existing english methods can be better than the existing language specific efforts evaluated.	3	7
improving neural machine translation with conditional sequence generative adversarial nets	this paper proposes an approach for applying gans to nmt. we build a conditional sequence generative adversarial net which comprises of two adversarial sub models, a generator and a discriminator. the generator aims to generate sentences which are hard to be discriminated from humantranslated sentences ( i.e., the golden target sentences); and the discriminator makes efforts to discriminate the machinegenerated sentences from humantranslated ones. the two sub models play a minimax game and achieve the winwin situation when they reach a nash equilibrium. additionally, the static sentencelevel bleu is utilized as the reinforced objective for the generator, which biases the generation towards high bleu points. during training, both the dynamic discriminator and the static bleu objective are employed to evaluate the generated sentences and feedback the evaluations to guide the learning of the generator. experimental results show that the proposed model consistently outperforms the traditional rnnsearch and the newly emerged stateoftheart transformer on englishgerman and chineseenglish translation tasks.	4	7
learning to parse and translate improves neural machine translation	reacttext 343 in typical neural machine translation~(nmt), the decoder generates a sentence word by word, packing all linguistic granularities in the same timescale of rnn. in this paper, we propose a new type of decoder for nmt, which splits the decode state into two parts and updates them in two different timescales. specifically, we first predict a chunk timescale state for phrasal modeling, on top of...  /reacttext  reacttext 344   /reacttext [show full ]	4	7
a survey of word reordering in statistical machine translation: computational models and language phenomena	word reordering is one of the most difficult aspects of statistical machine translation (smt), and an important factor of its quality and efficiency. despite the vast amount of research published to date, the interest of the community in this problem has not decreased, and no single method appears to be strongly dominant across language pairs. instead, the choice of the optimal approach for a new translation task still seems to be mostly driven by empirical trials.to orient the reader in this vast and complex research area, we present a comprehensive survey of word reordering viewed as a statistical modeling challenge and as a natural language phenomenon. the survey describes in detail how word reordering is modeled within different stringbased and treebased smt frameworks and as a standalone task, including systematic overviews of the literature in advanced reordering modeling.we then question why some approaches are more successful than others in different language pairs. we argue that besides measuring the amount of reordering, it is important to understand which kinds of reordering occur in a given language pair. to this end, we conduct a qualitative analysis of word reordering phenomena in a diverse sample of language pairs, based on a large collection of linguistic knowledge.	3	7
can machine translation systems be evaluated by the crowd alone	crowdsourced assessments of machine translation quality allow evaluations to be carried out cheaply and on a large scale. it is essential, however, that the crowd's work be filtered to avoid contamination of results through the inclusion of false assessments. one method is to filter via agreement with experts, but even amongst experts agreement levels may not be high. in this paper, we present a new methodology for crowdsourcing human assessments of translation quality, which allows individual workers to develop their own individual assessment strategy. agreement with experts is no longer required, and a worker is deemed reliable if they are consistent relative to their own previous work. individual translations are assessed in isolation from all others in the form of direct estimates of translation quality. this allows more meaningful statistics to be computed for systems and enables significance to be determined on smaller sets of assessments. we demonstrate the methodology's feasibility in largescale human evaluation through replication of the human evaluation component of workshop on statistical machine translation shared translation task for two language pairs, spanishtoenglish and englishtospanish. results for measurement based solely on crowdsourced assessments show system rankings in line with those of the original evaluation.	2	9
temporal attention model for neural machine translation	attentionbased neural machine translation (nmt) models suffer from attention deficiency issues as has been observed in recent research. we propose a novel mechanism to address some of these limitations and improve the nmt attention. specifically, our approach memorizes the alignments temporally (within each sentence) and modulates the attention with the accumulated temporal memory, as the decoder generates the candidate translation. we compare our approach against the baseline nmt model and two other related approaches that address this issue either explicitly or implicitly. largescale experiments on two language pairs show that our approach achieves better and robust gains over the baseline and related nmt approaches. our model further outperforms strong smt baselines in some settings even without using ensembles.	3	7
response-based learning for grounded machine translation	we propose a novel learning approach for statistical machine translation (smt) that allows to extract supervision signals for structured learning from an extrinsic response to a translation input. we show how to generate responses by grounding smt in the task of executing a semantic parse of a translated query against a database. experiments on the geoquery database show an improvement of about 6 points in f1score for responsebased learning over learning from references only on returning the correct answer from a semantic parse of a translated query. in general, our approach alleviates the dependency on human reference translations and solves the reachability problem in structured learning for smt.	1	11
oxlm: a neural language modelling framework for machine translation	this paper presents an open source implementation1 of a neural language model for machine translation. neural language models deal with the problem of data sparsity by learning distributed representations for words in a continuous vector space. the language modelling probabilities are estimated by projecting a word's context in the same space as the word representations and by assigning probabilities proportional to the distance between the words and the context's projection. neural language models are notoriously slow to train and test. our framework is designed with scalability in mind and provides two optional techniques for reducing the computational cost the socalled class decomposition trick and a training algorithm based on noise contrastive estimation. our models may be extended to incorporate direct ngram features to learn weights for every ngram in the training data. our framework comes with wrappers for the cdec and moses translation toolkits, allowing our language models to be incorporated as normalized features in their decoders (inside the beam search).	1	11
sentence level dialect identification for machine translation system selection	reacttext 526 while modern standard arabic (msa) has many resources, arabic dialects, the primarily spoken local varieties of arabic, are quite impoverished in this regard. in this article, we present adam (analyzer for dialectal arabic morphology). adam is a poor man’s solution to quickly develop morphological analyzers for dialectal arabic. adam has roughly half the outofvocabulary rate of a...  /reacttext  reacttext 527   /reacttext [show full ]	1	11
involving language professionals in the evaluation of machine translation	significant breakthroughs in machine translation only seem possible if human translators are taken into the loop. while automatic evaluation and scoring mechanisms such as bleu have enabled the fast development of systems, it is not clear how systems can meet realworld (quality) requirements in industrial translation scenarios today. tara x u project paves the way for wide usage of hybrid machine translation outputs through various feedback loops in system development. in a consortium of research and industry partners, taraxu project integrates human translators into the development process for rating and postediting of machine translation outputs collecting feedback for possible improvements.	1	11
modelling and optimizing on syntactic n-grams for statistical machine translation	the role of language models in smt is to promote fluent translation output, but traditional ngram language models are unable to capture fluency phenomena between distant words, such as some morphological agreement phenomena, subcategorisation, and syntactic collocations with stringlevel gaps. syntactic language models have the potential to fill this modelling gap. we propose a language model for dependency structures that is relational rather than configurational and thus particularly suited for languages with a (relatively) free word order. it is trainable with neural networks, and not only improves over standard ngram language models, but also outperforms related syntactic language models. we empirically demonstrate its effectiveness in terms of perplexity and as a feature function in stringtotree smt from english to german and russian. we also show that using a syntactic evaluation metric to tune the loglinear parameters of an smt system further increases translation quality when coupled with a syntactic language model.	2	9
what’s in a domain? analyzing genre and topic differences in statistical machine translation	reacttext 371 as larger and more diverse parallel texts become available, how can we leverage heterogeneous data to train robust machine translation systems that achieve good translation quality on various test domains? this challenge has been addressed so far by repurposing techniques developed for domain adaptation, such as linear mixture models which combine estimates learned on homogeneous subdomains....  /reacttext  reacttext 372   /reacttext [show full ]	2	9
non-projective dependency-based pre-reordering with recurrent neural network for machine translation	the quality of statistical machine translation performed with phrase based approaches can be increased by permuting the words in the source sentences in an order which resembles that of the target language. we propose a class of recurrent neural models which exploit sourceside dependency syntax features to reorder the words into a targetlike order. we evaluate these models on the germantoenglish and italiantoenglish language pairs, showing significant improvements over a phrasebased moses baseline. we also compare with state of the art germantoenglish prereordering rules, showing that our method obtains similar or better results.	2	9
pushdown automata in statistical machine translation	2014 association for computational linguistics.this article describes the use of pushdown automata (pda) in the context of statistical machine translation and alignment under a synchronous contextfree grammar. we use pdas to compactly represent the space of candidate translations generated by the grammar when applied to an input sentence. generalpurpose pda algorithms for replacement, composition, shortest path, and expansion are presented. we describe hipdt, a hierarchical phrasebased decoder using the pda representation and these algorithms.we contrast the complexity of this decoder with a decoder based on a finite state automata representation, showing that pdas provide a more suitable framework to achieve exact decoding for larger synchronous contextfree grammars and smaller language models. we assess this experimentally on a largescale chinesetoenglish alignment and translation task. in translation, we propose a twopass decoding strategy involving a weaker language model in the firstpass to address the results of pda complexity analysis. we study in depth the experimental conditions and tradeoffs in which hipdt can achieve stateoftheart performance for largescale smt.	1	10
automatic spelling correction for machine translation	methods, systems, and apparatus, including computer program products, for correcting spelling in text. a text input is received for translation. one or more suspect words in the text input are identified. for each suspect word, one or more candidate words are identified. a score for the text input and scores for each of one or more candidate inputs are determined, where each candidate input is the text input with one or more of the suspect words each replaced by a respective candidate word. if any, a candidate input whose score is highest among the scores for the candidate inputs and is greater than the text input score by at least a threshold is selected. otherwise, the text input is selected. a translation of a selected candidate input or the selected text input is provided as the translation of the text input.	1	10
evaluation of machine translation systems at cls corporate language services ag	this paper describes the evaluation of machine translation (mt) system for use in a large company. to take into account the specific requirements of such an environment, a pragmatic approach for the evaluation was developed. it consists of five steps ranging from a specification of the evaluation process to the integration of the chosen mt system in a given infrastructure. the process includes a specification of mt evaluation criteria relevant to systems which have to be employed for a large customer base. the paper also shows the results of such an evaluation study which was recently carried out at cls corporate language services ag, where comprendium is in the meantime being employed as corporate mt system.	1	10
controlling politeness in neural machine translation via side constraints	many languages use honorifics to express politeness, social distance, or the relative social status between the speaker and their addressee(s). in machine translation from a language without honorifics such as english, it is difficult to...	3	6
models and inference for prefix-constrained machine translation	reacttext 435 many phrase alignment models operate over the combinatorial space of bijective phrase alignments. we prove that finding an optimal alignment in this space is nphard, while com puting alignment expectations is #phard. on the other hand, we show that the problem of finding an optimal alignment can be cast as an integer linear program, which provides a simple, declarative approach to viterbi...  /reacttext  reacttext 436   /reacttext [show full ]	3	6
statistical machine translation in the translation curriculum: overcoming obstacles and empowering translators	in this paper we argue that the time is ripe for translator educators to engage with statistical machine translation (smt) in more profound ways than they have done to date. we explain the basic principles of smt and reflect on the role of humans in smt workflows. against a background of diverging opinions on the latter, we argue for a holistic approach to the integration of smt into translator training programmes, one that empowers rather than marginalises translators. we discuss potential barriers to the use of smt by translators generally and in translator training in particular, and propose some solutions to problems thus identified. more specifically, cloudbased services are proposed as a means of overcoming some of the technical and ethical challenges posed by more advanced uses of smt in the classroom. ultimately the paper aims to pave the way for the design and implementation of a new translatororiented smt syllabus at our own university and elsewhere.	1	10
rationalization: a neural machine translation approach to generating natural language explanations	we introduce ai rationalization, an approach for generating explanations of autonomous system behavior as if a human had done the behavior. we describe a rationalization technique that uses neural machine translation to translate internal stateaction representations of the autonomous agent into natural language. we evaluate our technique in the frogger game environment. the natural language is collected from human players thinking out loud as they play the game. we motivate the use of rationalization as an approach to explanation generation, show the results of experiments on the accuracy of our rationalization technique, and describe future research agenda.	4	6
online adaptation to post-edits for phrase-based statistical machine translation	recent research has shown that accuracy and speed of human translators can benefit from postediting output of machine translation systems, with larger benefits for higher quality output.	1	10
incorporating global visual features into attention-based neural machine translation	we introduce multimodal, attentionbased neural machine translation (nmt) models which incorporate visual features into different parts of both the encoder and the decoder. we utilise global image features extracted using a pretrained convolutional neural network and incorporate them (i) as words in the source sentence, (ii) to initialise the encoder hidden state, and (iii) as additional data to initialise the decoder hidden state. in our experiments, we evaluate how these different strategies to incorporate global image features compare and which ones perform best. we also study the impact that adding synthetic multimodal, multilingual data brings and find that the additional data have a positive impact on multimodal models. we report new stateoftheart results and our best models also significantly improve on a comparable phrasebased statistical mt (pbsmt) model trained on the multi30k data set according to all metrics evaluated. to the best of our knowledge, it is the first time a purely neural model significantly improves over a pbsmt model on all metrics evaluated on this data set.	4	6
the new thot toolkit for fully-automatic and interactive statistical machine translation	we present the new thot toolkit for fully automatic and interactive statistical ma chine translation (smt). initial public ver sions of thot date back to 2005 and did only include estimation of phrasebased models. by contrast, the new version of fers several new features that had not been previously incorporated. the key innova tions provided by the toolkit are computer aided translation, including postediting and interactive smt, incremental learn ing and robust generation of alignments at phrase level. in addition to this, the toolkit also provides standard smt fea tures such as fullyautomatic translation, scalable and parallel algorithms for model training, clientserver implementation of the translation functionality, etc. the toolkit can be compiled in unixlike and windows platforms and it is released un der the gnu lesser general public li cense (lgpl).	1	10
bridging neural machine translation and bilingual dictionaries	neural machine translation (nmt) has become the new stateoftheart in several language pairs. however, it remains a challenging problem how to integrate nmt with a bilingual dictionary which mainly contains words rarely or never seen in the bilingual training data. in this paper, we propose two methods to bridge nmt and the bilingual dictionaries. the core idea behind is to design novel models that transform the bilingual dictionaries into adequate sentence pairs, so that nmt can distil latent bilingual mappings from the ample and repetitive phenomena. one method leverages a mixed word/character model and the other attempts at synthesizing parallel sentences guaranteeing massive occurrence of the translation lexicon. extensive experiments demonstrate that the proposed methods can remarkably improve the translation quality, and most of the rare words in the test sentences can obtain correct translations if they are covered by the dictionary.	3	6
compression of neural machine translation models via pruning	neural machine translation (nmt), like many other deep learning domains, typically suffers from overparameterization, resulting in large storage sizes. this paper examines three simple magnitudebased pruning schemes to compress nmt models, namely classblind, classuniform, and classdistribution, which differ in terms of how pruning thresholds are computed for the different classes of weights in the nmt architecture. we demonstrate the efficacy of weight pruning as a compression technique for a stateoftheart nmt system. we show that an nmt model with over 200 million parameters can be pruned by 40% with very little performance loss as measured on the wmt'14 englishgerman translation task. this sheds light on the distribution of redundancy in the nmt architecture. our main result is that with retraining, we can recover and even surpass the original performance with an 80%pruned model.	3	6
memory-enhanced decoder for neural machine translation	we propose to enhance the rnn decoder in a neural machine translator (nmt) with external memory, as a natural but powerful extension to the state in the decoding rnn. this memoryenhanced rnn decoder is called \textsc{memdec}. at each time during decoding, \textsc{memdec} will read from this memory and write to this memory once, both with contentbased addressing. unlike the unbounded memory in previous work\cite{rnnsearch} to store the representation of source sentence, the memory in \textsc{memdec} is a matrix with predetermined size designed to better capture the information important for the decoding process at each time step. our empirical study on chineseenglish translation shows that it can improve by $4.8$ bleu upon groundhog and $5.3$ bleu upon on moses, yielding the best performance achieved with the same training set.	3	6
hume: human ucca-based evaluation of machine translation	human evaluation of machine translation normally uses sentencelevel measures such as relative ranking or adequacy scales. however, these provide no insight into possible errors, and do not scale well with sentence length. we argue for a semanticsbased evaluation, which captures what meaning components are retained in the mt output, thus providing a more finegrained analysis of translation quality, and enabling the construction and tuning of semanticsbased mt. we present a novel human semantic evaluation measure, human uccabased mt evaluation (hume), building on the ucca semantic representation scheme. hume covers a wider range of semantic phenomena than previous methods and does not rely on semantic annotation of the potentially garbled mt output. we experiment with four language pairs, demonstrating hume's broad applicability, and report good interannotator agreement rates and correlation with human adequacy scores.	3	6
toward multilingual neural machine translation with universal encoder and decoder	in this paper, we present our first attempts in building a multilingual neural machine translation framework under a unified approach. we are then able to employ attentionbased nmt for manytomany multilingual translation tasks. our approach does not require any special treatment on the network architecture and it allows us to learn minimal number of free parameters in a standard way of training. our approach has shown its effectiveness in an underresourced translation scenario with considerable improvements up to 2.6 bleu points. in addition, the approach has achieved interesting and promising results when applied in the translation task that there is no direct parallel corpus between source and target languages.	3	6
zero-resource machine translation by multimodal encoder–decoder network with multimedia pivot	we propose an approach to build a neural machine translation system with no supervised resources (i.e., no parallel corpora) using multimodal embedded representation over texts and images. based on the assumption that text documents are often likely to be described with other multimedia information (e.g., images) somewhat related to the content, we try to indirectly estimate the relevance between two languages. using multimedia as the pivot, we project all modalities into one common hidden space where samples belonging to similar semantic concepts should come close to each other, whatever the observed space of each sample is. this modalityagnostic representation is the key to bridging the gap between different modalities. putting a decoder on top of it, our network can flexibly draw the outputs from any input modality. notably, in the testing phase, we need only source language texts as the input for translation. in experiments, we tested our method on two benchmarks to show that it can achieve reasonable translation performance. we compared and investigated several possible implementations and found that an endtoend model that simultaneously optimized both rank loss in multimodal encoders and crossentropy loss in decoders performed the best.	3	6
an evaluation methodology for english to sinhala machine translation	this paper presents evaluation methodology for english to sinhala machine tran slation system. the english to sinhala machine translation system has been developed by using multi agent approach and powered through the concept of “varanegeema”. translation system works through the communication among nine agents namely english morphological analyzer agent, english parser agent, english to sinhala base word translator agent, sinhala morphological generator agent, sinhala parser agent, transliteration agent, intermediate editor agent, message space agent and request agent. the evaluation was conducted through three steps. as the first step, evaluation was conducted through the white box testing approach and tested each module in the machine translation system through the developed testing tools. then, evaluated the system performance and calculated the error rate through the result of the evaluation test bed. finally, intelligibility and the accuracy test will be conducted through the human support. the experimental result shows 89% accuracy of the overall system and 7.2% word error rate and the 5.4% sentence error rate. details of the evaluation and results are given in the paper	3	6
a survey of word reordering in statistical machine translation: computational models and language phenomena	2016. a survey of word reordering in statistical machine translation computational models and language phenomena. computational linguistics, 42.arianna bisazza and marcello federico. 2016. a survey of word reordering in statistical machine ...	3	6
how grammatical is character-level neural machine translation? assessing mt quality with contrastive translation pairs	analysing translation quality in regards to specific linguistic phenomena has historically been difficult and timeconsuming. neural machine translation has the attractive property that it can produce scores for arbitrary translations, and we propose a novel method to assess how well nmt systems model specific linguistic phenomena such as agreement over long distances, the production of novel words, and the faithful translation of polarity. the core idea is that we measure whether a reference translation is more probable under a nmt model than a contrastive translation which introduces a specific type of error. we present lingeval97, a largescale data set of 97000 contrastive translation pairs based on the wmt english>german translation task, with errors automatically created with simple rules. we report results for a number of systems, and find that recently introduced characterlevel nmt systems perform better at transliteration than models with bytepair encoding (bpe) segmentation, but perform more poorly at morphosyntactic agreement, and translating discontiguous units of meaning.	3	6
learning local word reorderings for hierarchical phrase-based statistical machine translation	statistical models for reordering source words have been used to enhance hierarchical phrasebased statistical machine translation. there are existing wordreordering models that learn reorderings for.	3	6
context gates for neural machine translation	in neural machine translation (nmt), generation of a target word depends on both source and target contexts. we find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency. intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. due to the lack of effective control over the influence from source and target contexts, conventional nmt tends to yield fluent but inadequate translations. to address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words. in this way, we can enhance both the adequacy and fluency of nmt with more careful control of the information flow from contexts. experiments show that our approach significantly improves upon a standard attentionbased nmt system by +2.3 bleu points.	4	6
six challenges for neural machine translation	we explore six challenges for neural machine translation domain mismatch, amount of training data, rare words, long sentences, word alignment, and beam search. we show both deficiencies and improvements over the quality of phrasebased statistical machine translation.	4	6
interactive attention for neural machine translation	conventional attentionbased neural machine translation (nmt) conducts dynamic alignment in generating the target sentence. by repeatedly reading the representation of source sentence, which keeps fixed after generated by the encoder (bahdanau et al., 2015), the attention mechanism has greatly enhanced stateoftheart nmt. in this paper, we propose a new attention mechanism, called interactive attention, which models the interaction between the decoder and the representation of source sentence during translation by both reading and writing operations. interactive attention can keep track of the interaction history and therefore improve the translation performance. experiments on nist chineseenglish translation task show that interactive attention can achieve significant improvements over both the previous attentionbased nmt baseline and some stateoftheart variants of attentionbased nmt (i.e., coverage models (tu et al., 2016)). and neural machine translator with our interactive attention can outperform the open source attentionbased nmt system groundhog by 4.22 bleu points and the open source phrasebased system moses by 3.94 bleu points averagely on multiple test sets.	3	6
real time adaptive machine translation for post-editing with cdec and transcenter	as sentences are translated, the models gain valuable context infor mation, allowing them toadapt to the specific tar  on line learning of loglinear weights in interactive ma chine translation online adaptation strategies for statistical machine translation in post editing scenarios	1	9
using syntax-based machine translation to parse english into abstract meaning representation	we present a parser for  meaning representation (amr). we treat englishtoamr conversion within the framework of stringtotree, syntaxbased machine translation (sbmt). to make this work, we transform the amr structure into a form suitable for the mechanics of sbmt and useful for modeling. we introduce an amrspecific language model and add data and features drawn from semantic resources. our resulting amr parser improves upon stateoftheart results by 7 smatch points.	2	8
enhancing statistical machine translation with bilingual terminology in a cat environment	in this paper, we address the problem of extracting and integrating bilingual terminology into a statistical machine translation (smt) system for a computer aided translation (cat) tool scenario. we develop a framework that, taking as input a small amount of parallel indomain data, gathers domainspecific bilingual terms and injects them in an smt system to enhance the translation productivity. therefore, we investigate several strategies to extract and align bilingual terminology, and to embed it into the smt. we compare two embedding methods that can be easily used at runtime without altering the normal activity of an smt system xml markup and the cachebased model. we tested our framework on two different domains showing improvements up to 15% bleu score points.	1	9
bilingual sentiment consistency for statistical machine translation	in this paper, we explore bilingual sentiment knowledge for statistical machine translation (smt). we propose to explicitly model the consistency of sentiment between the source and target side with a lexiconbased approach. the experiments show that the proposed model significantly improves chinesetoenglish nist translation over a competitive baseline.	1	9
dependency-based pre-ordering for chinese-english machine translation	in statistical machine translation (smt), syntaxbased preordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders. this paper introduces a novel preordering approach based on dependency parsing for chineseenglish smt. we present a set of dependencybased preordering rules which improved the bleu score by 1.61 on the nist 2006 evaluation data. we also investigate the accuracy of the rule set by conducting human evaluations.	1	9
optimizing instance selection for statistical machine translation with feature decay algorithms	we introduce fda5 for efficient parameterization, optimization, and implementation of feature decay algorithms (fda), a class of instance selection algorithms that use feature decay. fda increase the diversity of the selected training set by devaluing features (i.e., ngrams) that have already been included. fda5 decides which instances to select based on three functions used for initializing and decaying feature values and scaling sentence scores controlled with five parameters. we present optimization techniques that allow fda5 to adapt these functions to indomain and outofdomain translation tasks for different language pairs. in a transductive learning setting, selection of training instances relevant to the test set can improve the final translation quality. in machine translation experiments performed on the 2 million sentence englishgerman section of the europarl corpus, we show that a subset of the training set selected by fda5 can gain up to 3.22 bleu points compared to a randomly selected subset of the same size, can gain up to 0.41 bleu points compared to using all of the available training data using only 15% of it, and can reach within 0.5 bleu points to the full training set result by using only 2.7% of the full training data.	2	8
sentiment classification using machine learning techniques	we consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. using movie reviews as data, we find that standard machine learning techniques definitively outperform humanproduced baselines. however, the three machine learning methods we employed (naive bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topicbased categorization. we conclude by examining factors that make the sentiment classification problem more challenging.	-11	363.5625
biographies, bollywood, boomboxes and blenders: domain adaptation for sentiment classification	automatic sentiment classification has been extensively studied and applied in recent years. however, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. we investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. first, we extend to sentiment classification the recently proposed structural correspondence learning (scl) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original scl algorithm and 46% over a supervised baseline. second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. this measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains.	-6	129.36363636363637
twitter sentiment classification using distant supervision	we introduce a novel approach for automatically classifying the sentiment of twitter messages. these messages are classified as either positive or negative with respect to a query term. this is useful for consumers who want to research the sentiment of products before purchase, or companies that want to monitor the public sentiment of their brands. there is no previous research on classifying sentiment of messages on microblogging services like twitter. we present the results of machine learning algorithms for classifying the sentiment of twitter messages using distant supervision. our training data consists of twitter messages with emoticons, which are used as noisy labels. this type of training data is abundantly available and can be obtained through automated means. we show that machine learning algorithms (naive bayes, maximum entropy, and svm) have accuracy above 80% when trained with emoticon data. this paper also describes the preprocessing steps needed in order to achieve high accuracy. the main contribution of this paper is the idea of using tweets with emoticons for distant supervised learning.	-4	145.88888888888889
domain adaptation for large-scale sentiment classification: a deep learning approach	the exponential increase in the availability of online reviews and recommendations makes sentiment classification an interesting topic in academic and industrial research. reviews can span so many different domains that it is difficult to gather annotated training data for all of them. hence, this paper studies the problem of domain adaptation for sentiment classifiers, hereby a system is trained on labeled reviews from one source domain but is meant to be deployed on another. we propose a deep learning approach which learns to extract a meaningful representation for each review in an unsupervised fashion. sentiment classifiers trained with this highlevel feature representation clearly outperform stateoftheart methods on a benchmark composed of reviews of 4 types of amazon products. furthermore, this method scales well and allowed us to successfully perform domain adaptation on a larger industrialstrength dataset of 22 domains.	-2	84.85714285714286
target-dependent twitter sentiment classification	sentiment analysis on twitter data has attracted much attention recently. in this paper, we focus on targetdependent twitter sentiment classification; namely, given a query, we classify the sentiments of the tweets as positive, negative or neutral according to whether they contain positive, negative or neutral sentiments about that query. here the query serves as the target of the sentiments. the stateoftheart approaches for solving this problem always adopt the targetindependent strategy, which may assign irrelevant sentiments to the given target. moreover, the stateoftheart approaches only take the tweet to be classified into consideration when classifying the sentiment; they ignore its context (i.e., related tweets). however, because tweets are usually short and more ambiguous, sometimes it is not enough to consider only the current tweet for sentiment classification. in this paper, we propose to improve targetdependent twitter sentiment classification by 1) incorporating targetdependent features; and 2) taking related tweets into consideration. according to the experimental results, our approach greatly improves the performance of targetdependent sentiment classification.	-2	79.71428571428571
co-training for cross-lingual sentiment classification	the lack of chinese sentiment corpora limits the research progress on chinese sentiment classification. however, there are many freely available english sentiment corpora on the web. this paper focuses on the problem of crosslingual sentiment classification, which leverages an available english corpus for chi nese sentiment classification by using the eng lish corpus as training data. machine transla tion services are used for eliminating the lan guage gap between the training set and test set, and english features and chinese features are considered as two independent views of the classification problem. we propose a co training approach to making use of unlabeled chinese data. experimental results show the effectiveness of the proposed approach, which can outperform the standard inductive classifi ers and the transductive classifiers.	-4	42.666666666666664
dependency tree-based sentiment classification using crfs with hidden variables	in this paper, we present a dependency treebased method for sentiment classification of japanese and english subjective sentences using conditional random fields with hidden variables. subjective sentences often contain words which reverse the sentiment polarities of other words. therefore, interactions between words need to be considered in sentiment classification, which is difficult to be handled with simple bagofwords approaches, and the syntactic dependency structures of subjective sentences are exploited in our method. in the method, the sentiment polarity of each dependency subtree in a sentence, which is not observable in training data, is represented by a hidden variable. the polarity of the whole sentence is calculated in consideration of interactions between the hidden variables. sumproduct belief propagation is used for inference. experimental results of sentiment classification for japanese and english subjective sentences showed that the method performs better than other methods based on bagoffeatures.	-3	31.875
comparative experiments on sentiment classification for online product reviews	evaluating text fragments for positive and negative subjective expressions  and their strength can be important in applications such as single  or multi document summarization, document ranking, data mining, etc.  this paper looks at a simplified version of the problem classifying  online product reviews into positive and negative classes. we discuss  a series of experiments with different machine learning algorithms in  order to experimentally evaluate various tradeoffs, using approximately  100k product reviews from the web.	-7	30.333333333333332
sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis	we demonstrate that it is possible to perform automatic sentiment classification in the very noisy domain of customer feedback data. we show that by using large feature vectors in combination with feature reduction, we can train linear support vector machines that achieve high classification accuracy on data that present classification challenges even for a human annotator. we also show that, surprisingly, the addition of deep linguistic analysis features to a set of surface level word ngram features contributes consistently to classification accuracy in this domain.	-8	35.76923076923077
using emoticons to reduce dependency in machine learning techniques for sentiment classification	sentiment classification seeks to identify a piece of text according to its author070705s general feeling toward their subject, be it positive or negative. traditional machine learning techniques have been applied to this problem with reasonable success, but they have been shown to work well only when there is a good match between the training and test data with respect to topic. this paper demonstrates that match with respect to domain and time is also important, and presents preliminary experiments with training data labeled with emoticons, which has the potential of being independent of domain, topic and time.	-4	51.55555555555556
ensemble of feature sets and classification algorithms for sentiment classification	in this paper, we make a comparative study of the effectiveness of ensemble technique for sentiment classification. the ensemble framework is applied to sentiment classification tasks, with the aim of efficiently integrating different feature sets and classification algorithms to synthesize a more accurate classification procedure. first, two types of feature sets are designed for sentiment classification, namely the partofspeech based feature sets and the wordrelation based feature sets. second, three wellknown text classification algorithms, namely na谋篓ve bayes, maximum entropy and support vector machines, are employed as baseclassifiers for each of the feature sets. third, three types of ensemble methods, namely the fixed combination, weighted combination and metaclassifier combination, are evaluated for three ensemble strategies. a wide range of comparative experiments are conducted on five widelyused datasets in sentiment classification. finally, some indepth discussion is presented and conclusions are drawn about the effectiveness of ensemble technique for sentiment classification.	-2	31.428571428571427
feature ensemble plus sample selection: domain adaptation for sentiment classification	domain adaptation problems often arise often in the field of sentiment classification. here, the feature ensemble plus sample selection (ssfe) approach is proposed, which takes labeling and instance adaptation into account. a feature ensemble (fe) model is first proposed to learn a new labeling function in a feature reweighting manner. furthermore, a pcabased sample selection (pcass) method is proposed as an aid to fe. experimental results show that the proposed ssfe approach could gain significant improvements, compared to fe or pcass, because of its comprehensive consideration of both labeling adaptation and instance adaptation.	0	29.4
a non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge	sentiment classication refers to the task of automatically identifying whether a given piece of text expresses positive or negative opinion towards a subject at hand. the proliferation of usergenerated web content such as blogs, discussion forums and online review sites has made it possi ble to perform largescale mining of pub lic opinion. sentiment modeling is thus becoming a critical component of market intelligence and social media technologies that aim to tap into the collective wis dom of crowds. in this paper, we consider the problem of learning highquality senti ment models with minimal manual super vision. we propose a novel approach to learn from lexical prior knowledge in the form of domainindependent sentiment laden terms, in conjunction with domain dependent unlabeled data and a few la beled documents. our model is based on a constrained nonnegative trifactorization of the termdocument matrix which can be implemented using simple update rules. extensive experimental studies demon strate the effectiveness of our approach on a variety of realworld sentiment predic tion tasks.	-4	18.666666666666668
cross-domain sentiment classification using a sentiment sensitive thesaurus	automatic classification of sentiment is important for numerous applications such as opinion mining, opinion summarization, contextual advertising, and market analysis. typically, sentiment classification has been modeled as the problem of training a binary classifier using reviews annotated for positive or negative sentiment. however, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is costly. applying a sentiment classifier trained using labeled data for a particular domain to classify sentiment of user reviews on a different domain often results in poor performance because words that occur in the train (source) domain might not appear in the test (target) domain. we propose a method to overcome this problem in crossdomain sentiment classification. first, we create a sentiment sensitive distributional thesaurus using labeled data for the source domains and unlabeled data for both source and target domains. sentiment sensitivity is achieved in the thesaurus by incorporating document level sentiment labels in the context vectors used as the basis for measuring the distributional similarity between words. next, we use the created thesaurus to expand feature vectors during train and test times in a binary classifier.	0	24.8
sentiment classification for movie reviews in chinese by improved semantic oriented approach	sentiment classification aims at mining reviews of customers for a certain product by automatic classifying the reviews into positive or negative opinions. with the fast developing of world wide web applications, sentiment classification would have huge opportunity to help people automatic analysis of customers聮 opinions from the web information. automatic opinion mining will benefit to both consumers and sellers. up to now, it is still a complicated task with great challenge. there are mainly two types of approaches for sentiment classification, machine learning methods and semantic orientation methods. though some pioneer researches explored the approaches for english movie review classification, few jobs have been done on sentiment classification for chinese reviews. the improved semantic approach for sentiment classification on movie reviews written in chinese was proposed in this paper. data experiment shows the capability of this approach.	-7	13.0
a lexicon-enhanced method for sentiment classification: an experiment on online product reviews	as an emerging communication platform, web 2.0 has led the internet to become increasingly usercentric. people are participating in and exchanging opinions through online communitybased social media, such as discussion boards, web forums, and blogs. along with such trends, an increasing amount of usergenerated content containing rich opinion and sentiment information has appeared on the internet. understanding such opinion and sentiment information has become increasingly important for both service and product providers and users because it plays an important role in influencing consumer purchasing decisions.	-3	17.375
automatic seed word selection for unsupervised sentiment classification of chinese text	we describe and evaluate a new method of automatic seed word selection for unsupervised sentiment classification of product reviews in chinese. the whole method is unsupervised and does not require any annotated training data; it only requires information about commonly occurring negations and adverbials. unsupervised techniques are promising for this task since they avoid problems of domaindependency typically associated with supervised methods. the results obtained are close to those of supervised classifiers and sometimes better, up to an f1 of 92%.	-5	14.6
employing personal/impersonal views in supervised and semi-supervised sentiment classification	in this paper, we adopt two views, personal and impersonal views, and systematically employ them in both supervised and semisupervised sentiment classification. here, personal views consist of those sentences which directly express speaker's feeling and preference towards a target object while impersonal views focus on statements towards a target object for evaluation. to obtain them, an unsupervised mining approach is proposed. on this basis, an ensemble method and a cotraining algorithm are explored to employ the two views in supervised and semisupervised sentiment classification respectively. experimental results across eight domains demonstrate the effectiveness of our proposed approach.	-3	16.5
adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification	polarity lexicons have been a valuable re source for sentiment analysis and opinion mining. there are a number of such lexi cal resources available, but it is often sub optimal to use them as is, because general purpose lexical resources do not reflect domainspecific lexical usage. in this pa per, we propose a novel method based on integer linear programming that can adapt an existing lexicon into a new one to re flect the characteristics of the data more directly. in particular, our method collec tivelyconsidersthe relationsamong words and opinionexpressionsto derive the most likely polarity of each lexical item (posi tive, neutral, negative, or negator) for the given domain. experimental results show that our lexicon adaptation technique im proves theperformance offinegrained po larity classification.	-4	15.666666666666666
sentiment classification using phrase patterns	this paper presents a phrase patternbased method in classifying sentiment orientation of text. that is to analyze whether the text expresses a favorable or unfavorable sentiment for a specific subject. in our method, we construct some phrase patterns and calculate their sentiment orientation by unsupervised learning algorithm. when we classify a document, we first add special tags to some words in the text, then match the tags within a sentence with some phrase patterns to get the sentiment orientation of the sentence. at last, we add up the sentiment orientation of each sentence. we classify the text according to this summation. the method achieves an accuracy rate of 86% when used to evaluate sports reviews from some websites.	-9	9.142857142857142
sentiment classification and polarity shifting	polarity shifting marked by various linguistic structures has been a challenge to automatic sentiment classification. in this paper, we propose a machine learning approach to incorporate polarity shifting information into a documentlevel sentiment classification system. first, a feature selection method is adopted to automatically generate the training data for a binary classifier on polarity shifting detection of sentences. then, by using the obtained binary classifier, each document in the original polarity classification training data is split into two partitions, polarityshifted and polarityunshifted, which are used to train two base classifiers respectively for further classifier combination. the experimental results across four different domains demonstrate the effectiveness of our approach.	-3	13.25
selecting attributes for sentiment classification using feature relation networks	a major concern when incorporating large sets of diverse ngram features for sentiment classification is the presence of noisy, irrelevant, and redundant attributes. these concerns can often make it difficult to harness the augmented discriminatory potential of extended feature sets. we propose a rulebased multivariate text feature selection method called feature relation network (frn) that considers semantic information and also leverages the syntactic relationships between ngram features. frn is intended to efficiently enable the inclusion of extended sets of heterogeneous ngram features for enhanced sentiment classification. experiments were conducted on three online review testbeds in comparison with methods used in prior sentiment classification research. frn outperformed the comparison univariate, multivariate, and hybrid feature selection methods; it was able to select attributes resulting in significantly better classification accuracy irrespective of the feature subset sizes. furthermore, by incorporating syntactic information about ngram relations, frn is able to select features in a more computationally efficient manner than many multivariate and hybrid techniques.	-2	16.428571428571427
multi-level structured models for document-level sentiment classification	in this paper, we investigate structured models for documentlevel sentiment classification. when predicting the sentiment of a subjective document (e.g., as positive or negative), it is well known that not all sentences are equally discriminative or informative. but identifying the useful sentences automatically is itself a difficult learning problem. this paper proposes a joint twolevel approach for documentlevel sentiment classification that simultaneously extracts useful (i.e., subjective) sentences and predicts documentlevel sentiment based on the extracted sentences. unlike previous joint learning methods for the task, our approach (1) does not rely on gold standard sentencelevel subjectivity annotations (which may be expensive to obtain), and (2) optimizes directly for documentlevel performance. empirical evaluations on movie reviews and u.s. congressional floor debates show improved performance over previous approaches.	-3	15.0
adding redundant features for crfs-based sentence sentiment classification	in this paper, we present a novel method based on crfs in response to the two special characteristics of contextual dependency and label redundancy in sentence sentiment classification. we try to capture the contextual constraints on sentence sentiment using crfs. through introducing redundant labels into the original sentimental label set and organizing all labels into a hierarchy, our method can add redundant features into training for capturing the label redundancy. the experimental results prove that our method outperforms the traditional methods like nb, svm, maxent and standard chain crfs. in comparison with the cascaded model, our method can effectively alleviate the error propagation among different layers and obtain better performance in each layer.	-5	12.4
multi-domain adaptation for sentiment classification: using multiple classifier combining methods	sentiment classification is very domainspecific and good domain adaptation methods, when the training and testing data are drawn from different domains, are sorely needed. in this paper, we address a new approach to domain adaptation for sentiment classification in which classifiers are adapted for a specific domain with training data from multiple source domains. we call this new approach ‘multidomain adaptation’ and present a multiple classifier system (mcs) framework to describe and understand it. under this framework, we propose a new combining method, called multilabel consensus training (mct), to combine the base classifiers for selecting ‘automaticallylabeled’ samples from unlabeled data in the target domain. the experimental results for sentiment classification show that multidomain adaptation using this method improves adaptation performance.	-4	12.555555555555555
automatically extracting polarity-bearing topics for cross-domain sentiment classification.	joint sentimenttopic (jst) model was previously proposed to detect sentiment and topic simultaneously from text. the only supervision required by jst model learning is domainindependent polarity word priors. in this paper, we modify the jst model by incorporating word polarity priors through modifying the topicword dirichlet priors. we study the polaritybearing topics extracted by jst and show that by augmenting the original feature space with polaritybearing topics, the indomain supervised classifiers learned from augmented feature representation achieve the stateoftheart performance of 95% on the movie review data and an average of 90% on the multidomain sentiment dataset. furthermore, using feature augmentation and selection according to the information gain criteria for crossdomain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. nevertheless, our approach is much simpler and does not require difficult parameter tuning.	-2	13.285714285714286
mine the easy, classify the hard: a semi-supervised approach to automatic sentiment classification	supervised polarity classification systems are typically domainspecific. building these systems involves the expensive pro cess of annotating a large amount of data for each domain. a potential solution to this corpus annotation bottleneck is to build unsupervised polarity classification systems. however, unsupervised learning of polarity is difficult, owing in part to the prevalence of sentimentally ambiguous re views, where reviewers discuss both the positive and negative aspects of a prod uct. to address this problem, we pro pose a semisupervised approach to senti ment classification where we first mine the unambiguous reviews using spectral tech niques and then exploit them to classify the ambiguous reviews via a novel com bination of active learning, transductive learning, and ensemble learning.	-4	12.666666666666666
using multiple sources to construct a sentiment sensitive thesaurus for cross-domain sentiment classification	we describe a sentiment classication method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. we automatically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to nd the association between words that express similar sentiments in different domains. the created thesaurus is then used to expand feature vectors to train a binary classier. unlike previous crossdomain sentiment classication methods, our method can efciently learn from multiple source domains. our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous crossdomain sentiment classication methods on a benchmark dataset containing amazon user reviews for different types of products.	-2	13.857142857142858
multi-domain sentiment classification	this paper addresses a new task in sentiment classification, called multidomain sentiment classification, that aims to improve perform ance through fusing training data from multi ple domains. to achieve this, we propose two approaches of fusion, featurelevel and classi fierlevel, to use training data from multiple domains simultaneously. experimental stud ies show that multidomain sentiment classi fication using the classifierlevel approach performs much better than single domain classification (using the training data indi vidually).	-5	8.1
mining sentiment classification from political web logs	over the last few years the number of web logs and amount of opinionated data on the world wide web has grown dramatically. web logs allow people to share their opinions on a wide range of hot topics with virtual communities. as readers start turning to web logs as a source of information, automatic techniques that identify the sentiment of web log posts will help bloggers categorize and filter this exploding information source. however, on the surface, sentiment classification of web log posts, in particular political web log posts, appears to be a more difficult problem than classification of traditional text because of the interplay among the images, hyperlinks, the style of writing and language used within web logs. in this paper we investigate existing technology and their utility for sentiment classification on web log posts. we show that a na茂ve bayes classifier can on average correctly predict a posting's political category 78.06% of the time with a standard deviation of 2.39. it significantly outperforms support vector machines at the 99.9% confidence level with a confidence interval of [1.425, 3.488].	-7	7.166666666666667
sentiment classification of internet restaurant reviews written in cantonese	in this paper, standard machine learning techniques naive bayes and svm are incorporated into the domain of online cantonesewritten restaurant reviews to automatically classify user reviews as positive or negative. the effects of feature presentations and feature sizes on classification performance are discussed. we find that accuracy is influenced by interaction between the classification models and the feature options. the naive bayes classifier achieves as well as or better accuracy than svm. characterbased bigrams are proved better features than unigrams and trigrams in capturing cantonese sentiment orientation.	-2	12.571428571428571
selc:a self-supervised model for sentiment classification	this paper presents the selc model (selfsupervised, (lexiconbased and (corpusbased model) for sentiment classification. the selc model includes two phases. the first phase is a lexiconbased iterative process. in this phase, some reviews are initially classified based on a sentiment dictionary. then more reviews are classified through an iterative process with a negative/positive ratio control. in the second phase, a supervised classifier is learned by taking some reviews classified in the first phase as training data. then the supervised classifier applies on other reviews to revise the results produced in the first phase. experiments show the effectiveness of the proposed model. selc totally achieves 6.63% f1score improvement over the best result in previous studies on the same data (from 82.72% to 89.35%). the first phase of the selc model independently achieves 5.90% improvement (from 82.72% to 88.62%). moreover, the standard deviation of f1scores is reduced, which shows that the selc model could be more suitable for domainindependent sentiment classification.	-4	8.666666666666666
fast and accurate sentiment classification using an enhanced naive bayes model	we have explored different methods of improving the accuracy of a naive bayes classifier for sentiment analysis. we observed that a combination of methods like effective negation handling, word ngrams and feature selection by mutual information results in a significant improvement in accuracy. this implies that a highly accurate and fast sentiment classifier can be built using a simple naive bayes model that has linear training and testing time complexities. we achieved an accuracy of 88.80% on the popular imdb movie reviews dataset. the proposed method can be generalized to a number of text categorization problems for improving speed and accuracy.	0	12.8
automatically extracting polarity-bearing topics for cross-domain sentiment classification	joint sentimenttopic (jst) model was previously proposed to detect sentiment and topic simultaneously from text. the only supervision required by jst model learning is domainindependent polarity word priors. in this paper, we modify the jst model by incorporating word polarity priors through modifying the topicword dirichlet priors. we study the polaritybearing topics extracted by jst and show that by augmenting the original feature space with polaritybearing topics, the indomain supervised classifiers learned from augmented feature representation achieve the stateoftheart performance of 95% on the movie review data and an average of 90% on the multidomain sentiment dataset. furthermore, using feature augmentation and selection according to the information gain criteria for crossdomain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. nevertheless, our approach is much simpler and does not require difficult parameter tuning.	-2	12.0
multi-domain sentiment classification	stateofthearts studies on sentiment classification are typically domaindependent and domainrestricted.in this paper,we aim to reduce domain dependency and improve overall performance simultaneously by proposing an efficient multidomain sentiment classification algorithm.our method employs the approach of multiple classifier combination.in this approach,we first train single domain classifiers separately with domain specific data,and then combine the classifiers for the final decision.our experiments show that this approach performs much better than both single domain classification approach(using the training data individually) and mixed domain classification approach(simply combining all the training data).in particular,classifier combination with weighted sum rule obtains an average error reduction of 27.6%over single domain classification.	-5	7.6
sentiment classification based on supervised latent n-gram analysis	in this paper, we propose an efficient embedding for modeling higherorder (ngram) phrases that projects the ngrams to lowdimensional latent semantic space, where a classification function can be defined. we utilize a deep neural network to build a unified discriminative framework that allows for estimating the parameters of the latent space as well as the classification function with a bias for the target classification task at hand. we apply the framework to largescale sentimental classification task. we present comparative evaluation of the proposed method on two (large) benchmark data sets for online product reviews. the proposed method achieves superior performance in comparison to the state of the art.	-2	9.714285714285714
sentiment classification based on supervised latent n-gram analysis	a method for sentiment classification of a text document using highorder ngrams utilizes a multilevel embedding strategy to project ngrams into a lowdimensional latent semantic space where the projection parameters are trained in a supervised fashion together with the sentiment classification task. using, for example, a deep convolutional neural network, the semantic embedding of ngrams, the bagofoccurrence representation of text from ngrams, and the classification function from each review to the sentiment class are learned jointly in one unified discriminative framework.	-1	10.333333333333334
chinese sentence-level sentiment classification based on fuzzy sets	this paper presents a fuzzy set theory based approach to chinese sentencelevel sentiment classification. compared with traditional topicbased text classification techniques, the fuzzy set theory provides a straightforward way to model the intrinsic fuzziness between sentiment polarity classes. to approach fuzzy sentiment classification, we first propose a finetocoarse strategy to estimate sentence sentiment intensity. then, we define three fuzzy sets to represent the respective sentiment polarity classes, namely positive, negative and neutral sentiments. based on sentence sentiment intensities, we further build membership functions to indicate the degrees of an opinionated sentence in different fuzzy sets. finally, we determine sentencelevel polarity under maximum membership principle. we show that our approach can achieve promising performance on the test set for chinese opinion analysis pilot task at ntcir6.	-3	8.625
scalable sentiment classification for big data analysis using naïve bayes classifier	a typical method to obtain valuable information is to extract the sentiment or opinion from a message. machine learning technologies are widely used in sentiment classification because of their ability to “learn” from the training dataset to predict or support decision making with relatively high accuracy. however, when the dataset is large, some algorithms might not scale up well. in this paper, we aim to evaluate the scalability of na07ve bayes classifier (nbc) in large datasets. instead of using a standard library (e.g., mahout), we implemented nbc to achieve finegrain control of the analysis procedure. a big data analyzing system is also design for this study. the result is encouraging in that the accuracy of nbc is improved and approaches 82% when the dataset size increases. we have demonstrated that nbc is able to scale up to analyze the sentiment of millions movie reviews with increasing throughput.	0	10.8
cross lingual adaptation: an experiment on sentiment classifications.	in this paper, we study the problem of using an annotated corpus in english for the same natural language processing task in another language. while various ma chine translation systems are available, au tomated translation is still far from per fect. to minimize the noise introduced by translations, we propose to use only key 'reliable parts from the translations and apply structural correspondence learn ing (scl) to find a low dimensional rep resentation shared by the two languages. we perform experiments on an english chinese sentiment classification task and compare our results with a previous co training approach. to alleviate the prob lem of data sparseness, we create ex tra pseudoexamples for scl by making queries to a search engine. experiments on realworld online review data demon strate the two techniques can effectively improve the performance compared to pre vious work.	-3	8.75
active deep learning method for semi-supervised sentiment classification	in natural language processing community, sentiment classification based on insufficient labeled data is a wellknown challenging problem. in this paper, a novel semisupervised learning algorithm called active deep network (adn) is proposed to address this problem. first, we propose the semisupervised learning framework of adn. adn is constructed by restricted boltzmann machines (rbm) with unsupervised learning based on labeled reviews and abundant of unlabeled reviews. then the constructed structure is finetuned by gradientdescent based supervised learning with an exponential loss function. second, in the semisupervised learning framework, we apply active learning to identify reviews that should be labeled as training data, then using the selected labeled reviews and all unlabeled reviews to train adn architecture. moreover, we combine the information density with adn, and propose information adn (iadn) method, which can apply the information density of all unlabeled reviews in choosing the manual labeled reviews. experiments on five sentiment classification datasets show that adn and iadn outperform classical semisupervised learning algorithms, and deep learning techniques applied for sentiment classification.	0	11.2
are sentiwordnet scores suited for multi-domain sentiment classification?	motivated by the numerous applications of analysing opinions in multidomain scenarios, this paper studies the potential of a still rarely considered approach to the problem of multidomain sentiment analysis based on sentiwordnet as lexical resource. sentiwordnet scores are exploited together with additional features to assign a polarity to a text using machine learning. on the other hand, a rulebased approach is studied based on sentiment scores. the introduced methods are tested on single domains of a realworld data set consisting of documents in six different domains, but also in crossdomain settings. the results show that for crossdomain sentiment analysis rulebased approaches with fix opinion lexica are unsuited. for machinelearning based sentiment classification a mixture of documents of different domains achieves good results.	-4	8.333333333333334
effectiveness of simple linguistic processing in automatic sentiment classification of product reviews	this paper reports a study in automatic sentiment classification, i.e., automaticallyclassifying documents as expressing positive or negative sentiments/opinions. the study investigatesthe effectiveness of using svm (support vector machine) on various text features to classify productreviews into recommended (positive sentiment) and not recommended (negative sentiment). comparedwith traditional topical classification, it was hypothesized that syntactic and semantic processing oftext would be more important for sentiment classification. in the first part of this study, severaldifferent approaches, unigrams (individual words), selected words (such as verb, adjective, andadverb), and words labeled with partofspeech tags were investigated. a sample of 1,800 variousproduct reviews was retrieved from review centre (www.reviewcentre.com) for the study. 1,200reviews were used for training, and 600 for testing.	-9	5.928571428571429
sentiment analysis of movie reviews: a new feature-based heuristic for aspect-level sentiment classification	this paper presents our experimental work on a new kind of domain specific featurebased heuristic for aspectlevel sentiment analysis of movie reviews. we have devised an aspect oriented scheme that analyses the textual reviews of a movie and assign it a sentiment label on each aspect. the scores on each aspect from multiple reviews are then aggregated and a net sentiment profile of the movie is generated on all parameters. we have used a sentiwordnet based scheme with two different linguistic feature selections comprising of adjectives, adverbs and verbs and ngram feature extraction. we have also used our sentiwordnet scheme to compute the documentlevel sentiment for each movie reviewed and compared the results with results obtained using alchemy api. the sentiment profile of a movie is also compared with the documentlevel sentiment result. the results obtained show that our scheme produces a more accurate and focused sentiment profile than the simple documentlevel sentiment analysis.	0	10.8
sentiment classification based on supervised latent n-gram analysis	in this paper, we propose an efficient embedding for modeling higherorder (ngram) phrases that projects the ngrams to lowdimensional latent semantic space, where a classification function can be defined. we utilize a deep neural network to build a unified discriminative framework that allows for estimating the parameters of the latent space as well as the classification function with a bias for the target classification task at hand. we apply the framework to largescale sentimental classification task. we present comparative evaluation of the proposed method on two (large) benchmark data sets for online product reviews. the proposed method achieves superior performance in comparison to the state of the art.	-2	9.0
joint bilingual sentiment classification with unlabeled parallel corpora.	most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resourcerich languages to resourcepoor languages. we present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. we rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%8.12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudoparallel data from machine translation engines.	-2	9.285714285714286
sentiment classification for chinese reviews: a comparison between svm and semantic approaches	web content mining is intended to help people to discover valuable information from large amount of unstructured data on the web. sentiment classification aims to mining the web content of product reviews by classifying the reviews into positive or negative opinions. such kind of classification approaches could help both consumers and sellers in making their decisions. but it is also a complicated task with great challenge. this paper conducted a comparison between the svm approach and semantic approach for sentiment classification of chinese reviews and also proposed some improvement for sentiment classification approaches. experimental result indicated that, compared with previous researches for english reviews, the performance of both approaches for chinese reviews sentiment classification are acceptable, while the support vector machine approach has better performance than the semantic orientation approach.	-8	5.769230769230769
chinese sentence-level sentiment classification based on sentiment morphemes	in this paper, we take morphemes as the basic tokens and present a finetocoarse strategy for chinese sentencelevel sentiment classification. this study involves three parts. first, we employ morphological productivity to extract sentiment morphemes from a sentiment dictionary and to calculate their polarity intensity at the same time. then, we apply the acquired morphemelevel sentiment information to predict the semantic orientation of sentiment words and phrases within an opinionated sentence. finally, all the sentiment phrases and their polarity scores are combined to determine the semantic orientation of the sentence. the experimental results on ntcir6 oapt test set show our system can achieve stateoftheart performance.	-3	8.25
active deep networks for semi-supervised sentiment classification	this paper presents a novel semisupervised learning algorithm called active deep networks (adn), to address the semisupervised sentiment classification problem with active learning. first, we propose the semisupervised learning method of adn. adn is constructed by restricted boltzmann machines (rbm) with unsupervised learning using labeled data and abundant of unlabeled data. then the constructed structure is finetuned by gradientdescent based supervised learning with an exponential loss function. second, we apply active learning in the semisupervised learning framework to identify reviews that should be labeled as training data. then adn architecture is trained by the selected labeled data and all unlabeled data. experiments on five sentiment classification datasets show that adn outperforms the semisupervised learning algorithm and deep learning techniques applied for sentiment classification.	-3	8.25
active deep networks for semi-supervised sentiment classification.	by embedding prior knowledge into the learning structure, this paper presents a twostep semisupervised learning method called fuzzy deep belief networks (fdbn) for sentiment classification. first, we train the general deep belief networks (dbn) by the semisupervised learning taken on training dataset. then, we design a fuzzy membership function for each class of reviews based on the learned deep architecture. since the training of dbn maps each review into the dbn output space, the distribution of all training samples in the space is treated as prior knowledge and is encoded by a series of fuzzy membership functions. second, based on the fuzzy membership functions and the dbn obtained in the first step, a novel fdbn architecture is constructed and the supervised learning stage is applied to improve the classification performance of the fdbn. fdbn not only inherits the powerful ion ability of dbn, but also demonstrates the attractive fuzzy classification ability for handling sentiment data. to inherit the advantages of both active learning and fdbn, we also propose an active fdbn (afd) semisupervised learning method. the empirical validation on five sentiment classification datasets demonstrates the effectiveness of fdbn and afd methods.	-3	8.0
experimental study on sentiment classification of chinese review using machine learning techniques	machine learning method in text classification has expanded from topic identification to more challenging tasks such as sentiment classification, and it is valuable to explore, compare methods applied in sentiment classification and investigate relevant influence factors. the chief aim of the present work is to compare four machine learning methods to sentiment classification of chinese review. the corpus is made up of 16000 reviews from website.we investigate the factors which affect the performance namely feature representation via wordbased unigram (wbu),bigram (wbb) and chinese characterbased bigram (cbb), trigram (cbt);feature weighting schemes and feature dimensionality.experimental evaluations show that performance depends on different settings. as a result, we draw a conclusion that na?ve bayes (nb) classifier obtains the best averaging performance when using wbb, cbt as features with bool weighting under different dimensionality to the task.	-6	6.818181818181818
analysis of different approaches to sentence-level sentiment classification	sentiment classification is a way to analyze the subjective information in the text and then mine the opinion. sentiment analysis is the procedure by which information is extracted from the opinions, appraisals and emotions of people in regards to entities, events and their attributes. in decision making, the opinions of others have a significant effect on customers ease, making choices with regards to online shopping, choosing events, products, entities. the approaches of text sentiment analysis typically work at a particular level like phrase, sentence or document level. this paper aims at analyzing a solution for the sentiment classification at a finegrained level, namely the sentence level in which polarity of the sentence can be given by three categories as positive, negative and neutral.	0	9.8
weakly supervised techniques for domain-independent sentiment classification	an important subtask of sentiment analysis is polarity classification, in which text is classified as being positive or negative. supervised machine learning techniques can perform this task very effectively. however, they require a large corpus of training data, and a number of studies have demonstrated that the good performance of supervised models is dependent on a good match between the training and testing data with respect to the domain, topic and timeperiod. weaklysupervised techniques use a large collection of unlabelled text to determine sentiment, and so their performance may be less dependent on the domain, topic and timeperiod represented by the testing data. this paper presents experiments that investigate the effectiveness of word similarity techniques when performing weaklysupervised sentiment classification. it also considers the extent to which the performance of each method is independent from the domain, topic and timeperiod of the testing data. the results indicate that the word similarity techniques are suitable for applications that require sentiment classification across several domains.	-4	7.666666666666667
sentiment classification of movie and product reviews using contextual valence shifters	we present a method for determining the sentiment expressed by a customer review. the semantic orientation of a review can be pos itive, negative, or neutral. our method counts positive and negative terms, but also takes into account contextual valence shifters, such as negations and intensiers. tests are done taking both negations and in tensiers into account, and also using only negations without intensi ers. negations are used to reverse the semantic polarity of a particular term, while intensiers are used to change the degree to which a term is positive or negative. we use the general inquirer in order to identify positive and negative terms, as well as negations, overstatements, and understatements. we also test the impact of adding extra positive and negative terms from other sources, including a dictionary of synonym dierences and a very large web corpus. to compute the corpusbased values of the semantic orientation of individual terms we use their as sociation scores with a small group of positive and negative terms. we show that including contextual valence shifters improves the accuracy of the classication.	-7	5.833333333333333
sentiment classification for chinese reviews: a comparison between svm and semantic approaches	web content mining is intended to help people to discover valuable information from large amount of unstructured data on the web. sentiment classification aims to mining the web content of product reviews by classifying the reviews into positive or negative opinions. such kind of classification approaches could help both consumers and sellers in making their decisions. but it is also a complicated task with great challenge. this paper conducted a comparison between the svm approach and semantic approach for sentiment classification of chinese reviews and also proposed some improvement for sentiment classification approaches. experimental result indicated that, compared with previous researches for english reviews, the performance of both approaches for chinese reviews sentiment classification are acceptable, while the support vector machine approach has better performance than the semantic orientation approach. 漏 2005 ieee.	-8	5.384615384615385
sentiment classification using sentence-level semantic orientation of opinion terms from blogs	sentiment analysis is the procedure by which information is extracted from the opinions, appraisals and emotions of people in regards to entities, events and their attributes. in decision making, the opinions of others have a significant effect on customers ease in making choices regards to online shopping, choosing events, products, entities. in this paper, the rule based domain independent sentiment analysis method is proposed. the proposed method classifies subjective and objective sentences from reviews and blog comments. the semantic score of subjective sentences is extracted from sentiwordnet to calculate their polarity as positive, negative or neutral based on the contextual sentence structure. the results show the effectiveness of the proposed method and it outperforms the machine learning methods. the proposed method achieves an accuracy of 87% at the feedback level and 83% at the sentence level.	-1	8.333333333333334
sentiment classification using sentence-level lexical based semantic orientation of online reviews	sentiment analysis is the process of extracting knowledge from the peoples鈥 opinions, appraisals and emotions toward entities, events and their attributes. these opinions greatly impact on customers to make their choices regarding online shopping, choosing events, products and entities. with the rapid growth of online resources, discussion groups, forums and blogs; people communicate through these means of internet on daily basis. as a result, the vast amount of new data in the form of customer reviews and opinions are being generated progressively. so it is desired to develop an efficient and effective sentiment analysis system for online customer reviews and comments. in this study, the rule based domain independent sentiment analysis method is proposed. the proposed method classifies subjective and objective sentences from reviews and blog comments. the semantic score of subjective sentences is extracted from sentiwordnet to calculate their polarity as positive, negative or neutral based on the contextual sentence structure. the results show the effectiveness of the proposed method and it outperforms the word level and machine learning methods. the proposed method achieves an accuracy of 97.8% at the feedback level and 86.6% at the sentence level.	-2	7.142857142857143
chinese sentence-level sentiment classification based on sentiment morphemes	in this paper, we take morphemes as the basic tokens and present a finetocoarse strategy for chinese sentencelevel sentiment classification. this study involves three parts. first, we employ morphological productivity to extract sentiment morphemes from a sentiment dictionary and to calculate their polarity intensity at the same time. then, we apply the acquired morphemelevel sentiment information to predict the semantic orientation of sentiment words and phrases within an opinionated sentence. finally, all the sentiment phrases and their polarity scores are combined to determine the semantic orientation of the sentence. the experimental results on ntcir6 oapt test set show our system can achieve stateoftheart performance.	-3	7.75
learning to shift the polarity of words for sentiment classification	we propose a machine learning based method of sentiment classification of sentences using wordlevel polarity. the polarities of words in a sentence are not always the same as that of the sentence, because there can be polarityshifters such as negation expressions. the proposed method models the polarityshifters. our model can be trained in two different ways wordwise and sentencewise learning. in sentencewise learning, the model can be trained so that the prediction of sentence polarities should be accurate. the model can also combined with features used in previous work such as bagofwords and ngrams. we empirically show that our method improves the performance of sentiment classification of sentences especially when we have only small amount of training data.	-5	6.5
using objective words in sentiwordnet to improve word-of-mouth sentiment classification	to improve the performance of wordofmouth sentiment classification, this article reevaluates objective sentiment words in the sentiwordnet sentiment lexicon.	0	8.6
a feature selection method based on fisher’s discriminant ratio for text sentiment classification	owing to its openness, virtualization and sharing criterion, the internet has been rapidly becoming a platform for people to express their opinion, attitude, feeling and emotion. as the subjectivity texts are often too many for people to go through, how to automatically classify them into different sentiment orientation categories (e.g. positive/negative) has become an important research problem. in this paper, based on fisher鈥檚 discriminant ratio, an effective feature selection method is proposed for subjectivity text sentiment classification. in order to validate the proposed method, we compared it with the method based on information gain while support vector machine is adopted as the classifier. two experiments are conducted by combining different feature selection methods with two kinds of candidate feature sets. under 2739 subjectivity documents of coae2008s and 1006 carrelated subjectivity documents, the experimental results indicate that the fisher鈥檚 discriminant ratio based on word frequency estimation has the best performance respectively with accuracy 86.61% and 82.80% under two corpus while the candidate features are the words which appear in both positive and negative texts.	-2	8.428571428571429
using a contextual entropy model to expand emotion words and their intensity for the sentiment classification of stock market news	sentiment classification of stock market news involves identifying positive and negative news articles, and is an emerging technique for making stock trend predictions which can facilitate investor decision making. in this paper, we propose the presence and intensity of emotion words as features to classify the sentiment of stock market news articles. to identify such words and their intensity, a contextual entropy model  is developed to expand a set of seed words generated from a small corpus of stock market news articles with sentiment annotation. the contextual entropy model measures the similarity between two words by comparing their contextual distributions using an entropy measure, allowing for the discovery of words similar to the seed words. experimental results show that the proposed method can discover more useful emotion words and their corresponding intensity, thus improving classification performance. performance was further improved by the incorporation of intensity into the classification, and the proposed method outperformed the previouslyproposed pointwise mutual information (pmi)based expansion methods.	0	9.0
domain-specific sentiment classification	a domainspecific sentiment classifier that can be used to score the polarity and magnitude of sentiment expressed by domainspecific documents is created. a domainindependent sentiment lexicon is established and a classifier uses the lexicon to score sentiment of domainspecific documents. sets of highsentiment documents having positive and negative polarities are identified. the ngrams within the highsentiment documents are filtered to remove extremely common ngrams. the filtered ngrams are saved as a domainspecific sentiment lexicon and are used as features in a model. the model is trained using a set of training documents which may be manually or automatically labeled as to their overall sentiment to produce sentiment scores for the ngrams in the domainspecific sentiment lexicon. this lexicon is used by the domainspecific sentiment classifier.	0	7.8
cross-lingual mixture model for sentiment classification	the amount of labeled sentiment data in english is much larger than that in other languages. such a disproportion arouse interest in crosslingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. chinese) using labeled data in the source language (e.g. english). most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. this approach suffers from the limited coverage of vocabulary in the machine translation results. in this paper, we propose a generative crosslingual mixture model (clmm) to leverage unlabeled bilingual parallel data. by fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage significantly. experiments on multiple data sets show that clmm is consistently effective in two settings (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.	0	7.2
active learning for cross-domain sentiment classification	in the literature, various approaches have been proposedto address the domain adaptation problem in sentiment classification (also called crossdomainsentiment classification). however, the adaptation performance normally much suffers when the data distributionsin the source and target domains differ significantly. in this paper, we suggest to perform activelearning for crossdomain sentiment classification by actively selecting a smallamount of labeled data in the target domain. accordingly, we propose an novel activelearning approach for crossdomain sentiment classification. first, we traintwo individual classifiers, i.e., the source and target classifiers with thelabeled data from the source and target respectively. then, the two classifiersare employed to select informative samples with the selection strategy of queryby committee (qbc). third, the two classifier is combined to make theclassification decision. importantly, the two classifiers are trained by fullyexploiting the unlabeled data in the target domain with the label propagation(lp) algorithm. empirical studies demonstrate the effectiveness of our active learning approach for crossdomainsentiment classification over some strong baselines.	0	7.4
harnessing wordnet senses for supervised sentiment classification	traditional approaches to sentiment classification rely on lexical features, syntaxbased features or a combination of the two. we propose semantic features using word senses for a supervised documentlevel sentiment classifier. to highlight the benefit of sensebased features, we compare wordbased representation of documents with a sensebased representation where wordnet senses of the words are used as features. in addition, we highlight the benefit of senses by presenting a partofspeechwise effect on sentiment classification. finally, we show that even if a wsd engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on wordnet to address the problem of not finding a sense in the training corpus. we perform experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. the results show promising improvement with respect to the baseline.	-2	6.0
knowledge transformation for cross-domain sentiment classification	with the explosion of usergenerated web2.0 content in the form of blogs, wikis and discussion forums, the internet has rapidly become a massive dynamic repository of public opinion on an unbounded range of topics. a key enabler of opinion extraction and summarization is sentiment classification the task of automatically identifying whether a given piece of text expresses positive or negative opinion towards a topic of interest. building highquality sentiment classifiers using standard text categorization methods is challenging due to the lack of labeled data in a target domain. in this paper, we consider the problem of crossdomain sentiment analysis can one, for instance, download rated movie reviews from rottentomatoes.com or imbd discussion forums, learn linguistic expressions and sentimentladen terms that generally characterize opinionated reviews and then successfully transfer this knowledge to the target domain, thereby building highquality sentiment models without manual effort? we outline a novel sentiment transfer mechanism based on constrained nonnegative matrix trifactorizations of termdocument matrices in the source and target domains. we report some preliminary results with this approach.	-4	5.888888888888889
exploring the use of word relation features for sentiment classification.	word relation features, which encode relation information between words, are supposed to be effective features for sentiment classification. however, the use of word relation features suffers from two issues. one is the sparsedata problem and the lack of generalization performance; the other is the limitation of using word relations as additional features to unigrams. to address the two issues, we propose a generalized word relation feature extraction method and an ensemble model to efficiently integrate unigrams and different type of word relation features. furthermore, aimed at reducing the computation complexity, we propose two fast feature selection methods that are specially designed for word relation features. a range of experiments are conducted to evaluate the effectiveness and efficiency of our approaches.	-3	5.625
sample cutting method for imbalanced text sentiment classification based on brc	although the boundary region cutting algorithm brc is aimed to text sentiment classification we believe that it is also suitable to any twocategory classification problem with imbalanced sample data.	0	6.8
using objective words in sentiwordnet to improve word-of-mouth sentiment classification	to improve the performance of wordofmouth sentiment classification, this article reevaluates objective sentiment words in the sentiwordnet sentiment lexicon.	0	7.2
mine the easy, classify the hard: a semi-supervised approach to automatic sentiment classification	supervised polarity classification systems are typically domainspecific. building these systems involves the expensive pro cess of annotating a large amount of data for each domain.	-4	5.111111111111111
sentiment classification using the theory of anns	sentiment classification has attracted increasing interest from natural language processing. the goal of sentiment classification is to automatically identify whether a given piece of text expresses positive or negative opinion on a topic of interest. this paper presents the standpoint that uses individual model (imodel) based on artificial neural networks (anns) to determine text sentiment classification. the individual model consists of sentimental features, feature weight and prior knowledge base. during the training process, imodel that makes right sentimental judgment will correct those are wrong, to make more accurate prediction of text sentiment polarity. experimental results show that the accuracy of individual model is higher than that of support vector machines (svms) and hidden markov model (hmm) classifiers on movie review corpus.	-3	5.25
sentiment classification for chinese news using machine learning methods	in this paper,we study how to apply machine learning techniques to solve sentiment classification problems.the main task of sentiment classification is to determine whether news or reviews is negative or positive.naive bayes and maximum entropy classification are used for the sentiment classification of chinese news and reviews.the experimental results show that the methods we employed perform well.the accuracy of classification can achieve about 90%.moreover,we find that selecting the words with polarity as features,negation tagging and representing test documents as feature presence vectors can improve the performance of sentiment classification.conclusively,sentiment classification is a more challenging problem.	-6	4.363636363636363
multi-domain sentiment classification with classifier combination	stateofthearts studies on sentiment classification are typically domaindependent and domainrestricted. in this paper, we aim to reduce domain dependency and improve overall performance simultaneously by proposing an efficient multidomain sentiment classification algorithm. our method employs the approach of multiple classifier combination. in this approach, we first train single domain classifiers separately with domain specific data, and then combine the classifiers for the final decision. our experiments show that this approach performs much better than both single domain classification approach (using the training data individually) and mixed domain classification approach (simply combining all the training data). in particular, classifier combination with weighted sum rule obtains an average error reduction of 27.6% over single domain classification.	-2	5.571428571428571
active learning for imbalanced sentiment classification	active learning is a promising way for sentiment classification to reduce the annotation cost. in this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples. this scenario posits new challenges to active learning. to address these challenges, we propose a novel active learning approach, named coselecting, by taking both the imbalanced class distribution issue and uncertainty into account. specifically, our coselecting approach employs two feature subspace classifiers to collectively select most informative minorityclass samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majorityclass samples, to reduce humanannotation efforts. extensive experiments across four domains demonstrate great potential and effectiveness of our proposed coselecting approach to active learning for imbalanced sentiment classification.	-1	5.833333333333333
active learning for cross-lingual sentiment classification	crosslingual sentiment classification alms to predict the sentiment orientation of a text in a language (named as the target language) with the help of the resources from another language (named as the source language).how ever, current crosslingual performance is normally far away from satisfaction due to the huge difference in linguistic expression and social culture.in this pa per, we suggest to perform active learning for crosslingual sentiment classifica tion, where only a small scale of samples are actively selected and manually annotated to achieve reasonable performance in a short time for the target lan guage.the challenge therein is that there are normally much more labeled sam pies in the source language than those in the target language.this makes the small amount of labeled samples from the target language flooded in the ab oundance of labeled samples from the source language, which largely reduces their impact on crosslingual sentiment classification.to address this issue, we propose a data quality controlling approach in the source language to select highquality samples from the source language.specifically, we propose two kinds of data quality measurements, intraand extraquality measurements, from the certainty and similarity perspectives.empirical studies verify the appropriateness of our active learning approach to crosslingual sentiment classification.	0	6.6
bilingual co-training for sentiment classification of chinese product reviews	the lack of reliable chinese sentiment resources limits research progress on chinese sentiment classification. however, there are many freely available english sentiment resources on the web. this article focuses on the problem of crosslingual sentiment classification, which leverages only available english resources for chinese sentiment classification. we first investigate several basic methods (including lexiconbased methods and corpusbased methods) for crosslingual sentiment classification by simply leveraging machine translation services to eliminate the language gap, and then propose a bilingual cotraining approach to make use of both the english view and the chinese view based on additional unlabeled chinese data. experimental results on two test sets show the effectiveness of the proposed approach, which can outperform basic methods and transductive methods.	-2	5.714285714285714
sentirank: cross-domain graph ranking for sentiment classification	sentiment classification is attracting more and more attention because of its great benefits to social and human life. usually supervised classification approaches perform well in sentiment classification, but the performance decreases sharply when transferred from one domain to another domain. in this paper, we propose an approach, sentirank, which integrates the sentiment orientations of the documents into the graphranking algorithm for crossdomain sentiment classification. we apply the graphranking algorithm using the accurate labels of olddomain documents as well as the “pseudo” labels of newdomain documents, and investigate their relative importance for crossdomain sentiment classification. the experiment results indicate that the proposed algorithm could improve the performance of crossdomain sentiment classification dramatically.	-4	4.666666666666667
sentiment classification of customer reviews based on fuzzy logic	nowadays, ecommerce is growing fast, so product reviews have grown rapidly on the web. the large number of reviews makes it difficult for manufacturers or businesses to automatically classify them into different semantic orientations (positive, negative, and neutral). most existing method utilize a list of opinion words for sentiment classification. whereas, this paper propose a fuzzy logic model to perform semantic classifications of customers review into the following subclasses very weak, weak, moderate, very strong and strong by combinations adjective, adverb and verb to increase holistic the accuracy of lexicon approach. fuzzy logic, unlike statistical data mining techniques, not only allows using nonnumerical values also introduces the notion of linguistic variables. using linguistic terms and variables will result in a more human oriented querying process.	-3	4.75
opinion mining and sentiment classification: a survey	with the evolution of web technology, there is a huge amount of data present in the web for the internet users. these users not only use the available resources in the web, but also give their feedback, thus generating additional useful information. due to overwhelming amount of user’s opinions, views, feedback and suggestions available through the web resources, it’s very much essential to explore, analyze and organize their views for better decision making. opinion mining or sentiment analysis is a natural language processing and information extraction task that identifies the user’s views or opinions explained in the form of positive, negative or neutral comments and quotes underlying the text. text categorization generally classifies the documents by topic. this survey gives an overview of the efficient techniques, recent advancements and the future research directions in the field of sentiment analysis.	-1	5.5
sentiment classification using automatically extracted subgraph features	in this work, we propose a novel representation of text based on patterns derived from linguistic annotation graphs. we use a subgraph mining algorithm to automatically derive features as frequent subgraphs from the annotation graph. this process generates a very large number of features, many of which are highly correlated. we propose a genetic programming based approach to feature construction which creates a fixed number of strong classification predictors from these subgraphs. we evaluate the benefit gained from evolved structured features, when used in addition to the bagofwords features, for a sentiment classification task.	-3	4.25
research on language modeling based sentiment classification of text	presented in this paper is a language modeling approach to the sentiment classification of text.it provides the semantic information beyond topic in text summary when characterizing the semantic orientation of texts as thumb up or thumb down.the motivation is simplethumb up and thumb down language models are likely to be substantially differentthey prefer to different language habits.this divergence is exploited in the language models to effectively classify test documents.therefore,the method can be deployed in two stagesfirstly,the two sentiment language models are estimated from training data;secondly,tests are done through comparing the kullbackleibler divergence between the language model estimated from test document and those two trained sentiment models.the unigrams and bigrams of words are employed as the model parameters,and correspondingly maximum likelihood estimation and smoothing techniques are used to estimate these parameters.compared with two different classifiers,i.e.svms and na顣寁e bayes,on movie review corpus when training data is limited,the language modeling approach performs better than svms and na顣寁e bayes classifier,and on the other hand it shows its robustness in sentiment classification.future works may focus on finding a good way to estimate better language models,especially the higher order ngram models and more powerful smoothing methods.	-6	3.6363636363636362
sentirank: cross-domain graph ranking for sentiment classification	sentiment classification is attracting more and more attention because of its great benefits to social and human life. usually supervised classification approaches perform well in sentiment classification, but the performance decreases sharply when transferred from one domain to another domain. in this paper, we propose an approach, sentirank, which integrates the sentiment orientations of the documents into the graphranking algorithm for crossdomain sentiment classification. we apply the graphranking algorithm using the accurate labels of olddomain documents as well as the “pseudo” labels of newdomain documents, and investigate their relative importance for crossdomain sentiment classification. the experiment results indicate that the proposed algorithm could improve the performance of crossdomain sentiment classification dramatically.	-4	4.444444444444445
use of negation phrases in automatic sentiment classification of product reviews	this paper reports a study in automatic sentiment classification, i.e., automatically classifying documents as expressing positive or negative sentiments. the study investigates the effectiveness of using a machinelearning algorithm, support vector machine (svm), on various text features to classify online product reviews into recommended (positive sentiment) and not recommended (negative sentiment). in the first part of this study, several approaches, unigrams (individual words), selected words (such as verb, adjective, and adverb), and words labeled with partofspeech tags were investigated. using svm, the unigram approach obtained an accuracy rate of around 76%. error analysis suggests various approaches for improving classification accuracy handling of negation phrases, inferencing from superficial words, and handling the problem of comments on parts of the product. the second part of the study investigated the use of negation phrase ngrams to improve classification accuracy. this approach increased the accuracy rate to 79.33%. compared with traditional subject classification which mainly uses unigrams, syntactic and semantic processing of text appear more important for sentiment classification. we expect that deeper linguistic processing will help increase accuracy for sentiment classification.	-8	3.5384615384615383
sentiment vector space model for lyric-based song sentiment classification	song sentiment analysis attracts much attention in research areas such as acoustic signal processing (asp) and natural language processing (nlp). the textbased efforts in the nlp community are found to be interesting. as a popular textbased solution, the lyricbased sentiment classification approach adopts the vector space model (vsm) to represent lyric text and assigns songs sentiment labels such as lighthearted and heavyhearted. four problems render the termbased vsm model ineffective. firstly, many words within song lyrics contribute little to expressing sentiment, but they are equally considered as term features. secondly, nouns and verbs being used to express sentiment are ambiguously used in natural language text. but the ambiguity is not addressed. thirdly, negations and modifiers accompanying the sentiment keywords make particular contributions to sentiment expressing, but the contributions are not reflected. lastly, song lyric is usually very short and data sparseness problem is serious. to ...	-5	3.8
incorporating lexicon knowledge into svm learning to improve sentiment classification	a sentiment classifier for sentiment classification of content. an aspect classifier is configured to classify content as being related to a particular aspect of information, the aspect classifier incorporating at least a portion of the domain specific sentiment lexicon. a polarity classifier is then configured to classify the content classified by the aspect classifier as having one of a positive sentiment of the particular aspect of information, a negative sentiment of the particular aspect of information or as having no sentiment as to the particular aspect of information. the polarity classifier also incorporating at least a portion of the domain specific sentiment lexicon.	0	6.0
a feature selection method based on fisher’s discriminant ratio for text sentiment classification	with the rapid growth of ecommerce, product reviews on the web have become an important information source for customers’ decision making when they intend to buy some product. as the reviews are often too many for customers to go through, how to automatically classify them into different sentiment orientation categories (i.e. positive/negative) has become a research problem. in this paper, based on fisher’s discriminant ratio, an effective feature selection method is proposed for product review text sentiment classification. in order to validate the validity of the proposed method, we compared it with other methods respectively based on information gain and mutual information while support vector machine is adopted as the classifier. in this paper, 6 subexperiments are conducted by combining different feature selection methods with 2 kinds of candidate feature sets. under 1006 review documents of cars, the experimental results indicate that the fisher’s discriminant ratio based on word frequency estimation has the best performance with f value 83.3% while the candidate features are the words which appear in both positive and negative texts.	-4	3.888888888888889
sentiment classification techniques for tracking literary reputation	the initial stages of a project tracking the literary reputation of authors are described. the critical reviews of six authors who either rose to fame or fell to obscurity between 1900 and 1950 will be examined and we hope to demonstrate the contribution of each text to the evolving reputations of the authors. we provide an initial report on the use of the semantic orientation of adjectives and their rough position in the text to calculate the overall orientation of the text and suggest ways in which this calculation can be improved. improvements include further development of adjective lists, expansion of these lists and the consequent algorithms for calculating orientation to include other parts of speech, and the use of rhetorical structure theory to differentiate units that make a direct contribution to the intended orientation from those that are contrastive or otherwise make an indirect contribution.	-7	3.0833333333333335
sentiment classification using rough set based hybrid feature selection	sentiment analysis means to extract opinion of users from review documents. sentiment classification using machine learning (ml) methods faces the problem of high dimensionality of feature vector. therefore, a feature selection method is required to eliminate the irrelevant and noisy features from the feature vector for efficient working of ml algorithms. rough set theory based feature selection method finds the optimal feature subset by eliminating the redundant features. in this paper, rough set theory (rst) based feature selection method is applied for sentiment classification. a hybrid feature selection method based on rst and information gain (ig) is proposed for sentiment classification. proposed methods are evaluated on four standard datasets viz. movie review, product (book, dvd and electronics) review dataset. experimental results show that hybrid feature selection method outperforms than other feature selection methods for sentiment classification. 1	0	4.8
a new method for sentiment classification in text retrieval	traditional text categorization is usually a topicbased task, but a subtle demand on information retrieval is to distinguish between positive and negative view on text topic. in this paper, a new method is explored to solve this problem. firstly, a batch of concerned concepts in the researched domain is predefined. secondly, the special knowledge representing the positive or negative context of these concepts within sentences is built up. at last, an evaluating function based on the knowledge is defined for sentiment classification of free text. we introduce some linguistic knowledge in these procedures to make our method effective. as a result, the new method proves better compared with svm when experimenting on chinese texts about a certain topic.	-8	2.8461538461538463
sentiment classification through combining classifiers with multiple feature sets	sentiment classification aims at assigning a document to a predefined category according to the polarity of its subjective information (e.g. 'thumbs up' or 'thumbs down'). in this paper, we present a classifier combination approach to this task. first, different classifiers are generated through training the review data with different features unigram and some pos features. then, classifier selection method is used to select a part of the classifiers for the nextstep combination. finally, these selected classifiers are combined using several combining rules. the experimental results show that all the combination approaches with different combining rules outperform individual classifiers and the sum rule achieves the best performance with an improvement of 2.56% over the best individual classifier.	-6	3.1818181818181817
document sentiment classification by exploring description model of topical terms	sentiment classification is used to identify whether the opinion expressed in a document is positive or negative. in this paper, we present an approach to do documentarylevel sentiment classification by modeling description of topical terms. the motivation of this work stems from the observation that the global document classification will benefit greatly by examining the way of a topical term to give opinion in its local sentence context. two sentencelevel sentiment description models, namely positive and negative topical term description models, are constructed for each topical term. when analyzing a document, the topical term description models generate divergence to support the classification of its sentiment at the sentencelevel which in turn can be used to decide the whole document classification collectively. the results of the experiments prove that our proposed method is effective. it is also shown that our results are comparable to the stateofart results on a publicly available movie review corpus and a chinese digital product review corpus. this is quite encouraging to us and motivates us to have further investigation on the development of a more effective topical term related description model in the future.	-2	4.428571428571429
bilingual co-training for sentiment classification of chinese product reviews	the lack of reliable chinese sentiment resources limits research progress on chinese sentiment classification. however, there are many freely available english sentiment resources on the web. this article focuses on the problem of crosslingual sentiment classification, which leverages only available english resources for chinese sentiment classification. we first investigate several basic methods (including lexiconbased methods and corpusbased methods) for crosslingual sentiment classification by simply leveraging machine translation services to eliminate the language gap, and then propose a bilingual cotraining approach to make use of both the english view and the chinese view based on additional unlabeled chinese data. experimental results on two test sets show the effectiveness of the proposed approach, which can outperform basic methods and transductive methods.	-2	4.142857142857143
research on sentiment classification of chinese reviews based on supervised machine learning techniques	sentiment classification is an applied technology with great significance.it can solve information disorder and help people locate the required reviews in the internet.up to now,most research of sentiment classification is on english reviews,and little work has been done on chinese reviews.to find an effective way for the task based on supervised machine learning method,and analyze the influence by term expression and term selection,this paper conducted some experiments under distinct environments,including different feature representation,different feature selection,different categorization technique,different size of features and different size of training data,over chinese text collections.the experimental results show that sentiment classification will obtain high performance,when using bigrams representation,information gain and svm classifier,enough training data and plenty of features.	-6	3.1818181818181817
an empirical study to address the problem of unbalanced data sets in sentiment classification	with the emergence of web 2.0, sentiment analysis is receiving more and more attention. several interesting works were performed to address different issues in sentiment analysis. nevertheless, the problem of unbalanced data sets was not enough tackled within this research area. this paper presents the study we have carried out to address the problem of unbalanced data sets in supervised sentiment classification in a multilingual context. we propose three different methods to undersample the majority class documents. these methods are remove similar, remove farthest and remove by clustering. our goal is to compare the effectiveness of the proposed methods with the common random undersampling. we also aim to evaluate the behavior of the classifiers toward different undersampling rates. we use three different common classifiers, namely na茂ve bayes, support vector machines and knearest neighbors. the experiments are carried out on two arabic data sets and an english data set. we show that the four undersampling methods are typically competitive. na茂ve bayes is shown as insensitive to unbalanced data sets. but support vector machines seems to be highly sensitive to unbalanced data sets; knearest neighbors shows a slight sensitivity to imbalance in comparison with support vector machines.	-1	4.666666666666667
a new method for sentiment classification in text retrieval	traditional text categorization is usually a topicbased task, but a subtle demand on information retrieval is to distinguish between positive and negative view on text topic. in this paper, a new method is explored to solve this problem. firstly, a batch of concerned concepts in the researched domain is predefined. secondly, the special knowledge representing the positive or negative context of these concepts within sentences is built up. at last, an evaluating function based on the knowledge is defined for sentiment classification of free text. we introduce some linguistic knowledge in these procedures to make our method effective. as a result, the new method proves better compared with svm when experimenting on chinese texts about a certain topic.	-8	2.6923076923076925
sentence based sentiment classification from online customer reviews	sentiment analysis is the process of analyzing and classifying the rewires contents about a product, event, and place etc into positive, negative or neutral opinion. in this paper; we propose a sentence level machine learning approach for sentiment classification of online reviews. the proposed method extracts the subjective sentences from the reviews and label each sentence either positive or negative based on its word level feature using naïve naïve bayesian (nb) classifier. the labeled sentences create an annotated set of sentences called as bos (bagofsentences). we train support vector machine (svm) classifier on the bos for sentences polarity classification. the contextual information in each sentence structure is taken into consideration to calculate the semantic orientation. the effectiveness of the proposed method is evaluated thought simulation. results show that our machine learning based proposed method on average achieves accuracy of 81% and 83% with some contextual information. this method improves the sentiment classification polarity on sentence level unlike the word level lexical feature based work, by focus on sentences, this also concentrate on contextual information.	-3	3.75
comment target extraction and sentiment classification	the research on sentiment analysis is a hot issue in natural language processing.this paper makes an intensive study of the two stages of sentiment analysis the comment target extraction and the corresponding sentiment classification.for the first task,we use the syntactic analysis to obtain the candidats,and then combine pmi based on web mining and nn filtering algorithm to decide the targets.for the second task,we design certain heuristic rules by analyzing subjective sentences,and then apply these rules to predict the orientation of opinion in the sentences.this method performs well in task three of the coae2008 i.	-3	3.625
sentiment classification for chinese reviews using machine learning methods based on string kernel	opinions and reviews on products and services are expressed in the web through blogs, feedback forms; it is essential to develop methods to automatically classify and gauge them to identify the underlying sentiment about the product. analyzing the polarity of sentiment expressed in data is opinion mining (om). it is a system that identifies and classifies opinion/sentiment as represented in...  /reacttext  reacttext 500   /reacttext [show full ]	-5	3.0
an ontology-based sentiment classification methodology for online consumer reviews	this paper presents a method of ontologybased sentiment classification to classify and analyse online product reviews of consumers. we implement and experiment with a support vector machines text classification approach based on a lexical variable ontology. after testing, it could be demonstrated that the proposed method can provide more effectiveness for sentiment classification based on text content.	-5	3.1
a hybrid method of feature selection for chinese text sentiment classification	text sentiment classification can be extensively applied to information retrieval, text filtering, online tracking evaluation, the diagnoses of public opinions and chat systems. in this paper, a kinds of hybrid methods, based on category distinguishing ability of words and information gain, is adopted to feature selection. for examining the impact of varying the feature dimension to classification results, using corpus of car reviews, feature dimensions, 1000, 2000 and 3000 are adopted in our experiments. the experiments classification results indicate that the hybrid methods are best with feature dimension equal to 3000, and the result by using hybrid methods is superior to that by directly using information gain. in our experiments f value can achieve over 80%. finally, some mistake examples are employed to indicate the limitations of methods in this paper.	-6	2.909090909090909
sentiment classification of chinese traveler reviews by support vector machine algorithm	nowadays, online wordofmouth has turned to be a very important resource for electronic businesses. how to analyze user generated reviews and to classify them into different sentiment classes is gradually becoming a question that people pay close attention to. in this field, special challenges are associated with the mining of traveler reviews. at present, there is some research on sentiment analysis for english traveler generated reviews, but very few studies pay attention to sentiment analysis for traveler reviews in chinese. china is the largest country in terms of the number of internet users. internet technologies are gradually playing more and more important roles for many industries including tourism industry. the lack of sentiment analysis methods will block the use of wordofmouth for tourism industry in china. to solve the problem, this study conducts an exploring research on sentiment analysis to chinese traveler reviews by support vector machine (svm) algorithm. the experiment data of chinese reviews for hotels are downloaded from www.ctrip.com, the largest online travel agency in china. empirical results indicate that, comparing to prior studies on english reviews, svm algorithm can gain a very well performance of sentiment classification for traveler reviews in chinese.	-4	3.111111111111111
sentiment classification for chinese reviews using machine learning methods based on string kernel	sentiment classification aims at mining reviews of people for a certain event's topic or product by automatic classifying the reviews into positive or negative opinions. with the fast developing of world wide web applications, sentiment classification would have huge opportunity to help people automatic analysis of customers' opinions from the web information. automatic opinion mining will benefit to both decision maker and ordinary people. up to now, it is still a complicated task with great challenge. there are mainly two types of approaches for sentiment classification, machine learning methods and semantic orientation methods. though some pioneer researches explored the approaches for english reviews classification, few jobs have been done on sentiment classification for chinese reviews. the machine learning approach based on string kernel for sentiment classification on reviews written in chinese was proposed in this paper. data experiment shows the capability of this approach.	-5	3.0
an ontology-based sentiment classification methodology for online consumer reviews	this paper presents a method of ontologybased sentiment classification to classify and analyse online product reviews of consumers.	-5	2.9
a two-stage framework for cross-domain sentiment classification	supervised sentiment classification systems are typically domainspecific, and the performance decreases sharply when transferred from one domain to another domain. building these systems involves annotating a large amount of data for every domain, which needs much human labor. so, a reasonable way is to utilize labeled data in one existed (or called source) domain for sentiment classification in target domain. to address this problem, we propose a twostage framework for crossdomain sentiment classification. at the “building a bridge” stage, we build a bridge between the source domain and the target domain to get some most confidently labeled documents in the target domain; at the “following the structure” stage, we exploit the intrinsic structure, revealed by these most confidently labeled documents, to label the targetdomain data. the experimental results indicate that the proposed approach could improve the performance of crossdomain sentiment classification dramatically.highlights? propose a twostage framework for sentiment classification. ? build a bridge between the source and target domain. ? exploit the intrinsic structure. ? experimental results indicate the efficiency of proposed approach.	-2	3.7142857142857144
sentiment classification: a lexical similarity based approach for extracting subjectivity in documents	with the growth of social media, document sentiment classification has become an active area of research in this decade. it can be viewed as a special case of topical classification applied only to subjective portions of a document (sources of sentiment). hence, the key task in document sentiment classification is extracting subjectivity. existing approaches to extract subjectivity rely heavily on linguistic resources such as sentiment lexicons and complex supervised patterns based on partofspeech (pos) information. this makes the task of subjective feature extraction complex and resource dependent. in this work, we try to minimize the dependency on linguistic resources in sentiment classification. we propose a simple and statistical methodology called review summary (rsumm) and use it in combination with wellknown feature selection methods to extract subjectivity. our experimental results on a movie review dataset prove the effectiveness of the proposed methodology.	-2	3.5714285714285716
cross-lingual sentiment classification via bi-view non-negative matrix tri-factorization	recently the sentiment classification problem interests the researchers over the world, but most sentiment corpora are in english, which limits the research progress on sentiment classification in other languages. crosslingual sentiment classification aims to use annotated sentiment corpora in one language (e.g. english) as training data, to predict the sentiment polarity of the data in another language (e.g. chinese). in this paper, we design a biview nonnegative matrix trifactorization (bnmtf) model for the crosslingual sentiment classification problem. we employ machine translation service so that both training and test data is able to have two representation, one in source language and the other in target language. our bnmtf model is derived from the nonnegative matrix trifactorization models in both languages in order to make more accurate prediction. our bnmtf model has three main advantages (1) combining the information from two views (2) incorporating the lexical knowledge and training document label knowledge (3) adding information from test documents. experimental results show the effectiveness of our bnmtf model, which can outperform other baseline approaches to crosslingual sentiment classification.	-2	3.5714285714285716
imbalanced sentiment classification	sentiment classification has undergone significant development in recent years. however, most existing studies assume the balance between negative and positive samples, which may not be true in reality. in this paper, we investigate imbalanced sentiment classification instead. in particular, a novel clusteringbased stratified undersampling framework and a centroiddirected smoothing strategy are proposed to address the imbalanced class and feature distribution problems respectively. evaluation across different datasets shows the effectiveness of both the undersampling framework and the smoothing strategy in handling the imbalanced problems in real sentiment classification applications.	-2	3.4285714285714284
sentiment classification based on ontology and svm classifier	there are a lot of text documents on the web which contain opinions or sentiments about an object such as software reviews, product reviews, movies reviews, music reviews, and book reviews etc. opinion mining or sentiment classification aim to extract the features on which the reviewers express their opinions and determine they are positive or negative. in this paper we proposed an ontology based combination approach to enhance the existing approaches of the sentiment classification. we also used the supervised learning techniques for classification of the sentiments in the software reviews. this paper proposed the combination of using natural language processing techniques (nlp), ontology based on formal concept analysis (fca) design, and support vector machine (svm) for classifying the software reviews are positive, negative or neutral.	-3	3.25
ensemble learning for sentiment classification	this paper presents an ensemble learning method for sentiment classification of reviews. the diversity among the machine learning algorithms for sentiment classification with different settings, which includes different features, different weight measures and the modeling of negation, is investigated in three domains, which gives a space for improving the performance. then the ensemble learning framework, stacking generalization is introduced based on different algorithms with different settings, and compared with the majority voting. according to the characteristic of reviews, the opinion summary of review is proposed in this paper, which is composed of the first two and last two sentences of review. results show that stacking has been proven to be consistently effective over all domains, working better than majority voting, and that using the opinion summary can improve the performance further.	-1	3.6666666666666665
sentiment classification of chinese traveler reviews by support vector machine algorithm	nowadays, online wordofmouth has turned to be a very important resource for electronic businesses. how to analyze user generated reviews and to classify them into different sentiment classes is gradually becoming a question that people pay close attention to. in this field, special challenges are associated with the mining of traveler reviews. at present, there is some research on sentiment analysis for english traveler generated reviews, but very few studies pay attention to sentiment analysis for traveler reviews in chinese. china is the largest country in terms of the number of internet users. internet technologies are gradually playing more and more important roles for many industries including tourism industry. the lack of sentiment analysis methods will block the use of wordofmouth for tourism industry in china. to solve the problem, this study conducts an exploring research on sentiment analysis to chinese traveler reviews by support vector machine (svm) algorithm. the experiment data of chinese reviews for hotels are downloaded from www.ctrip.com, the largest online travel agency in china. empirical results indicate that, comparing to prior studies on english reviews, svm algorithm can gain a very well performance of sentiment classification for traveler reviews in chinese.	-4	3.0
cross-lingual sentiment classification via bi-view non-negative matrix tri-factorization	summary recently the sentiment classification problem interests the researchers over the world, but most sentiment corpora are in english, which limits the research progress on sentiment classification in other languages. crosslingual sentiment classification aims to use annotated sentiment corpora in one language (e.g. english) as training data, to predict the sentiment polarity of the data in another language (e.g. chinese). in this paper, we design a biview nonnegative matrix trifactorization (bnmtf) model for the crosslingual sentiment classification problem. we employ machine translation service so that both training and test data is able to have two representation, one in source language and the other in target language. our bnmtf model is derived from the nonnegative matrix trifactorization models in both languages in order to make more accurate prediction. our bnmtf model has three main advantages (1) combining the information from two views (2) incorporating the lexical knowledge and training document label knowledge (3) adding information from test documents. experimental results show the effectiveness of our bnmtf model, which can outperform other baseline approaches to crosslingual sentiment classification.	-2	3.2857142857142856
is machine translation ripe for cross-lingual sentiment classification?	recent advances in machine translation (mt) have brought forth a new paradigm for building nlp applications in lowresource scenarios. to build a sentiment classifier for a language with no labeled resources, one can translate labeled data from another language, then train a classifier on the translated text. this can be viewed as a domain adaptation problem, where labeled translations and test data have some mismatch. various prior work have achieved positive results using this approach. in this opinion piece, we take a step back and make some general statements about crosslingual adaptation problems. first, we claim that domain mismatch is not caused by mt errors, and accuracy degradation will occur even in the case of perfect mt. second, we argue that the crosslingual adaptation problem is qualitatively different from other (monolingual) adaptation problems in nlp; thus new adaptation algorithms ought to be considered. this paper will describe a series of carefullydesigned experiments that led us to these conclusions. 1	-2	3.4285714285714284
combining collaborative filtering and sentiment classification for improved movie recommendations	summary recommender systems are traditionally of following three types contentbased, collaborative filtering and hybrid systems. contentbased methods are limited in their applicability to textual items only, whereas collaborative filtering due to its accuracy and its black box approach has been used widely for different kinds of item recommendations. hybrid method, the third approach, tries to combine content and collaborative approaches to improve the recommendation results. in this paper, we present an alternative approach to a hybrid recommender system that improves the results of collaborative filtering by incorporating a sentiment classifier in the recommendation process. we have explored this idea through our experimental work in movie review domain, with collaborative filtering doing first level filtering and the sentiment classifier performing the second level of filtering. the final recommendation list is a more accurate and focused set.	-2	3.4285714285714284
using objective words in sentiwordnet to improve sentiment classification for word of mouth	to improve the performance of sentiment classification for word of mouth (wom), this research reevaluates objective sentiment words in a sentiment lexicon, sentiwordnet. sentiwordnet provides each synonymous set with three sentiment values regarding positivity, negativity, and objectivity. as the evaluation of sentiments of words in wom is useful for sentiment classification, sentiwordnet has become a public and popular lexicon resource. this sentiment lexicon includes 117,659 entries but 93.75% of them have a stronger objective sentiment tendency than their sentimental counterparts. a sentiment lexicon such as sentiwordnet with so many objective words may suffer from noise in the application of sentiment classification. this research revises sentiment value and tendency for objective words in sentiwordnet based on assessment of the corelevance of each objective word and its associated sentiment sentences. experiments show that this proposed approach is significantly better than the traditional nonrevised approach as evaluated by the classification accuracy criterion.	0	4.0
appraisal expression recognition with syntactic path for sentence sentiment classification	an appraisal expression is described as a collocation of the polarity word and its modified target, which can be considered as an atomic unit expressing an evaluative stance towards a target. recognizing appraisal expressions is essential for sentence sentiment classification. however, the relevant research is far from enough. this paper proposes a novel method that uses syntactic paths to recognize appraisal expressions. compared with the previous work, the proposed syntactic path based method has two advantages 1) it automatically explores syntactic knowledge, and 2) it covers more syntactic relationships between polarity words and targets. based on these, this paper applies appraisal expressions to sentence sentiment classification. some novel features based on appraisal expressions, including semantic features, syntactic features, lexical features and polarity features, are designed to classify sentiment sentences as positive or negative. experimental results on the camera and mp3 player domains show...	-2	3.2857142857142856
sentiment classification based on ontology and svm classifier	there are a lot of text documents on the web which contain opinions or sentiments about an object such as software reviews, product reviews, movies reviews, music reviews, and book reviews etc. opinion mining or sentiment classification aim to extract the features on which the reviewers express their opinions and determine they are positive or negative. in this paper we proposed an ontology based combination approach to enhance the existing approaches of the sentiment classification. we also used the supervised learning techniques for classification of the sentiments in the software reviews. this paper proposed the combination of using natural language processing techniques (nlp), ontology based on formal concept analysis (fca) design, and support vector machine (svm) for classifying the software reviews are positive, negative or neutral.	-3	2.75
sentiment classification of documents based on latent semantic analysis	sentiment classification has attracted increasing interest from natural language processing. the goal of sentiment classification is to automatically identify whether a given piece of text expresses positive or negative opinion on a topic of interest. latent semantic analysis (lsa) has been shown to be extremely useful in information retrieval. in this paper, we propose a new method, based on lsa and support vector machine (svm) to improve the sentiment classification performance. this method takes the advantage of both lsa and svm. during the training process, svm makes use of its excellent classification ability to conduct the sentiment classification first. to show that our method is feasible and effective, we designed two experiments and the experimental result shows that the introduction of svm outperforms the other experiment in precision of the polarity analysis.	-2	3.2857142857142856
sentiment classification for chinese product reviews using an unsupervised internet-based method	sentiment classification aims at mining opinions of customers for a certain product by automatically classifying the reviews into positive or negative opinions. with the fast developing of world wide web applications, sentiment classification would have huge opportunity to help automatic analysis of customers’ opinions from the web information. opinion mining will benefit both consumers and sellers. up to now, it is still a complicated task with great challenge. though some pioneer researches explored the approaches for english review classification, few works have been done on sentiment classification for chinese reviews. in this paper, we focus on a specific domain—cell phone review and propose an internetbased approach for chinese product review mining. the experimental results show the effectiveness of the proposed approach in sentiment classification for chinese product reviews.	-5	2.5
ontology based combined approach for sentiment classification	text documents contain opinions or sentiments about the objects, such as movie reviews, book reviews, and product reviews etc. sentiment analysis is the mining the sentiment or opinion words and identification and analysis of the opinion and arguments in the text. in this paper, we proposed an ontology based combination approach to enhance the exits approaches of sentiment classifications and use supervised learning techniques for classifications.	-4	2.5555555555555554
cross-lingual sentiment classification via bi-view non-negative matrix tri-factorization	recently the sentiment classification problem interests the researchers over the world, but most sentiment corpora are in english, which limits the research progress on sentiment classification in other languages. crosslingual sentiment classification aims to use annotated sentiment corpora in one language (e.g. english) as training data, to predict the sentiment polarity of the data in another language (e.g. chinese). in this paper, we design a biview nonnegative matrix trifactorization (bnmtf) model for the crosslingual sentiment classification problem. we employ machine translation service so that both training and test data is able to have two representation, one in source language and the other in target language. our bnmtf model is derived from the nonnegative matrix trifactorization models in both languages in order to make more accurate prediction. our bnmtf model has three main advantages (1) combining the information from two views (2) incorporating the lexical knowledge and training document label knowledge (3) adding information from test documents. experimental results show the effectiveness of our bnmtf model, which can outperform other baseline approaches to crosslingual sentiment classification.	-2	3.2857142857142856
semantic-oriented sentiment classification for chinese product reviews: an experimental study of book and cell phone reviews	sentiment classification is an automatic opinion classification method to classify the product reviews on web into positive or negative opinions to help consumers or sellers to understand the opinions and evaluations from existing customers. semanticoriented approach is one of the recent developments in sentiment classification. up to now, most research of sentiment classification is on english reviews,and little work has been done on chinese reviews using sentiment classification. the detailed techniques used in english review cannot be applied directly to chinese reviews due to the different characteristics between these two languages. this study modified and improved the semanticoriented approach to a 6step process for chinese review, focusing on the modification and improvement on the text segmentation and reference words pairs (rwps) identification. two experiments were conducted on book reviews and cell phone reviews. the results show that the performances of the proposed approach are comparable to those of the existing english reviews classification studies.	-8	2.0
an unsupervised snippet-based sentiment classification method for chinese unknown phrases without using reference word pairs	this work presents an unsupervised snippetbased sentiment classification method for chinese unknown sentiment phrases, which is also applicable to other languages theoretically. unlike existing semantic orientation (so) methods, our proposed method does not require any reference word pairs (rwps) for predicting the sentiments of phrases. the results of preliminary experiments show that our proposed method is highly effective and achieves over 80% accuracy and fmeasures with relatively fewer queries. an experiment of opinion extraction using a public chinese ugc corpus also shows promising results.	-3	2.75
identifying high-impact sub-structures for convolution kernels in document-level sentiment classification	convolution kernels support the modeling of complex syntactic information in machinelearning tasks. however, such models are highly sensitive to the type and size of syntactic structure used.	-1	3.1666666666666665
augmenting chinese online video recommendations by using virtual ratings predicted by review sentiment classification	in this paper we aim to resolve the recommendation problem by using the virtual ratings in online environments when user rating information is not available. as a matter of fact, in most of current websites especially the chinese videosharing ones, the traditional pure rating based collaborative filtering recommender methods are not fully qualified due to the sparsity of rating data. motivated by our prior work on the investigation of user reviews that broadly appear in such sites, we hence propose a new recommender algorithm by fusing a selfsupervised emoticonintegrated sentiment classification approach, by which the missing useritem rating matrix can be substituted by the virtual ratings which are predicted by decomposing user reviews as given to the items. to test the algorithm's practical value, we have first identified the selfsupervised sentiment classification's higher performance by comparing it with a supervised approach. moreover, we conducted a statistic evaluation method to show the effectiveness of our recommender system on improving chinese online video recommendations' accuracy.	-3	2.75
verb oriented sentiment classification	sentiment analysis refers to a broad range of fields of natural language processing, computational linguistics and text mining. sentiment classification of reviews and comments has emerged as the most useful application in the area of sentiment analysis. although sentiment classification generally is carried out at the document level, accurate results require analysis at the sentence level. bag of words and feature based sentiment are the most popular approaches used by researchers to deal with sentiment classification of opinions about products such as movies, electronics, cars etc. until recently most classification techniques have considered adjectives, adverbs and nouns as features. this paper proposes a new approach based on verb as an important opinion term particularly in social domains. we extract opinion structures which consider verb as the core element. sentiment orientation is recognized from sentiments inside of opinion structures and their association with the social issue. experimental results show that considering verbs improves the performance of sentiment classification.	-1	3.0
a novel approach to sentiment classification	we introduce a novel approach to sentiment classification. our reasoning through search (rts) technique uses existing labeled data, query formation strategies, and a case base to estimate the sentiment of a text review. unlike previous systems, when classifying a document from a domain that the system does not have explicit, indomain training data, our classification system leverages domain relatedness and a case base of labeled reviews to perform the classification. while the system does require labeled training data, it does not rely on the guaranteed presence of indomain labeled training data. reasoning through search	-6	2.1818181818181817
super parsing:sentiment classification with review extraction	this paper describes the sentiment classification with review extraction. whole process can be illustrated logically as (1) extract the review expressions on specific subjects and attach sentiment tag and weight to each expression; (2) calculate the sentiment indicator of each tag by accumulating the weights of all the expression with the corresponding tag; (3) given the indicators on different tags, use a classifier to predict the sentiment label of the text. a system approximate text analysis (ata) is used for review extraction in stage 1. it follows the idea of super parsing, which enables nonadjacent constituents to be merged to deduce a new one. to traverse the valid constituent combinations in super parsing, an algorithm named candidate list algorithm (cla) is proposed. then the performance of three kinds of classifiers (a simple linear classifier, svm and decision tree) in stage 3 is studied. the experiments on online documents show that the svm algorithm achieves the best performance	-8	1.9230769230769231
a probabilistic approach to tweets' sentiment classification	prior to 2003, mankind generated a total of about 5 exabyte's of contents. now, we generate this amount of contents in about two days! the spread of generic (as twitter, facebook or google+) or specialized (as linked in or viadeo) social networks allows sharing opinions on different aspects of life every day. therefore this information is a rich source of data for opinion mining and sentiment analysis. this paper introduces a novel approach to the sentiment analysis based on the weighted word pairs obtained by the use of the latent dirichlet allocation (lda) approach. the proposed methodology aims at identifying a wordbased graphical model for depicting and mining a positive or negative attitude towards a topic. for the evaluation of the proposed approach a challenging scenario has been set the realtime analysis of tweets. the experimental evaluation shows how the proposed approach is effective and satisfactory.	0	3.2
text mining facebook status updates for sentiment classification	in recent years, text mining and sentiment analysis have received great attention due to the abundance of opinion data that exist in social networks such as facebook, twitter, etc. sentiments are projected on these media using texts for expressing feelings such as friendship, social support, anger, happiness, etc. existing sentiment analysis studies tend to identify user behaviors and state of minds but remain insufficient due to complexities in conveyed texts. in this research paper, we focus on the usage of text mining for sentiment classification. illustration is performed on tunisian users' statuses on facebook posts during the “arabic spring” era. our aim is to extract useful information, about users' sentiments and behaviors during this sensitive and significant period. for that purpose, we propose a method based on support vector machine (svm) and nai04ve bayes. we also construct a sentiment lexicon, based on the emoticons, interjections and acronyms', from extracted statuses updates. moreover, we perform some comparative experiments between two machine learning algorithms svm and nai04ve bayes through a training model for sentiment classification.	0	3.2
sentiment classification by sentence level semantic orientation using sentiwordnet from online reviews and blogs	sentiment analysis is the procedure by which information is extracted from the opinions, appraisals and emotions of people in regards to entities, events and their attributes. in decision making, the opinions of others have a significant effect on customers ease in making choices regards to online shopping, choosing events, products, entities. in this paper, the rule based domain independent sentiment analysis method is proposed. the proposed method classifies subjective and objective sentences from reviews and blog comments. the semantic score of subjective sentences is extracted from sentiwordnet to calculate their polarity as positive, negative or neutral based on the contextual sentence structure. the results show the effectiveness of the proposed method and it outperforms the machine learning methods. the proposed method achieves an accuracy of 87% at the feedback level and 83% at the sentence level for comments and 97% at feedback and 86 % at sentences for customer reviews.	-2	2.7142857142857144
a review of opinion mining and sentiment classification framework in social networks	the web has dramatically changed the way we express opinions on certain products that we have purchased and used, or for services that we have received in the various industries. opinions and reviews can be easily posted on the web, such as in merchant sites, review portals, blogs, internet forums, and much more. these data are commonly referred to as usergenerated content or usergenerated media. both the product manufacturers, as well as potential customers are very interested in this online ‘wordofmouth’, as it provides product manufacturers information on their customers likes and dislikes, as well as the positive and negative comments on their products whenever available, giving them better knowledge of their products limitations and advantages over competitors; and also providing potential customers with useful and ‘firsthand’ information on the products and/or services to aid in their purchase decision making process. this paper discusses the existing works on opinion mining and sentiment classification of customer feedback and reviews online, and evaluates the different techniques used for the process. it focuses on the areas covered by the evaluated papers, points out the areas that are well covered by many researchers and areas that are neglected in opinion mining and sentiment classification which are open for future research opportunity.	-4	2.3333333333333335
identifying high-impact sub-structures for convolution kernels in document-level sentiment classification	convolution kernels support the modeling of complex syntactic information in machinelearning tasks. however, such models are highly sensitive to the type and size of syntactic structure used. it is therefore an important challenge to automatically identify high impact substructures relevant to a given task. in this paper we present a systematic study investigating (combinations of) sequence and convolution kernels using different types of substructures in documentlevel sentiment classification. we show that minimal substructures extracted from constituency and dependency trees guided by a polarity lexicon show 1.45 point absolute improvement in accuracy over a bagofwords classifier on a widely used sentiment corpus.	-1	3.0
sentiment classification of short chinese sentences	we explore an extreme case of text classification. the short statements in microblogs were collected, and were associated by a category based on the sentiment indicated by the associated icons. we evaluated different methods that assigned the categories with just the wordings in the short statements. short statements in microblogs are harder to classify because of the shortage of context, yet it is not rare for the statements to include words that may be linked to sentiments directly. in this work, we considered two polarities of sentiments negative and positive. we employed the statistical information about the word usage, a dictionary for chinese synonyms, and an emotional phrases dictionary to convert short statements into vectors, and applied techniques of support vector machines and probabilistic modeling for the classification task. the results of classification varied with the classification methods and experimental setups. the best one exceeded 80%, but the lowest just made 55%.	-3	2.5
sentiment classification of customer reviews on electric products	a lot of terms represent the speaker's evaluation of the item. this evaluative character of the word is called its semantic orientation. the word with positive semantic orientation implies that the item is desirable, and on the other hand, the word with negative semantic orientation implies that the item is not desirable. we propose a method to estimate the semantic orientation(positive or negative) of japanese products reviews, in which a pair of noun and adjective are selected as the corpus to determine the semantic orientation of the reviews and the semantic orientation scores of the review are calculated according to the corpus. the words which change the semantic orientation of a word called as contextual valence shifter such as not, very quite are considered in the algorithm to determine the semantic orientation. in order to empirically evaluate the performance of the classification method for japanese documents, 1400 reviews of two electric products, lcd and mp3 music player, are classified to two categories (positive or negative).	-5	2.0
sentiment classification considering negation and contrast transition	negation and contrast transition are two kinds of linguistic phenomena which are popularly used to reverse the sentiment polarity of some words and sentences. in this paper, we propose an approach to incorporate their classification information into our sentiment classification system first, we classify sentences into sentiment reversed and nonreversed parts. then, represent them as two different bagsofwords. third, present three general strategies to do classification with twobagofwords modeling. we collect a largescale product reviews involving five domains and conduct our experiments on them. the experimental results show that incorporating both negation and contrast transition information is effective and performs robustly better than traditional machine learning approach (based on onebagofwords modeling) across five different domains.	-4	2.111111111111111
domain independent sentiment classification with many lexicons	sentiment lexicons are language resources widely used in opinion mining and important tools in unsupervised sentiment classification. we present a comparative study of sentiment classification of reviews on six different domains using sentiment lexicons from different sources. our results highlight the tendency of a lexicon鈥檚 performance to be imbalanced towards one class, and indicate lexicon accuracy varies with the target domain. we propose an approach that combines information from different lexicons to make classification decisions and achieve more robust results that consistently improve our baseline across all domains tested. these are further refined by a domain independent score adjustment that mitigates the effect of the recall imbalance seen on some of the results	-2	2.5714285714285716
joint bilingual sentiment classification with unlabeled parallel corpora	most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resourcerich languages to resourcepoor languages. we present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. we rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%8.12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudoparallel data from machine translation engines.	-2	2.4285714285714284
text sentiment classification for sns-based marketing using domain sentiment dictionary	in this paper, we propose a new method of classifying the sentiment behind tweets that contains formal and informal vocabulary. previous methods used only formal vocabulary to classify the sentiments behind the sentences. however, these methods are ineffective in classifying texts since internet users make sentences using informal vocabulary. in addition, we use emotion based vocabulary to classify the sentiment behind texts. feature vectors extracted from the vocabulary are classified by support vector machine (svm). our proposed method shows a strong performance in the classifying the emotion behind the text.	-1	2.6666666666666665
ontology based combined approach for sentiment classification	text documents contain opinions or sentiments about the objects, such as movie reviews, book reviews, and product reviews etc. sentiment analysis is the mining the sentiment or opinion words and identification and analysis of the opinion and arguments in the text. in this paper, we proposed an ontology based combination approach to enhance the exits approaches of sentiment classifications and use supervised learning techniques for classifications.	-4	2.111111111111111
incorporating lexicon knowledge into svm learning to improve sentiment classification	a sentiment classifier for sentiment classification of content. an aspect classifier is configured to classify content as being related to a particular aspect of information, the aspect classifier incorporating at least a portion of the domain specific sentiment lexicon. a polarity classifier is then configured to classify the content classified by the aspect classifier as having one of a positive sentiment of the particular aspect of information, a negative sentiment of the particular aspect of information or as having no sentiment as to the particular aspect of information. the polarity classifier also incorporating at least a portion of the domain specific sentiment lexicon.	-2	2.4285714285714284
do neighbours help?: an exploration of graph-based algorithms for cross-domain sentiment classification	this paper presents a comparative study of graphbased approaches for crossdomain sentiment classification. in particular, the paper analyses two existing methods an optimisation problem and a ranking algorithm. we compare these graphbased methods with each other and with the other stateoftheart approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem. analysis of the best parameters for graphbased algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.	-1	2.8333333333333335
sentiment classification for indonesian message in social media	nowadays, classifying sentiment from social media has been a strategic thing since people can express their feeling about something in an easy way and short text. mining opinion from social media has become important because people are usually honest with their feeling on something. in our research, we tried to identify the problems of classifying sentiment from indonesian social media. we identified that people tend to express their opinion in text while the emoticon is rarely used and sometimes misleading. we also identified that the indonesian social media opinion can be classified not only to positive, negative, neutral and question but also to a special mix case between negative and question type. basically there are two levels of problem word level and sentence level. word level problems include the usage of punctuation mark, the number usage to replace letter, misspelled word and the usage of nonstandard abbreviation. in sentence level, the problem is related with the sentiment type such as mentioned before. in our research, we built a sentiment classification system which includes several steps such as text preprocessing, feature extraction, and classification. the text preprocessing aims to transform the informal text into formal text. the word formalization method in that we use is the deletion of punctuation mark.	-1	2.5
cross-domain sentiment classification using a two-stage method	in this paper, we give out a twostage approach for domain adaptation problem in sentiment classification. in the first stage, based on our observation that customers often use different words to comment on the similar topics in the different domains, we regard these common topics as the bridge to link the different domainspecific features. we propose a novel topic model named transferplsa to extract the topic knowledge between different domains. through these common topics, the features in the source domain are corresponded to the target features, so that those domainspecific knowledge can be transferred across different domains. in the second step, we use the classifier trained on the labeled examples in the source domain to pick up some informative examples in the target domain. then we retrain the classifier on these selected examples, so that the classifier is adapted for the target domain. experimental results on sentiment classification in four different domains indicate that our method outperforms other traditional methods.	-4	1.8888888888888888
enhancing sentiment classification performance using bi-tagged phrases	sentiment analysis research mainly aims to determine the orientation of an opinionated stretch of text into positive or negative polarity. the key motivation of sentiment analysis is getting to know what consumers think about products and services by analyzing their opinions on online portals, blogs, discussion boards, reviews etc. the main objective of this paper is to incorporate the information of posbased sentimentrich phrases in a machinelearning algorithm that determines the semantic orientation of a given text. in this paper, bitagged phrases are used as features in combination with unigram features for sentiment classification. joint feature vectors of unigrams and bitagged phrases have high dimensions consisting of noisy and irrelevant features. therefore, a feature selection method is used to select only relevant features from the feature vector. experimental results show that the combination of prominent unigrams and bitagged phrases outperforms other features for sentiment classification in a movie review dataset.	0	2.6
sentiment classification of movie reviews by supervised machine learning approaches	large volumes of data are available in the web. the discussion forum, review sites, blogs and news corpora are some of the opinion rich resources. the opinions obtained from those can be classified and used for gathering online customer  preferences. techniques are being applied to design a system that identifies and classify opinions spread largely in the internet. few different problems such as sentiment classification, feature based classification and handling negotiations are predominating this research community. this paper studies online movie reviews using sentiment analysising approaches. in this study, sentiment classification techniques wereapplied to movie reviews. specifically, we compared three supervised machine learning approaches svm, navie bayes and knn for sentiment classification of reviews. empirical results states that svm approachoutperformed the navie bayes and knn approaches, and the training dataset had a large number of reviews, svm approach reached accuracies of atleast 80%.	0	2.6
research on sentence sentiment classification based on chinese sentiment word table	this paper presents the weighted linear combination method for the sentence sentiment classification based on chinese sentiment word table.in proposed method,firstly,chinese sentiment word table is constructed by using five existing dictionaries, secondly,automatically identifying method is explored for the sentence sentiment classification using the weighted linear combination method.the experiment results indicate that the f value of sentence sentiment classification with word language granularity reaches 78.2%,and adding the negative phrase to language granularity,the f value of sentence sentiment classification has increased by 4.14%.	-4	2.0
empirical study of sentiment classification for chinese microblog based on machine learning	with the development of microblog,it is more convenient to comment on the web.up to now,there are very few studies on the sentiment classification for chinese microblog,therefore this paper uses three machine learning algorithms,three kinds of feature selection methods and three feature weight methods to study the sentiment classification for chinese microblog.the experimental results indicate that the performance of svm is best in three machine learning algorithms,ig is the better feature selection method compared to the other methods,and tfidf is best fit for the sentiment classification in chinese microblog.combining the three factors the conclusion can be drawn that the performance of combination of svm,ig and tfidf is best.for the movie domain it is found that the sentiment classification depends on the review style.	-1	2.3333333333333335
a new term weighting method by introducing class information for sentiment classification of textual data	with the popularity of text based communication tools such as blogs, plurk, twitter, and so on, customers can easily express their opinions, reviews or comments about purchased products/services. these personal opinions, especially negative comments, might have a significant influence on other consumers' purchasing decisions. therefore, how to detect users' sentiment from textual data to assist companies to carefully respond to customers' comments has become a crucial task. recently, machine learning methods have been considered as one of solutions in sentiment classification. when applying machine learning approaches to classify sentiment, term frequency (tf), term presence (tp) and term frequencyinverse document frequency (tfidf) usually have been employed to describe collected textual data. however, these traditional term weighting methods cannot have positive influence on improving classification performance.	-2	2.142857142857143
sentiment classification approaches – a review	with the outbreak of web 2.0, several types of social media such as blogs, discussion forums, review websites and community websites that can be useful for determine the public; sentiment and opinion, towards products and services. recent surveys impart that online reviews have greater economic impact compared to claric media. the major task of opinion mining or sentiment analysis is used to find the subjective information from the user defined opinions. the expressed opinions may be positive, negative or neutral. machine learning techniques are widely used for sentiment classification. in this paper, we look insight into the various machine learning techniques for sentiment classification and research challenges exist in this field.	0	2.2
robust sense-based sentiment classification	the new trend in sentiment classification is to use semantic features for representation of documents. we propose a semantic space based on wordnet senses for a supervised documentlevel sentiment classifier. not only does this show a better performance for sentiment classification, it also opens opportunities for building a robust sentiment classifier. we examine the possibility of using similarity metrics defined on wordnet to address the problem of not finding a sense in the training corpus. using three popular similarity metrics, we replace unknown synsets in the test set with a similar synset from the training set. an improvement of 6.2% is seen with respect to baseline using this approach.	-2	2.142857142857143
sentiment classification of review documents using phrase patterns	sentiment analysis determines the polarity of text whether it belongs to positive or negative polarity. one motivation for sentiment analysis research is the need for user and ecommerce companies to know the public opinion from blogs, online forums, reviews about certain products, services, topics etc. phrases are important in extracting contextual information which is important for sentiment classification. phrases can convey sentiment information more efficiently than individual words. in this paper, sentimentrich phrases are extracted using partofspeech (pos) based rules and dependency relation in the document that are capable of extracting contextual and syntactic information from the document. next, semantic orientations of these phrases are calculated using pointwise mutual information (pmi) based method. finally, review document is classified after aggregating the semantic orientation of all the phrases into positive or negative polar document.	0	2.4
data mining for tweet sentiment classification	the goal of this master thesis is to classify short twitter messages with respect to their sentiment using data mining techniques. twitter messages, or tweets, are limited to 140 characters. this limitation makes it more difficult for people to express their sentiment and as a consequence, the classification of the sentiment will be more difficult as well. the sentiment can refer to two different types emotions and opinions. this research is solely focused on the sentiment of opinions. these opinions can be divided into three classes positive, neutral and negative. the tweets are then classified with an algorithm to one of those three classes.known supervised learning algorithms as support vector machines and naive bayes are used to create a prediction model. before the prediction model can be created, the data has to be preprocessed from text to a fixedlength feature vector. the features consist of sentimentwords and frequently occurring words that are predictive for the sentiment. the learned model is then applied to a test set to validate the model. the data that is considered in this research is based on two datasets, one from sananalytics and a selfbuilt twitter dataset.when the models are applied and tested insample the results were quite acceptable. however outofsample, with crossvalidation the results were disappointing.	-1	2.1666666666666665
cross-domain sentiment classification using a two-stage method	in this paper, we give out a twostage approach for domain adaptation problem in sentiment classification. in the first stage, based on our observation that customers often use different words to comment on the similar topics in the different domains, we regard these common topics as the bridge to link the different domainspecific features. we propose a novel topic model named transferplsa to extract the topic knowledge between different domains. through these common topics, the features in the source domain are corresponded to the target features, so that those domainspecific knowledge can be transferred across different domains. in the second step, we use the classifier trained on the labeled examples in the source domain to pick up some informative examples in the target domain. then we retrain the classifier on these selected examples, so that the classifier is adapted for the target domain. experimental results on sentiment classification in four different domains indicate that our method outperforms other traditional methods.	-4	1.7777777777777777
a cross-domain adaptation method for sentiment classification using probabilistic latent analysis	sentiment classification is becoming attractive in recent years because of its potential commercial applications. it exploits supervised learning methods to learn the classifiers from the annotated training documents. the challenge in sentiment classification lies in that the sentiment domains are diverse, heterogeneous and fastgrowing. the classifiers trained on one domain (source domain) could not classify a document from another domain (target domain). the domain adaptation technique is to address the problem by making use of labeled samples in the source domain, and unlabeled samples in the target domain. this paper presents a new solution, a crossdomain topic indexing (cdti) method, with which a common semantic space is found from the prior betweendomain term correspondences and the term cooccurrences in the crossdomain documents. these observations are characterized with the mixture model in cdti, with each component being a possible topic shared by the source and target domains. such common topics are found to index the crossdomain content. we evaluate the algorithms on a multidomain sentiment classification task, which shows that cdti outperforms the stateoftheart domain adaptation method, i.e. spectral feature alignment (sfa), and the traditional latent semantic indexing method.	-2	2.0
a weakly supervised approach to chinese sentiment classification using partitioned self-training	with the rapid evolution of documents on the world wide web which express opinions, there exists an increasing demand for developing such a sentiment analysis technique that can easily adapt to new domains with minimum supervision. this article introduces a novel weakly supervised approach for chinese sentiment classification. the approach applies a variant of selftraining algorithm on two partitions split from test dataset, and combines classification results of the two partitions into a pseudolabelled training set and an unlabelled test set, then trains an initial classifier on the pseudolabelled training set and adopts a standard selflearning cycle to obtain the overall classification results. experiments on the four datasets from two domains show that our approach has competitive advantages over baseline approaches; it even outperforms the supervised approach in some of the datasets despite using no labelled documents.	0	2.4
transfer learning using twitter data for improving sentiment classification of turkish political news	in this paper, we aim to determine the overall sentiment classification of turkish political columns. that is, our goal is to determine whether the whole document has positive or negative opinion regardless of its subject. in order to enhance the performance of the classification, transfer learning is applied from unlabeled twitter data to labeled political columns. a variation of selftaught learning has been proposed, and implemented for the classification. different machine learning techniques, including support vector machine, maximum entropy classification, and naivebayes has been used for the supervised learning phase. in our experiments we have obtained up to 26聽% increase in the accuracy of the classification with the inclusion of the twitter data into the sentiment classification of turkish political columns using transfer learning.	0	2.4
adaptation and use of subjectivity lexicons for domain dependent sentiment classification	sentiment analysis refers to the automatic extraction of sentiments from a natural language text. we study the effect of subjectivitybased features on sentiment classification on two lexicons and also propose new subjectivitybased features for sentiment classification. the subjectivitybased features we experiment with are based on the average word polarity and the new features that we propose are based on the occurrence of subjective words in review texts. experimental results on hotel and movie reviews show an overall accuracy of about 84% and 71% in hotel and movie review domains respectively, improving the baseline using just the average word polarities by about 2% points.	-1	2.1666666666666665
instance selection and instance weighting for cross-domain sentiment classification via pu learning	due to the explosive growth of the internet online reviews, we can easily collect a large amount of labeled reviews from different domains. but only some of them are beneficial for training a desired targetdomain sentiment classifier. therefore, it is important for us to identify those samples that are the most relevant to the target domain and use them as training data. to address this problem, a novel approach, based on instance selection and instance weighting via pu learning, is proposed. pu learning is used at first to learn an intargetdomain selector, which assigns an intargetdomain probability to each sample in the training set. for instance selection, the samples with higher intargetdomain probability are used as training data; for instance weighting, the calibrated intargetdomain probabilities are used as sampling weights for training an instanceweighted naive bayes model, based on the principle of maximum weighted likelihood estimation. the experimental results prove the necessity and effectiveness of the approach, especially when the size of training data is large. it is also proved that the larger the kullbackleibler divergence between the training and test data is, the more effective the proposed approach will be.	0	2.4
sentiment classification with polarity shifting detection	sentiment classification is now a hot research issue in the community of natural language processing and the bagofwords based machine learning approach is the stateoftheart for this task.	0	2.2
sentiment classification using information extraction technique	this paper explores the sentiment classification with information extraction (ie) approach. the ie approach here is required to detect the sentiment expressions on specific subject (person, product, company and so on) and then to evaluate the sentiment strength and/or the validation of them. our method can be illustrated logically as (1) from a given text, extract the sentiment expressions on the specific subjects and attach certain sentiment tag and weight to each of them; (2) calculate the sentiment indicator for each sentiment genre by accumulating the weights of all the expression with the corresponding tag; (3) given the indicators on different sentiment genres, use a classifier to predict the sentiment label of the given text. to extract expression robustly when encounter some complex linguistic phenomena (such as ellipsis, anaphora), a new parsing idea named super parsing  is proposed. it enables some nonadjacent linguistic constituents to be merged to deduce a new one. as an incremental implementation of super parsing, a system named approximate text analysis  (ata) is described in this paper. as for the classification task, two different classifiers are used simple linear classifier (called slc here) and svm. the experiments show the reasonable performance of our approach.	-8	1.2307692307692308
sentiment classification method of chinese micro-blog based on emotional knowledge	this paper proposes an unsupervised method of sentiment classification and applies it to perform sentiment classification on sina microblog.the approach employs emotional images and emotional words as the emotional knowledge to extract pseudolabeled samples,and uses them to train a classifier for automatically classification on polarities of the miroblog.experimental results show that the method achieves a decent performance on sentiment classification for chinese microblog.	-1	2.0
improving sentiment classification using feature highlighting and feature bagging	sentiment classification is an important data mining task. previous researches tried various machine learning techniques while didn't make fully use of the difference among features. this paper proposes a novel method for improving sentiment classification by fully exploring the different contribution of features. the method consists of two parts. first, we highlight sentimental features by increasing their weight. second, we use bagging to construct multiple classifiers on different feature spaces and combine them into an aggregating classifier. extensive experiments show that the method can evidently improve the performance of sentiment classification.	-2	1.8571428571428572
language-independent sentiment classification using three common words	many methods for crosslingual processing tasks are resourcedependent, which will not work without machine translation system or bilingual lexicon. in this paper, we propose a novel approach for multilingual sentiment classification just by few seed words. for a given language, the proposed approach learns a sentiment classifier from the initial seed words instead of any labeled data. we employ our method both in supervised learning and unsupervised learning. experimental results demonstrate that our method relies less on external resource but performs as well as or better than the baseline.	-2	1.8571428571428572
dynamic construction of dictionaries for sentiment classification	the sentiment classification is one of the new challenges emerged with the advence of social networks. our purpose is to determine the sentimental orientation of a facebook comment (positive or negative) by using the linguistic approach. in most of the sentiment analysis applications using this approach, the sentiment lexicon plays a key role. thus, it is very important to create a lexicon covering several sentiment words. for this reason, we address in this paper the problem how to group and list words present in the corpus into two dictionaries. we proposed a new automatic technique to create the positive and negative dictionaries that exploits the emotions symbols (emoticons, acronyms and exclamation words) present in comments. more importantly, our idea allows to enlarge these dictionaries with an enrichment step. finally, by using these prepared dictionaries, we predict the positive and negative polarities of the comment. we evaluate our approach by comparison to human classification. our results are also effective and consistent.	0	2.2
feature subsumption for sentiment classification of dynamic data in social networks using scddf	the analysis of opinions till now is done mostly on static data rather than on the dynamic data. opinions may vary in time. earlier methods concentrated on opinions expressed in an individual site. but on a given concept opinions may vary from site to site. also the past works did not consider the opinions at aggregate level. this paper proposes a novel method for sentiment classification that uses dynamic data features (scddf). experiments were conducted on various product reviews collected from different sites using qtp. opinions were aggregated using bayesian networks and natural language processing techniques. bulk amount of dynamic data is considered rather than the static one. our method takes as input a collection of comments from the social networks and outputs ranks to the comments within each site and finally classifies all comments irrespective of the site it belongs to. thus the user is presented with overall evaluation of the product and its features.	-1	2.0
sentiment classification for the italian language: a case study on movie reviews 365 sentiment classification for the italian language: a	we consider the problem of tracking the opinion polarity, in terms of positive or negative orientation, expressed in documents written in natural language and extracted from a heterogeneous set of web sources. more specifically, we focus our attention on the movie reviews domain. we are interested in evaluating the performance obtained by a set of high performance opinion polarity classifiers for the italian language. classification of polarity expressed by the input documents is achieved by means of several sets of specialized autonomous or interacting agents, devoted, respectively, to document gathering, classification and visualization. in particular the results of opinion analysis are represented by means of a graphical interface, where a multi agent based implementation of zzstructures is exploited to offer graphcentric views and navigation of results. the specific experimental evaluation performed so far shows an accuracy level, which is higher than previous results reported in the literature.	-5	1.5
bottom up: exploring word emotions for chinese sentence chief sentiment classification	in this paper we demonstrate the effectiveness of employing basic sentiment components for analyzing the chief sentiment of chinese sentence among nine categories of sentiments (including “no emotion”). compared to traditional lexicon based methods, our research explores emotion intensities of words and phrases in an eight dimensional sentiment space as features. an emotion matrix kernel is designed to evaluate inner product of these sentiment features for svm classification with o(n) time complexity. experimental result shows our method significantly improves performance of sentiment classification.	-3	1.75
turning online product reviews to customer knowledge: a semantic-based sentiment classification approach	many product review websites have been established (e.g., epinion.com, rateitall.com) for collecting user reviews for a variety of products. in addition, it has also become a common practice for merchants or product manufacturers to setup online forums that allow their customers to provide reviews or express opinions on products they are interested or have purchased. to facilitate merchants, product manufacturers, and customers in exploiting online product reviews for their marketing, product design, or purchasing decision making, classification of the products reviews into positive and negative categories is essential. in this study, we propose a semanticbased sentiment classification (ssc) technique that constructs from a training set of precategorized product reviews a sentiment classification model on the basis of a collection of positive and negative cue features. furthermore, the proposed ssc technique includes a semantic expansion mechanism that uses wordnet for expanding the given set of positive and negative cue features. on the basis of three product review corpora, our empirical evaluation results suggest that the proposed ssc technique achieves higher classification effectiveness than the traditional syntacticlevel sentiment classification technique does.	-7	1.3333333333333333
a sentiment classification method for chinese document	for the great demand of analyzing and mining user's opinion, this paper presents a novel sentiment classification method for chinese document. firstly, the subjective documents are preprocessed and the sentiment features are extracted; then it calculates the basic polarity of the sentiment features based on a sentiment word dictionary, meanwhile dynamic sentiment word's polarity is judged and polarity adjustment is carried out according to the context information; finally, the overall polarity of document is determined by all sentiment words in it. experiment of comparing with baseline and svm shows the effectiveness of the proposed method.	-3	1.625
sentiment classification with supervised sequence embedding	summary in this paper, we introduce a novel approach for modeling $n$grams in a latent space learned from supervised signals. the proposed procedure uses only unigram features to model short phrases (ngrams) in the latent space. the phrases are then combined to form documentlevel latent representation for a given text, where position of an $n$gram in the document is used to compute corresponding combining weight. the resulting twostage supervised embedding is then coupled with a classifier to form an endtoend system that we apply to the largescale sentiment classification task. the proposed model does not require feature selection to retain effective features during preprocessing, and its parameter space grows linearly with size of $n$gram. we present comparative evaluations of this method using two largescale datasets for sentiment classification in online reviews (amazon and tripadvisor). the proposed method outperforms standard baselines that rely on bagofwords representation populated with $n$gram features.	-1	1.8333333333333333
sentiment classification using information extraction technique	summary this paper explores the sentiment classification with information extraction (ie) approach. the ie approach here is required to detect the sentiment expressions on specific subject (person, product, company and so on) and then to evaluate the sentiment strength and/or the validation of them. our method can be illustrated logically as (1) from a given text, extract the sentiment expressions on the specific subjects and attach certain sentiment tag and weight to each of them; (2) calculate the sentiment indicator for each sentiment genre by accumulating the weights of all the expression with the corresponding tag; (3) given the indicators on different sentiment genres, use a classifier to predict the sentiment label of the given text. to extract expression robustly when encounter some complex linguistic phenomena (such as ellipsis, anaphora), a new parsing idea named super parsing is proposed. it enables some nonadjacent linguistic constituents to be merged to deduce a new one. as an incremental implementation of super parsing, a system named approximate text analysis (ata) is described in this paper. as for the classification task, two different classifiers are used simple linear classifier (called slc here) and svm. the experiments show the reasonable performance of our approach.	-8	1.2307692307692308
learning sentiment classification model from labeled features	we propose a novel framework where an initial classifier is learned by incorporating prior information extracted from an existing sentiment lexicon. preferences on expectations of sentiment labels of those lexicon words are expressed using generalized expectation criteria. documents classified with high confidence are then used as pseudolabeled examples for automatical domainspecific feature acquisition. the wordclass distributions of such selflearned features are estimated from the pseudolabeled examples and are used to train another classifier by constraining the model's predictions on unlabeled instances. experiments on both the movie review data and the multidomain sentiment dataset show that our approach attains comparable or better performance than exiting weaklysupervised sentiment classification methods despite using no labeled documents.	-3	1.625
sentiment classification via integrating multiple feature presentations	in the bag of words framework, documents are often converted into vectors according to predefined features together with weighting mechanisms. since each feature presentation has its character, it is difficult to determine which one should be chosen for a specific domain, especially for the users who are not familiar with the domain. this paper explores the integration of various feature presentations to improve the classification accuracy. a general two phases framework is proposed. in the first phase, we train multiple base classifiers with various vector spaces and use these classifiers to predict the class of testing samples respectively. in the second phase, the previous predicted results are integrated into the ultimate class via stacking with svm. the experimental results demonstrate the effectiveness of our method.	-1	1.8333333333333333
text feature selection for sentiment classification of chinese online reviews	in order to meet the requirement of customised services for online communities, sentiment classification of online reviews has been applied to study the unstructured reviews so as to identify users芒聙聶 opinions on certain products. the purpose of this article is to select features for sentiment classification of chinese online reviews with techniques well performed in traditional text classification. first, adjectives, adverbs and verbs are identified as the potential text features containing sentiment information. then, four statistical feature selection methods, such as document frequency (df), information gain (ig), chisquared statistic (chi) and mutual information (mi), are adopted to select features. after that, the boolean weighting method is applied to set feature weights and construct a vector space model. finally, a support vector machine (svm) classifier is employed to predict the sentiment polarity of online reviews. comparative experiments are conducted based on hotel online reviews in chinese. the results indicate that the highest accuracy of the sentiment classification of chinese online reviews is achieved by taking adjectives, adverbs and verbs together as the feature. besides that, different feature selection methods make distinct performances on sentiment classification, as df performs the best.	0	2.0
dynamic construction of dictionaries for sentiment classification	the sentiment classification is one of the new challenges emerged with the advence of social networks. our purpose is to determine the sentimental orientation of a facebook comment (positive or negative) by using the linguistic approach. in most of the sentiment analysis applications using this approach, the sentiment lexicon plays a key role. thus, it is very important to create a lexicon covering several sentiment words. for this reason, we address in this paper the problem how to group and list words present in the corpus into two dictionaries. we proposed a new automatic technique to create the positive and negative dictionaries that exploits the emotions symbols (emoticons, acronyms and exclamation words) present in comments. more importantly, our idea allows to enlarge these dictionaries with an enrichment step. finally, by using these prepared dictionaries, we predict the positive and negative polarities of the comment. we evaluate our approach by comparison to human classification. our results are also effective and consistent.	0	2.0
sentiment classification for microblog by machine learning	with the development of microblog, many studies pay special attention to sentiment classification of the reviews in microblog. this paper summarizes three wellknown methods for text classification and then improves one of them for sentiment analysis. we come up with a new model in which we introduce efficient approaches to select features, calculate weights, train samples and evaluate classifier. the new model is based on bayesian algorithm and machine learning that is one of the most popular methods for sentiment classification. our model can enhance the overall efficiency of the sentiment classifier.	-1	1.8333333333333333
sentiment classification with supervised sequence embedding	in this paper, we introduce a novel approach for modeling n grams in a latent space learned from supervised signals. the proposed procedure uses only unigram features to model short phrases ( n grams) in the latent space. the phrases are then combined to form documentlevel latent representation for a given text, where position of an n gram in the document is used to compute corresponding combining weight. the resulting twostage supervised embedding is then coupled with a classifier to form an endtoend system that we apply to the largescale sentiment classification task. the proposed model does not require feature selection to retain effective features during preprocessing, and its parameter space grows linearly with size of n gram. we present comparative evaluations of this method using two largescale datasets for sentiment classification in online reviews (amazon and tripadvisor). the proposed method outperforms standard baselines that rely on bagofwords representation populated with n gram features.	-1	1.8333333333333333
weighted scl model for adaptation of sentiment classification	in recent years, structural correspondence learning (scl) is regarded as one of the most promising techniques for transfer learning. the main idea behind scl model is to identify correspondences among features from different domains by modeling their correlations with pivot features. however, scl model treats each feature as well as each instance by an equivalentweight strategy. from the perspective of feature, this strategy fails to overcome the adverse influence of highfrequency domainspecific (hfds) features they occupy a relative large portion of weight  in classification model, while hardly carry corresponding sentiment information. from the other perspective, the equivalentweight strategy of scl model does not take into account the labels (“positive” or “negative”) of labeled instance and the labels of pivot features positive pivot features tend to occur more frequently in positive instances and vice versa. to address the two issues effectively, we proposed a weighted scl model (wscl), which weights the features as well as the instances. more specifically, wscl assigns a smaller weight to hfds features and assigns a larger weight to instances with the same label as the involved pivot feature. the experimental results indicate that proposed wscl model could overcome the adverse influence of hfds features, and leverage knowledge from labels of instances and pivot features.	-2	1.5714285714285714
a method of chinese texts sentiment classification based on bayesian algorithm	in this paper, the author did the sentiment classification experiment with chinese hotel reviews from internet based on semantic lexicon and naive bayesian. many experiments have shown the method in order to improve the accuracy of sentiment classification, and time shortened of text processing, the method can also be used in fast sentiment classification for mass data of chinese texts.	0	1.8
a cross-domain adaptation method for sentiment classification using probabilistic latent analysis	sentiment classification is becoming attractive in recent years because of its potential commercial applications. it exploits supervised learning methods to learn the classifiers from the annotated training documents. the challenge in sentiment classification lies in that the sentiment domains are diverse, heterogeneous and fastgrowing. the classifiers trained on one domain (source domain) could not classify a document from another domain (target domain). the domain adaptation technique is to address the problem by making use of labeled samples in the source domain, and unlabeled samples in the target domain. this paper presents a new solution, a crossdomain topic indexing (cdti) method, with which a common semantic space is found from the prior betweendomain term correspondences and the term cooccurrences in the crossdomain documents. these observations are characterized with the mixture model in cdti, with each component being a possible topic shared by the source and target domains. such common topics are found to index the crossdomain content. we evaluate the algorithms on a multidomain sentiment classification task, which shows that cdti outperforms the stateoftheart domain adaptation method, i.e. spectral feature alignment (sfa), and the traditional latent semantic indexing method.	-2	1.7142857142857142
latent sentiment model for weakly-supervised cross-lingual sentiment classification	in this paper, we present a novel weaklysupervised method for crosslingual sentiment analysis. in specific, we propose a latent sentiment model (lsm) based on latent dirichlet allocation where sentiment labels are considered as topics. prior information extracted from english sentiment lexicons through machine translation are incorporated into lsm model learning, where preferences on expectations of sentiment labels of those lexicon words are expressed using generalized expectation criteria. an efficient parameter estimation procedure using variational bayes is presented. experimental results on the chinese product reviews show that the weaklysupervised lsm model performs comparably to supervised classifiers such as support vector machines with an average of 81% accuracy achieved over a total of 5484 review documents. moreover, starting with a generic sentiment lexicon, the lsm model is able to extract highly domainspecific polarity words from text.	-2	1.7142857142857142
unsupervised sentiment classification of english movie reviews using automatic selection of positive and negative sentiment items	we consider the problem of classifying documents not by topic, but by overall sentiment. previous approaches to sentiment classification have favored domainspecific, supervised machine learning (naive bayes, maximum entropy classification, and support vector machines). inherent in these methodologies is the need for annotated training data. building on previous work, we examine an unsupervised system of iteratively extracting positive and negative sentiment items which can be used to classify documents. our method is completely unsupervised and only requires linguistic insight into the semantic orientation of sentiment.	-3	1.5
evaluating the utility of appraisal hierarchies as a method for sentiment classification	recent studies of sentiment classification (determining whether a text is positive or negative) using appraisal theory have provided mixed results. while some good results have been obtained, it is difficult to tell what aspects of appraisal are particularly useful for this task. in this paper, we present a series of experiments to isolate features of appraisal, in order to compare which parts aid the task of sentiment classification on movie reviews. we report results which on the surface challenge the utility of appraisal hierarchies for this task, when modelled using systemic features. however in the context of making a tradeoff between coverage and scale of feature space, our results appear promising. we hence discuss the need for a balance between the size of a classifier's structure and the overall accuracy.	-8	1.0769230769230769
sentiment classification for stock news	web news articles play an important role in stock market. sentiment classification of news articles can help the investors make investment decisions more efficiently. in this paper, we implemented an approach of chinese new words detection by using ngram model and applied the result for chinese word segmentation and sentiment classification. appraisal theory was introduced into sentiment analysis and naive bay es, knearest neighbor and support vector machine were used as classification algorithms. our method was used for a chinese stock news data set. the best accuracy reaches 82.9% in all experiments. additionally, we developed a prototype system to demonstrate our work.	-2	1.5714285714285714
sentiment classification of online product reviews using product features	there is a great number of online product reviews on the internet which needs to be organized. in this paper, we consider the problem of sentiment classification of online reviews to determine the overall semantic orientation of customer reviews. our proposed method for review classification is a supervised machine learning method based on extracting product features and the polarity of opinions expressed about the features.	-2	1.5714285714285714
a cross-study of sentiment classification on arabic corpora	sentiment analysis is a research area where the studies focus on processing and analyzing the opinions available on the web. several interesting and advanced works were performed on english. in contrast, very few works were conducted on arabic. this paper presents the study we have carried out to investigate supervised sentiment classification in an arabic context. we use two arabic corpora which are different in many aspects. we use three common classifiers known by their effectiveness, namely na茂ve bayes, support vector machines and knearest neighbor. we investigate some settings to identify those that allow achieving the best results. these settings are about stemming type, term frequency thresholding, term weighting and ngram words. we show that na茂ve bayes and support vector machines are competitively effective; however k nearest neighbor鈥檚 effectiveness depends on the corpus. through this study, we recommend to use lightstemming rather than stemming, to remove terms that occur once, to combine unigram and bigram words and to use presencebased weighting rather than frequencybased one. our results show also that classification performance may be influenced by documents length, documents homogeneity and the nature of document authors. however, the size of data sets does not have an impact on classification results.	-1	1.6666666666666667
sentiment classification of chinese online reviews: analysing and improving supervised machine learning	with the boost of online reviews, a large quantity of consumers' opinions on certain products and services are generated and spread over the internet, thus techniques of sentiment classification for online reviews rise in response to the requirement of retrieving valuable information. this paper is mainly focused on improving sentiment classification of chinese online reviews through analysing and improving each step in supervised machine learning. at first, adjectives, adverbs, and verbs arc selected as the initial text features. then, three statistic methods (df, ig and chi) are utilised to extract features. at last, a boolean method is applied to set weight to features and a support vector machine (svm) is employed as the classifier. several comparative experiments have been conducted on reviews of two domains mobile phone (product) reviews and hotel (service) reviews. the experimental results indicate that part of speech (pos), the number of features, evaluation domain, feature extraction algorithm and kernel function of svm have great influences on sentiment classification, while the number of training corpora has a little impact. in addition, further improvements of df ig and chi have been made, which demonstrate the theoretical significance and the practical value of this research.	-1	1.6666666666666667
effectiveness of web search results for genre and sentiment classification	summary the motivation of this study is to enhance general topical search with a sentimentbased one where the search results (snippets) returned by the web search engine are clustered by sentiment categories. firstly we developed an automatic method to identify product review documents using the snippets (summary information that includes the url, title, and summary text), which is genre classification. then the identified snippets were automatically classified into positive (recommended) and negative (nonrecommended) documents, which is sentiment classification. thereafter the user may directly decide to access the positive or negative review documents. in this study we used only the snippets rather than their original fulltext documents, and applied a common machine learning technique, svm (support vector machine), and heuristic approaches to investigate how effectively the snippets can be used for genre and sentiment classification. the results show that the web search engine should improve the quality of the snippets especially for opinionated documents (i.e. review documents).	-4	1.3333333333333333
turning online product reviews to customer knowledge: a semantic-based sentiment classification approach	many product review websites have been established (e.g., epinion.com, rateitall.com) for collecting user reviews for a variety of products. in addition, it has also become a common practice for merchants or product manufacturers to setup online forums that allow their customers to provide reviews or express opinions on products they are interested or have purchased. to facilitate merchants, product manufacturers, and customers in exploiting online product reviews for their marketing, product design, or purchasing decision making, classification of the products reviews into positive and negative categories is essential. in this study, we propose a semanticbased sentiment classification (ssc) technique that constructs from a training set of precategorized product reviews a sentiment classification model on the basis of a collection of positive and negative cue features. furthermore, the proposed ssc technique includes a semantic expansion mechanism that uses wordnet for expanding the given set of positive and negative cue features. on the basis of three product review corpora, our empirical evaluation results suggest that the proposed ssc technique achieves higher classification effectiveness than the traditional syntacticlevel sentiment classification technique does.	-7	1.0833333333333333
sentiment classification with interpolated information diffusion kernels	information diffusion kernels  similarity metrics in noneuclidean information spaces  have been found to produce state of the art results for document classification. in this paper, we present a novel approach to global sentiment classification using these kernels. we carry out a large array of experiments addressing the wellknown movie review data set of pang and lee, a de facto benchmark, comparing information diffusion kernels with a standard rbf kernel machine. our results show that interpolation of unigram and bigram information is beneficiary for sentiment classification. copyright 2007 acm.	-6	1.0909090909090908
bounce: sentiment classification in twitter using rich feature sets	the widespread use of twitter makes it very interesting to determine the opinions and the sentiments expressed by its users. the shortness of the length and the highly informal nature of tweets render it very difficult to automatically detect such information. this paper reports the results to a challenge, set forth by semeval2013 task 2, to determine the positive, neutral, or negative sentiments of tweets. two systems are explained system a for determining the sentiment of a phrase within a tweet and system b for determining the sentiment of a tweet. both approaches rely on rich feature sets, which are explained in detail.	0	1.6
sentiment classification analysis based on extraction of sentiment key sentence	a key problem of sentiment analysis is to determine the polarity of a review is positive(thumbs up) or negative(thumbs down).unlike topicbased text classification,where a high accuracy can be achieved,the sentiment classification is a hard and complicated task.one of the main challenges for documentlevel sentiment classification is that not every part of the document is equally informative for inferring the polarity of the whole document.thus,making a distinction between key sentences and trivial sentences will be helpful to improve the sentiment classification performance.we divide a document into key sentences and detailed sentences.key sentence is usually brief but discriminative while detailed sentences are diverse and ambiguous.for key sentence extraction,our approach takes three attributes into accountsentiment attribute,position attribute and special words attribute.to make use of the discrepancy and complementarity of key sentences and detailed sentences,we incorporate key sentences and detailed sentences in supervised and semisupervised learning.in supervised sentiment classification,a classifier combination approach is adopted because the original document is divided into two different and complementary parts;in semisupervised sentiment classification,a cotraining algorithm is proposed to incorporate unlabeled data for sentiment classification.	-1	1.5
sentiment classification of drug reviews using a rule-based linguistic approach	clauselevel sentiment classification algorithm is developed and applied to drug reviews on a discussion forum. the algorithm adopts a pure linguistic approach of computing the sentiment of a clause from the prior sentiment scores assigned to individual words, taking into consideration the grammatical dependency structure of the clause using the sentiment analysis rules. metamap, a medical resource tool, is used to identify various disease terms in the review documents to utilize domain knowledge for sentiment classification. experiment results with 1,000 clauses show the effectiveness of the proposed approach, and it performed significantly better than baseline machine learning approaches. various challenging issues were identified through error analysis, and we will continue improving our linguistic algorithm.	-1	1.5
an unsupervised approach for sentiment classification	in this paper we propose a new unsupervised and domain independent approach for sentiment classification. it takes a few documents as the training set to build a sentiment vocabulary list which will be used to classify the documents according to their sentiment orientation. the system is selfsupervised and domain independent. experimental results show that the classification accuracy of the approach can reach 85.7% which is better than the previous experiments of unsupervised methods.	-1	1.5
reserved self-training: a semi-supervised sentiment classification method for chinese microblogs	yang, reserved selftraining a semi supervised sentiment classification method for chinese microblogs, in proceedings of the sixth international joint conference on natural language processing.	0	1.6
using multiple sources of agreement information for sentiment classification of political transcripts	sentiment classifiers attempt to determine whether a document expresses a generally positive or negative sentiment about its topic. previous work has shown that overall per formance can be improved by combining perdocument classifications with information about agreement between documents. this paper explores approaches to sentiment clas sification of u.s congressional floor debate transcripts that use a model for incorporating multiple sources of information about agree ments between speakers. an empirical eval uation demonstrates accuracy improvements over previously published results.	-5	1.2
integrating intra- and inter-document evidences for improving sentence sentiment classification	sentence sentiment classification is an important task of sentiment analysis. it aims to classify the sentences into positive, negative, or objective. one can consider sentence sentiment classification as a standard text categorization problem. however, determining the sentiment orientation of a review sentence requires more than the features inside the sentence itself, especially for the sentences with little or ambiguous inside sentence features. through observing, some features outside the sentence can interact with its inside features to enhance the overall performance of sentence sentiment classification. thus in this paper, we propose two such outside sentence features intradocument evidence and interdocument evidence. then in order to improve the sentence sentiment classification performance, a graphbased propagation approach is presented to incorporate these inside and outside sentence features. the experimental results on camera domain show that the proposed approach performs better than the approaches without using outside sentence features, and outperforms other representational previous approaches.	-3	1.375
text sentiment classification based on phrase patterns	the research of the text sentiment classification has the broad prospect and the related classification on phrases is the basic in qa system, information security and online investigation. based on the linguistics, the paper analyzes the characteristics of the semantic definition in hownet, calculates the orientation similarity of words in the phrase based on the sentiment weight priority and puts forward the concept of center word to calculate the orientation of the phrase according to the combination of the words in the phrase. the experiments show that it has better result in orientation recognition and some practice value that it can ground text orientation recognition in the research on larger granularities.	-5	1.1
sentiment classification of movie reviews using multiple perspectives	this study develops an automatic method for indepth sentiment analysis of movie review documents using information extraction techniques and a machine learning approach. the analysis results provide sentiment orientations in multiple perspectives, each focusing on a specific aspect of the reviewed entity. sentiment  classification in multiple perspectives can provide more comprehensive sentiment analysis for applications like sentiment ranking and rating. by utilizing information extraction techniques such as entity extraction, coreferencing and pronoun resolution, the review texts are segmented into sections where each section discusses particular aspect of the reviewed entity. for each section of sentences, support vector machine (svm)  using vectors of terms is applied to determine sentiment orientation toward the target aspect. in our exploratory study, we focus on the sentiment orientations toward overall movie, movie directors and casts in the movie. the experimental results prove the effectiveness of the proposed approach for sentiment classification of movie reviews.	-5	1.1
text sentiment classification research based on semantic comprehension	text sentiment classification is used widely,such as information filtering,information security and information recommendation.this paper proposed an improved method based on semantic comprehension.in this paper,sentiment primitive was introduced into sentiment terms identification,and then semantic values of phrases were obtained.furthermore,this paper further analysed adverbs and its influence on identification of text orientation in the semantic level and achieved the text sentiment classification.the experimental results show that the proposed approach is suitable for judging sentiment orientation.	-3	1.25
sentiment classification using genetic algorithm and conditional random fields	sentiment classification has attracted increasing interest from natural language processing. this paper explores the genetic algorithm to extract the best feature collections from the semantic features of emotional collections. conditional random fields (crfs) is employed to model the emotional tendency of web pages which are divided into different types of comments, such as positive comments, negative comments and objective comments. experimental results on both the product reviews and the 1998 people's daily corpus show that the proposed algorithm works reasonable in the real calculation.	-3	1.25
a method of text sentiment classification based on weighted rough membership	facing with promptly increasing reviews on the web,it has been great challenge for information science and technology that how people effectively organize and process document data hiding large amounts of information to meet with particular needs.text sentiment classification aims at developing some new theories and methods to automatically explore the sentiment orientation of a text by mining and analyzing subjective information in texts such as standpoint,view,attitude,mood,and so on.a method of text sentiment classification based on weighted rough membership is proposed in this paper.in the method,the model of text expression is established based on twotuples attribute(feature,feature orientation intensity),by introducing feature orientation intensity into the method of vector space representation.an attribute discretization method is proposed based on the sentiment orientation sequence for feature selection unifying the discretization processing to depress data dimension.to utilize the feature orientation intensity,a weighted rough membership is defined for classifying new sentiment text.compared with svm classifier,on the reality car review corpus,the proposed method based on rough membership for text sentiment classification has the best performance after data being compressed in a certainty extent for text sentiment classification.	-2	1.2857142857142858
a non-syntactic approach for text sentiment classification with stopwords	the present approach uses stopwords and the gaps that occur between successive stopwords formed by contentwords as features for sentiment classification.	-2	1.2857142857142858
snippet-based unsupervised approach for sentiment classification of chinese online reviews	sentiment classification seeks to identify general attitude of a piece of text of comments or reviews on certain subject, be it positive or negative. most existing researches on sentiment classification employ supervised learning approaches that rely on annotated data. however, sentiment is expressed differently on different subjects in different domains, and having annotated corpora for every domain of interest is not always practical. this paper proposes an unsupervised learning approach for classifying text of online reviews as recommended or not recommended. the proposed method is based on search engine snippet, summary information on the result page of a search engine. a basic assumption is that terms with similar orientation tend to cooccur. the cooccurrence is measured by utilizing snippets returned from search engines, with a query consisting of the text and a seed positive or negative word. with the information of snippets, the proposed method may estimate the association of candidate terms more accurately. this allows us to reliably predict the sentiment orientation of customer reviews. texts of customer reviews are then classified as recommended or not recommended if the average sentiment orientations of its phrases are positive or negative. the research data set of this study consists of 600 chinese online reviews about travel destinations retrieved from ctrip.	-2	1.2857142857142858
developing evaluation model of topical term for document-level sentiment classification	sentiment classification is used to identify whether the opinion expressed in a document is positive or negative. in this paper, we present an evaluation modeling approach to documentlevel sentiment.	-5	1.1
sentiment classification with support vector machines and multiple kernel functions	support vector machine (svm) is a learning technique that performs well on sentiment classification. the performance of svm depends on the used kernel function.	-4	1.1111111111111112
imbalanced sentiment classification with multi-strategy ensemble learning	recently, sentiment classification has become a hot research topic in natural language processing. but most existing studies assume that the samples in the negative and positive categories are balanced, which might not be true in real applications. in this paper, we investigate sentiment classification tasks where the class distribution of the samples is imbalanced. to handle the imbalanced problem, we propose a multistrategy ensemble learning approach to this problem. our ensemble approach integrates sampleensemble, featureensemble, and classifierensemble by exploiting multiple classification algorithms. evaluation across four domains shows that our ensemble approach outperforms many other popular approaches that handling imbalanced classification problems, such as resampling and costsensitive approaches, and is proven effective for imbalanced sentiment classification.	-2	1.2857142857142858
a kernel-based sentiment classification approach for chinese sentences	there has been a large growth of online opinioned customer reviews in the recent years. classifying such reviews into polarized ones would be beneficial in business intelligence and other application domains. this paper aims at finding a solution for the sentiment classification at a finegrained level, namely the sentence level. the challenge is that because a sentiment expression is more freestyle, it is more difficult to determine classification features. therefore, we propose a kernelbased machine learning approach to make it feasible for incorporating multiple features from lexical and syntactic levels. the experiment results have shown that our approach is effective and outperforms the very competitive ngram method.	-4	1.1111111111111112
a case-based approach to cross domain sentiment classification	this paper considers the task of sentiment classification of subjective text across many domains, in particular on scenarios where no indomain data is available.	-1	1.3333333333333333
sentiment classification in persian: introducing a mutual information-based method for feature selection	with the enormous growth of online reviews in internet, sentiment analysis has received more and more attention in information retrieval and natural language processing community. up to now there are very few researches conducted on sentiment analysis for persian documents. this paper considers the problem of sentiment classification for online customer reviews in persian language. one of the challenges of persian language is using of a wide variety of declensional suffixes. another common problem of persian text is word spacing. in persian in addition to white space as interwords space, an intraword space called pseudospace separates word's part. one more noticeable challenge in customer reviews in persian language is that of utilizing many informal or colloquial words in text. in this paper we study these challenges by proposing a model for sentiment classification of persian review documents. the proposed model is based on a lemmatization approach for persian language and is employed naive bayes learning algorithm for classification. additionally we present a new feature selection method based on the mutual information method to extract the best feature collection from the initial extracted features. finally we evaluate the performance of the model on a manually gathered collection of cellphone reviews, where the results show the effectiveness of the proposed model.	0	1.4
wikipedia based semantic smoothing for twitter sentiment classification	sentiment classification is one of the important and popular application areas for text classification in which texts are labeled as positive and negative. moreover, naive bayes (nb) is one of the mostly used algorithms in this area. nb having several advantages on lower complexity and simpler training procedure, it suffers from sparsity. smoothing can be a solution for this problem, mostly laplace smoothing is used; however in this paper we propose wikipedia based semantic smoothing approach. in our study we extend semantic approach by using wikipedia article titles that exist in training documents, categories and redirects of these articles as topic signatures. results of the extensive experiments show that our approach improves the performance of nb and even can exceed the accuracy of svm on twitter sentiment 140 dataset.	0	1.4
extracting features for sentiment classification: in the perspective of statistical natural language processing	in order to improve the accuracy of sentiment classification especially for chinese online reviews, this paper proposed an approach to extract features for sentiment classification effectively and efficiently. the proposed method is based on supervised machine learning and follows the basic procedure of statistical natural language processing (snlp). through feature selection, feature extraction and feature weighting, the significant features for sentiment classification are obtained while the insignificant ones are removed. comparative experiments have been made on mobile phone online reviews in chinese, and improvement of three extraction algorithms (df, ig and chi) have also been made to obtain more accurate result. this research enriches the studies on sentiment classification theoretically, and is helpful for future work.	-1	1.3333333333333333
nebular: a sentiment classification system for the tourism business	due to the rapid growth of the tourism industry around the globe, tourists tend to find information of interesting attractions via available search engines. with the rapid growth of web 2.0 in the past few years, tourists generally share their experiences through travel social network websites (travel 2.0) such as tripadvisor, virtuaitourist and yahoo travel. these websites have become major sources of information for tourists; however, due to the amount of available opinionated text, tourists are often overwhelmed with information. as a consequence, tourists find it extremely difficult to obtain any useful comments to make a decision regarding their travel destinations. the nebular system is therefore proposed to classify comments gathered from available travel social network websites into predefined aspects and further analyze comments into positive and negative sentiments. this system aims to assist tourists to easily extract subjective information from travel social network websites and determine the attitude and the overall tonality of writers in the traveling domain. this can reduce the time required in searching for related information as well as easily support the growth of the tourism industry around the world.	-2	1.1428571428571428
sentiment classification using semantic features extracted from wordnet-based resources	in this paper, we concentrate on the 3 of the tracks proposed in the ntcir 8 moat, concerning the classification of sentences according to their opinionatedness, relevance and polarity. we propose a method for the detection of opinions, relevance, and polarity classification, based on isrwn (a resource for the multidimensional analysis with relevant semantic trees of sentences using different wordnetbased information sources). based on the results obtained, we can conclude that the resource and methods we propose are appropriate for the task, reaching the level of stateoftheart approaches.	-2	1.1428571428571428
research on sentiment classification problem of sino-japanese relations forum	aiming at sentiment classification problem about sinojapanese relations forum,this paper studies the corpus characteristic of the specific areas(on sinojapanese relations forum),the influence of different characteristic dimension,weight computation,selection method as well as different word classes to the sentiment classification result.by automatically classifying sentiments on the corpus of sinojapanese relations forum during jan.,2006may,2006.,the situation of sinojapanese relations are concluded.	-6	0.9090909090909091
affective-word based chinese text sentiment classification	when browsing news on the web, various emotions may be evoked in readers and furthermore cause different influence on their minds and life. we expect that emotional analysis and classification of text may provide good performance and significance to users surfing the internet. most previous research only focus on biemotion classification, that is, positive and negative, e.g., identifying whether a comment is for praising or criticizing. in this paper, we propose a 蠂2based chinese text emotion classification with five sentiment categories. we run two experiments, one uses sentiment words extracted from hownet and a chinese thesaurus tongyici cilin, and the other is not. the results shows that adding affective words can make better prediction in the sentiment classification.	-2	1.1428571428571428
feature subsumption for sentiment classification in multiple languages	an open problem in machine learningbased sentiment classification is how to extract complex features that outperform simple features; figuring out which types of features are most valuable is another.	-3	1.125
a case-based approach to cross domain sentiment classification	this paper considers the task of sentiment classification of subjective text across many domains, in particular on scenarios where no indomain data is available. motivated by the more general applicability of such methods, we propose an extensible approach to sentiment classification that leverages sentiment lexicons and outofdomain data to build a casebased system where solutions to past cases are reused to predict the sentiment of new documents from an unknown domain. in our approach the case representation uses a set of features based on document statistics, while the case solution stores sentiment lexicons employed on past predictions allowing for later retrieval and reuse on similar documents. the casebased nature of our approach also allows for future improvements since new lexicons and classification methods can be added to the case base as they become available. on a cross domain experiment our method has shown robust results when compared to a baseline singlelexicon classifier where the lexicon has to be preselected for the domain in question.	-1	1.3333333333333333
recognizing contextual valence shifters in document-level sentiment classification	sentiment classification is an emerging research field. due to the rich opinionated web content, people and organizations are interested in knowing others' opinions, so they needan automated tool for analyzing and summarizing these opinions. one of the major tasks of sentiment classification is to classify a document (i.e. a blog, news article or review) as holding an overall positive or negative sentiment. machine learning approaches havesucceeded in achieving better results than semantic orientation approaches in documentlevel sentiment classification; however, they still need to take linguistic context into account,by making use of the socalled contextual valence shifters. early research has tried to add sentiment features and contextual valence shifters to the machine learning approach to tackle this problem, but the classifier's performance was low.in this study, we would like to improve the performance of documentlevel sentiment classification using the machine learning approach by proposing new feature sets that refine the traditional sentiment feature extraction method and take contextual valence shiftersinto consideration from a different perspective than the earlier research. these feature sets include 1) a feature set consisting of 16 features for counting different categories of contextual valence shifters (intensifiers, negators and polarity shifters).	-2	1.1428571428571428
suicide note sentiment classification: a supervised approach augmented by web data	to create a sentiment classification system for the fifth i2b2/va challenge track 2, which can identify thirteen subjective categories and two objective categories. we developed a hybrid system using support vector machine (svm) classifiers with augmented training data from the internet. our system consists of three types of classificationbased systems the first system uses spanning ngram features for subjective categories, the second one uses bagofngram features for objective categories, and the third one uses pattern matching for infrequent or subtle emotion categories. the spanning ngram features are selected by a feature selection algorithm that leverages emotional corpus from weblogs. special normalization of objective sentences is generalized with shallow parsing and external web knowledge. we utilize three sources of web data the weblog of livejournal which helps to improve the feature selection, the ebay list which assists in special normalization ofinformationandinstructionscategories, and the suicide project web which provides unlabeled data with similar properties as suicide notes. the performance is evaluated by the overall microaveraged precision, recall and fmeasure. our system achieved an overall microaveraged fmeasure of 0.59.happiness_peacefulnesshad the highest fmeasure of 0.81. we were ranked as the second best out of 26 competing teams.	-1	1.1666666666666667
sentiment classification in persian: introducing a mutual information-based method for feature selection	with the enormous growth of online reviews in internet, sentiment analysis has received more and more attention in information retrieval and natural language processing community. up to now there are very few researches conducted on sentiment analysis for persian documents. this paper considers the problem of sentiment classification for online customer reviews in persian language. one of the challenges of persian language is using of a wide variety of declensional suffixes. another common problem of persian text is word spacing. in persian in addition to white space as interwords space, an intraword space called pseudospace separates word's part. one more noticeable challenge in customer reviews in persian language is that of utilizing many informal or colloquial words in text. in this paper we study these challenges by proposing a model for sentiment classification of persian review documents. the proposed model is based on a lemmatization approach for persian language and is employed naive bayes learning algorithm for classification. additionally we present a new feature selection method based on the mutual information method to extract the best feature collection from the initial extracted features. finally we evaluate the performance of the model on a manually gathered collection of cellphone reviews, where the results show the effectiveness of the proposed model.	0	1.2
improving document-level sentiment classification using contextual valence shifters	traditional sentiment feature extraction methods in documentlevel sentiment classification either count the frequencies of sentiment words as features, or the frequencies of modified and unmodified instances of each of these words. however, these methods do not represent the sentiment words’ linguistic context efficiently. we propose a novel method and feature set to handle the contextual polarity of sentiment words efficiently. our experiments on both movie and product reviews show a significant improvement in the classifier’s performance (an overall accuracy increase of 2%), in addition to statistical significance of our feature set over the traditional feature set. also, compared with other widelyused feature sets, most of our features are among the key features for sentiment classification.	-1	1.1666666666666667
improving document-level sentiment classification using contextual valence shifters	summary traditional sentiment feature extraction methods in documentlevel sentiment classification either count the frequencies of sentiment words as features, or the frequencies of modified and unmodified instances of each of these words. however, these methods do not represent the sentiment words’ linguistic context efficiently. we propose a novel method and feature set to handle the contextual polarity of sentiment words efficiently. our experiments on both movie and product reviews show a significant improvement in the classifier’s performance (an overall accuracy increase of 2\%), in addition to statistical significance of our feature set over the traditional feature set. also, compared with other widelyused feature sets, most of our features are among the key features for sentiment classification.	-1	1.1666666666666667
spectral clustering-based semi-supervised sentiment classification	this work proposes a semisupervised sentiment classification method. our method utilizes spectral clusteringbased algorithm to improve the sentiment classification accuracy. we adopt a spectral clustering algorithm to map sentiment units in consumer reviews into new features which are extended into the original feature space. one sentiment classifier is built on the features in the original training space, and the original training features combined with the extended features are used to train the other sentiment classifier. the two basic sentiment classifiers together form the final sentiment classifier through selecting instances in the unlabeled data set into the training data set. experimental results show that our proposed method has better performance than selflearning svmbased sentiment classification method.	-1	1.1666666666666667
featured based sentiment classification for hotel reviews using nlp and bayesian classification	the internet revolution has brought about a new way of expressing an individual's opinion. it has become a medium through which people openly express their views on various subjects. these opinions contain useful information which can be utilized in many sectors which require constant customer feedback. analysis of the opinion and it's classification into different sentiment classes is gradually emerging as a key factor in decision making. there has been extensive research on automatic text analysis for sentiments such as sentiment classifiers, affect analysis, automatic survey analysis, opinion extraction, or recommender systems. these methods typically try to extract the overall sentiment revealed in a sentence or document, either positive or negative, or somewhere in between. however, a drawback of these methods is that the information can be degraded, especially in texts where a loss of information can also occur. the proposed method attempts to overcome the problem of the loss of text information by using well trained training sets. also, recommendation of a product or request for a product as per the user's requirements have achieved with the proposed method.	-1	1.1666666666666667
heterogeneous ensemble learning for chinese sentiment classification	sentiment classification is an important research field in information processing and has rich application background and practical value. the intuition that builds a high performance classifier via some combination of different algorithm is a long motivation. in this paper, three heterogeneous ensemble learning method is used to ensemble the following four classifierssupport vector machine, k nearest neighbor, weighting sums of sentimental words based on statistics and weighting sums of sentimental words based on ontology. for each kind of classifiers we pick one to three classifiers to test the influence of quantity of individual classifiers to the performance of ensemble classifier. experiments on chinese benchmark dataset chnsenticorphtlba4000 show that ensemble learning methods can generate an ensemble classifier which outperforms any individual classifier, and with more individual classifiers the ensemble classifier will gain better performance.	-1	1.1666666666666667
revised mutual information approach for german text sentiment classification	the significant increase in content of online social media such as product reviews, blogs, forums etc., have led to an increasing attention to sentiment analysis tools and approaches that make use of mining this substantially growing content. the aim of this paper is to develop a robust classification approach of customer reviews based on a selfannotated domainspecific corpus by applying a statistical approach i.e., mutual information. first, subjective words in each test sentence are identified. second, ambiguous adjectives such as high, low, large, many etc., are disambiguated based on their accompanying noun using a conditional mutual information approach. third, a mutual information approach is applied to find the sentiment orientation (polarity) of the identified subjective words based on analyzing their statistical relationship with the manually annotated sentiment labels within a sizeable sentiment training data. fourth, since negation plays a significant role in flipping the sentiment polarity of an identified sentiment word, we estimate the role of negation in affecting the classification accuracy. finally, the identified polarity for each test sentence is evaluated against experts' annotation.	0	1.2
sentiment classification using machine learning techniques with syntax features	sentiment classification has adopted machine learning techniques to improve its precision and efficiency. however, the features are always produced by basic wordsbag methods without much consideration for words' syntactic properties, which could play an important role in the judgment of sentiment meanings. to remedy this, we firstly generate syntax trees of the sentences, with the analysis of syntactic features of the sentences. then we introduce multiple sentiment features into the basic wordsbag features. such features were trained on movie reviews as data, with machine learning methods (naive bayes and support vector machines). the features and factors introduced by syntax tree were examined to generate a more accurate solution for sentiment classification.	3	42.5
cross-domain sentiment classification using sentiment sensitive embeddings	unsupervised crossdomain sentiment classification is the task of adapting a sentiment classifier trained on a particular domain (source domain), to a different domain (target domain), without requiring any labeled data for the target domain. by adapting an existing sentiment classifier to previously unseen target domains, we can avoid the cost for manual data annotation for the target domain. we model this problem as embedding learning, and construct three objective functions that capture (a) distributional properties of  pivots (i.e., common features that appear in both source and target domains), (b) label constraints in the source domain documents, and (c) geometric properties in the unlabeled documents in both source and target domains. unlike prior proposals that first learn a lowerdimensional embedding independent of the source domain sentiment labels, and next a sentiment classifier in this embedding, our joint optimisation method learns embeddings that are sensitive to sentiment classification. experimental results on a benchmark dataset show that by jointly optimising the three objectives we can obtain better performances in comparison to optimising each objective function separately, thereby demonstrating the importance of taskspecific embedding learning for crossdomain sentiment classification. among the individual objective functions, the best performance is obtained by (c).	3	33.5
coooolll: a deep learning system for twitter sentiment classification	in this paper, we develop a deep learn ing system for messagelevel twitter sen timent classification. among the 45 sub mitted systems including the semeval 2013 participants, our system (coooolll) is ranked 2nd on the twitter2014 test set of semeval 2014 task 9. coooolll is built in a supervised learning framework by concatenating the sentimentspecific word embedding (sswe) features with the stateoftheart handcrafted features. we develop a neural network with hybrid loss function 1 to learn sswe, which en codes the sentiment information of tweets in the continuous representation of words. to obtain largescale training corpora, we train sswe from 10m tweets collected by positive and negative emoticons, without any manual annotation. our system can be easily reimplemented with the publicly available sentimentspecific word embed ding.	1	16.75
learning sentiment-specific word embedding for twitter sentiment classification	we present a method that learns word embedding for twitter sentiment classification in this paper. most existing algorithms for learning continuous word representations typically only model the syntactic context of words but ignore the sentiment of text. this is problematic for sentiment analysis as they usually map words with similar syntactic context but opposite sentiment polarity, such as good and bad, to neighboring word vectors. we address this issue by learning sentimentspecific word embedding (sswe), which encodes sentiment information in the continuous representation of words. specifically, we develop three neural networks to effectively incorporate the supervision from sentiment polarity of text (e.g. sentences or tweets) in their loss functions. to obtain large scale training corpora, we learn the sentimentspecific word embedding from massive distantsupervised tweets collected by positive and negative emoticons. experiments on applying sswe to a benchmark twitter sentiment classification dataset in semeval 2013 show that (1) the sswe feature performs comparably with handcrafted features in the topperformed system; (2) the performance is further improved by concatenating sswe with existing feature set.	1	58.0
document modeling with gated recurrent neural network for sentiment classification	emoji is an essential component in dialogues which has been broadly utilized on almost all social platforms. it could express more delicate feelings beyond plain texts and thus smooth the communications between users, making dialogue systems more anthropomorphic and vivid. in this paper, we focus on automatically recommending appropriate emojis given the contextual information in multiturn.	2	36.0
adaptive recursive neural network for target-dependent twitter sentiment classification	we propose adaptive recursive neural network (adarnn) for targetdependent twitter sentiment classification. adarnn adaptively propagates the sentiments of words to target depending on the context and syntactic relationships.	1	21.0
sentiment classification: the contribution of ensemble learning	analyzing and predicting the polarity of the sentiment plays an important role.•three popular ensemble methods for sentiment classification are asse.	1	15.75
target-dependent twitter sentiment classification with rich automatic features	targetdependent sentiment analysis on twitter has attracted increasing research attention. most previous work relies on syntax, such as automatic parse trees, which are subject to noise for informal text such as tweets.	2	11.0
harnessing wordnet senses for supervised sentiment classification.	traditional approaches to sentiment classification rely on lexical features, syntaxbased features or a combination of the two. we propose semantic features using word senses for a supervised documentlevel sentiment classifier. to highlight the benefit of sensebased features, we compare wordbased representation of documents with a sensebased representation where wordnet senses of the words are used as features. in addition, we highlight the benefit of senses by presenting a partofspeechwise effect on sentiment classification. finally, we show that even if a wsd engine disambiguates between a limited set of words in a document, a sentiment classifier still performs better than what it does in absence of sense annotation. since word senses used as features show promise, we also examine the possibility of using similarity metrics defined on wordnet to address the problem of not finding a sense in the training corpus. we perform experiments using three popular similarity metrics to mitigate the effect of unknown synsets in a test corpus by replacing them with similar synsets from the training corpus. the results show promising improvement with respect to the baseline.	1	10.0
a multi-label classification based approach for sentiment classification	a detailed empirical study of different multilabel classification methods on sentiment classification is conducted to compare their classification performances. specifically, total 11 state of the art multilabel classification methods are compared on two microblog datasets and 8 evaluation metrics are used. the effects of the three sentiment dictionaries for multilabel classification are empirically studied and compared, which, to the best of our knowledge, have not been performed. the performed empirical comparisons show that dalian university of technology sentiment dictionary has the best performance among the three different sentiment dictionaries.	2	9.0
swisscheese at semeval-2016 task 4: sentiment classification using an ensemble of convolutional neural networks with distant supervision	in this paper, we propose a classifier for predicting messagelevel sentiments of en glish microblog messages from twitter. our method builds upon the convolutional sen tence embedding approach proposed by (sev eryn and moschitti, 2015a; severyn and mos chitti, 2015b). we leverage large amounts of data with distant supervision to train an en semble of 2layer convolutional neural net works whose predictions are combined using a random forest classifier. our approach was evaluated on the datasets of the semeval2016 competition (task 4) outperforming all other approaches for the message polarity classifi cation task.	3	13.5
learning semantic representations of users and products for document level sentiment classification	review rating prediction is an important research topic. the problem was approached from either the perspective of recommender systems (rs) or that of sentiment analysis (sa). recent sa research using deep neural networks (dnns) has realized the importance of user and product interaction for better interpreting the sentiment of reviews.	2	14.333333333333334
lifelong learning for sentiment classification	this paper proposes a novel lifelong learning (ll) approach to sentiment classification. ll mimics the human continuous learning process, i.e., retaining the knowledge learned from past tasks and use it to help future learning. in this paper, we first discuss ll in general and then ll for sentiment classification in particular. the proposed ll approach adopts a bayesian optimization framework based on stochastic gradient descent. our experimental results show that the proposed method outperforms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction.	2	5.0
aspect level sentiment classification with deep memory network	we introduce a deep memory network for aspect level sentiment classification. unlike featurebased svm and sequential neural models such as lstm, this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect. such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory. experiments on laptop and restaurant datasets demonstrate that our approach performs comparable to stateofart feature based svm system, and substantially better than lstm and attentionbased lstm architectures. on both datasets we show that multiple computational layers could improve the performance. moreover, our approach is also fast. the deep memory network with 9 layers is 15 times faster than lstm with a cpu implementation.	3	7.0
multilingual twitter sentiment classification: the role of human annotators	what are the limits of automated twitter sentiment classification? we analyze a large set of manually labeled tweets in different languages, use them as training data, and construct automated classification models. it turns out that the quality of classification models depends much more on the quality and size of training data than on the type of the model trained. experimental results indicate that there is no statistically significant difference between the performance of the top classification models. we quantify the quality of training data by applying various annotator agreement measures, and identify the weakest points of different datasets. we show that the model performance approaches the interannotator agreement when the size of the training set is sufficiently large. however, it is crucial to regularly monitor the self and interannotator agreements since this improves the training datasets and consequently the model performance. finally, we show that there is strong evidence that humans perceive the sentiment classes (negative, neutral, and positive) as ordered.	3	7.5
context-sensitive twitter sentiment classification using neural network	sentiment classification on twitter has attracted increasing research in recent years.most existing work focuses on feature engineering according to the tweet content itself.in this paper, we propose a contextbased neural network model for twitter sentiment analysis, incorporating contextualized features from relevant tweets into the model in the form of word embedding vectors.experiments on both balanced and unbalanced datasets show that our proposed models outperform the current stateoftheart.	3	8.5
effective lstms for target-dependent sentiment classification	targetdependent sentiment classification remains a challenge modeling the semantic relatedness of a target with its context words in a sentence. different context words have different influences on determining the sentiment polarity of a sentence towards the target. therefore, it is desirable to integrate the connections between target word and context words when building a learning system. in this paper, we develop two target dependent long shortterm memory (lstm) models, where target information is automatically taken into account. we evaluate our methods on a benchmark dataset from twitter. empirical results show that modeling sentence representation with standard lstm does not perform well. incorporating target information into lstm can significantly boost the classification accuracy. the targetdependent lstm models achieve stateoftheart performances without using syntactic parser or external sentiment lexicons.	3	7.0
do users rate or review?: boost phrase-level sentiment labeling with review-level sentiment classification	current approaches for contextual sentiment lexicon construction in phraselevel sentiment analysis assume that the numerical star rating of a review represents the overall sentiment orientation of the review text. although widely adopted, we find through user rating analysis that this is not necessarily true. in this paper, we attempt to bridge the gap between phraselevel and review/documentlevel sentiment analysis by leveraging the results given by reviewlevel sentiment classification to boost phraselevel sentiment polarity labeling in contextual sentiment lexicon construction tasks, using a novel constrained convex optimization framework. experimental results on both english and chinese reviews show that our framework improves the precision of sentiment polarity labeling by up to 5.6%, which is a significant improvement from current approaches.	1	4.25
do users rate or review?: boost phrase-level sentiment labeling with review-level sentiment classification	current approaches for contextual sentiment lexicon construction in phraselevel sentiment analysis assume that the numerical star rating of a review represents the overall sentiment orientation of the review text. although widely adopted, we find through user rating analysis that this is not necessarily true. in this paper, we attempt to bridge the gap between phraselevel and review/documentlevel sentiment analysis by leveraging the results given by reviewlevel sentiment classification to boost phraselevel sentiment polarity labeling in contextual sentiment lexicon construction tasks, using a novel constrained convex optimization framework. experimental results on both english and chinese reviews show that our framework improves the precision of sentiment polarity labeling by up to 5.6%, which is a significant improvement from current approaches.	1	4.0
combination of active learning and self-training for cross-lingual sentiment classification with density analysis of unlabelled samples	in recent years, research in sentiment classification has received considerable attention by natural language processing researchers. annotated sentiment corpora are the most important resources used in sentiment classification. however, since most recent research works in this field have focused on the english language, there are accordingly not enough annotated sentiment resources in other languages. manual construction of reliable annotated sentiment corpora for a new language is a labourintensive and timeconsuming task. projection of sentiment corpus from one language into another language is a natural solution used in crosslingual sentiment classification. automatic machine translation services are the most commonly tools used to directly project information from one language into another. however, since term distribution across languages may be different due to variations in linguistic terms and writing styles, crosslingual methods cannot reach the performance of monolingual methods. in this paper, a novel learning model is proposed based on the combination of uncertaintybased active learning and semisupervised selftraining approaches to incorporate unlabelled sentiment documents from the target language in order to improve the performance of crosslingual methods.	2	5.0
neural sentiment classification with user and product attention	documentlevel sentiment classification aims to predict user's overall sentiment in a doc ument about a product. however, most of existing methods only focus on local text in formation and ignore the global user pref erence and product characteristics. even though some works take such information into account, they usually suffer from high model complexity and only consider word level preference rather than semantic levels. to address this issue, we propose a hierarchi cal neural network to incorporate global user and product information into sentiment clas sification. our model first builds a hierar chical lstm model to generate sentence and document representations. afterwards, user and product information is considered via at tentions over different semantic levels due to its ability of capturing crucial semantic com ponents. the experimental results show that our model achieves significant and consistent improvements compared to all stateofthe art methods. the source code of this paper can be obtained from https//github. com/thunlp/nsc.	3	5.0
sentiment classification of online reviews: using sentence-based language model	with the development of social media, the increasing online reviews of products are greatly influencing the electronic market, making sentiment classification the topic of interest for both industry and academia. this paper develops a sentencebased language model to perform sentiment classification at a finegrained sentence level. the proposed approach applies a machine learning method to determine the sentiment polarity of a sentence at first, then designs statistical algorithm to compute the weight of the sentence in sentiment classification of the whole document and at last aggregates the weighted sentence to predict the sentiment polarity of document. besides, experiments are carried out on corpuses in different evaluation domains and languages, and the results demonstrate the effectiveness of the sentencebased approach in obtaining a more accurate result of sentiment classification across different reviews. furthermore, the experimental results also indicate that the position and the sentiment of a sentence have great impact on predicting the sentiment polarity of document, and corpuses with different evaluative objects, languages and sentiments also greatly influence the performance of sentiment classification. it is believed that these conclusions will be a good inspiration for similar researches.	1	3.5
a statistical parsing framework for sentiment classification	we present a statistical parsing framework for sentencelevel sentiment classification in this article. unlike previous works that employ syntactic parsing results for sentiment analysis, we develop a statistical parser to directly analyze the sentiment structure of a sentence. we show that complicated phenomena in sentiment analysis (e.g., negation, intensification, and contrast) can be handled the same as simple and straightforward sentiment expressions in a unified and probabilistic way. we formulate the sentiment grammar upon contextfree grammars (cfgs), and provide a formal description of the sentiment parsing framework. we develop the parsing model to obtain possible sentiment parse trees for a sentence, from which the polarity model is proposed to derive the sentiment strength and polarity, and the ranking model is dedicated to selecting the best sentiment tree. we train the parser directly from examples of sentences annotated only with sentiment polarity labels but without any syntactic annotations or polarity annotations of constituents within sentences. therefore we can obtain training data easily. in particular, we train a sentiment parser, s.parser, from a large amount of review sentences with users' ratings as rough sentiment polarity labels. extensive experiments on existing benchmark datasets show significant improvements over baseline sentiment classification approaches.	1	3.75
attention-based lstm for aspect-level sentiment classification	aspectlevel sentiment classification is a fine grained task in sentiment analysis. since it provides more complete and indepth results, aspectlevel sentiment analysis has received much attention these years. in this paper, we reveal that the sentiment polarity of a sentence is not only determined by the content but is also highly related to the concerned aspect. for instance, the appetizers are ok, but the service is slow., for aspect taste, the polar ity is positive while for service, the polarity is negative. therefore, it is worthwhile to ex plore the connection between an aspect and the content of a sentence. to this end, we propose an attentionbased long shortterm memory network for aspectlevel sentiment classification. the attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input. we experiment on the semeval 2014 dataset and results show that our model achieves stateof theart performance on aspectlevel sentiment classification.	3	4.5
sentiment classification of online political discussions: a comparison of a word-based and dependency-based method	building up the ndt, a manually annotated syntactic treebank for norwegian bokm02l and norwegian nynorsk. this project was conducted at the national library of norway in collaboration with the text.	1	3.0
adversarial deep averaging networks for cross-lingual sentiment classification	in recent years deep neural networks have achieved great success in sentiment classification for english, thanks in part to the availability of copious annotated resources. unfortunately, most other languages do not enjoy such an abundance of annotated data for sentiment analysis. to tackle this problem, we propose the adversarial deep averaging network (adan) to transfer sentiment knowledge learned from labeled english data to lowresource languages where only unlabeled data exists. adan is a yshaped network with two discriminative branches a sentiment classifier and an adversarial language identification scorer. both branches take input from a shared feature extractor that aims to learn hidden representations that capture the underlying sentiment of the text and are invariant across languages. experiments on chinese and arabic sentiment classification demonstrate that adan significantly outperforms several baselines, including a strong pipeline approach that relies on stateoftheart machine translation.	3	5.0
enhanced twitter sentiment classification using contextual information	the rise in popularity and ubiquity of twitter has made sentiment analysis of tweets an important and wellcovered area of research. however, the 140 character limit imposed on tweets makes it hard to use standard linguistic methods for sentiment classification. on the other hand, what tweets lack in structure they make up with sheer volume and rich metadata. this metadata includes geolocation, temporal and author information. we hypothesize that sentiment is dependent on all these contextual factors. different locations, times and authors have different emotional valences. in this paper, we explored this hypothesis by utilizing distant supervision to collect millions of labelled tweets from different locations, times and authors. we used this data to analyse the variation of tweet sentiments across different authors, times and locations. once we explored and understood the relationship between these variables and sentiment, we used a bayesian approach to combine these variables with more standard linguistic features such as ngrams to create a twitter sentiment classifier. this combined classifier outperforms the purely linguistic classifier, showing that integrating the rich contextual information available on twitter into sentiment classification is a promising direction of research.	2	3.6666666666666665
sentiment classification on polarity reviews: an empirical study using rating-based features	we present a new feature type named ratingbased feature and evaluate the contribution of this feature to the task of documentlevel sentiment analysis. we achieve stateoftheart results on two publicly available standard polarity movie datasets on the dataset consisting of 2000 reviews produced by pang and lee (2004) we obtain an accuracy of 91.6% while it is 89.87% evaluated on the dataset of 50000 reviews created by maas et al. (2011). we also get a performance at 93.24% on our own dataset consisting of 233600 movie reviews, and we aim to share this dataset for further research in sentiment polarity analysis task.	1	2.75
personalized sentiment classification based on latent individuality of microblog users	sentiment expression in microblog posts often reflects user's specific individuality due to different language habit, personal character, opinion bias and so on. existing sentiment classification algorithms largely ignore such latent personal distinctions among different microblog users. meanwhile, sentiment data of microblogs are sparse for individual users, making it infeasible to learn effective personalized classifier. in this paper, we propose a novel, extensible personalized sentiment classification method based on a variant of latent factor model to capture personal sentiment variations by mapping users and posts into a lowdimensional factor space. we alleviate the sparsity of personal texts by decomposing the posts into words which are further represented by the weighted sentiment and topic units based on a set of syntactic units of words obtained from dependency parsing results. to strengthen the representation of users, we leverage users following relation to consolidate the individuality of a user fused from other users with similar interests. results on realworld microblog datasets confirm that our method outperforms stateoftheart baseline algorithms with large margins.	2	3.6666666666666665
improving twitter sentiment classification using topic-enriched multi-prototype word embeddings	it has been shown that learning distributed word representations is highly useful for twitter sentiment classification.most existing models rely on a single distributed representation for each word.this is problematic for sentiment classification because words are often polysemous and each word can contain different sentiment polarities under different topics.we address this issue by learning topicenriched multiprototype word embeddings (tmwe).in particular, we develop two neural networks which 1) learn word embeddings that better capture tweet context by incorporating topic information, and 2) learn topicenriched multiple prototype embeddings for each word.experiments on twitter sentiment benchmark datasets in semeval 2013 show that tmwe outperforms the top system with handcrafted features, and the current best neural network model.	3	4.0
detecting adverse drug reactions using a sentiment classification framework	medical blogs and forums are a source of sentimentoriented content that is used in diverse applicationsincluding postmarketing drug surveillance, competitive intelligence and the assessment of healthrelatedopinions and sentiments for detecting adverse drugreactions. however applying existing tools for sentiment analysis to healthrelated datasets provides inadequate classification accuracy. these methodsemploy less useful features sets and therefore lackdiscriminatory potential. in this study we proposea framework that uses feature set ensembles withnovel feature representations that reduce sparsity byadding representational richness. our framework extracts important semantic, sentiment, and affect cues,that are better able to reflect the experiences of people when they discuss adverse drug reactions as well as the severity and the emotional impact of their experiences. experiments conducted on a test bed ofhealth2.0 datasets, demonstrate improved classification accuracy in comparison to existing techniques.furthermore, the proposed framework is able to detect adverse drug events earlier, and with higher recall than comparison methods, thereby demonstrating its utility for social media based postmarketing drug surveillance.	1	2.75
pos-rs: a random subspace method for sentiment classification based on part-of-speech analysis	with the rise of web 2.0 platforms, personal opinions, such as reviews, ratings, recommendations, and other forms of usergenerated content, have fueled interest in sentiment classification in both academia and industry. in order to enhance the performance of sentiment classification, ensemble methods have been investigated by previous research and proven to be effective theoretically and empirically. we advance this line of research by proposing an enhanced random subspace method, posrs, for sentiment classification based on partofspeech analysis. unlike existing random subspace methods using a single subspace rate to control the diversity of base learners, posrs employs two important parameters, i.e. content lexicon subspace rate and function lexicon subspace rate, to control the balance between the accuracy and diversity of base learners. ten publicly available sentiment datasets were investigated to verify the effectiveness of proposed method. empirical results reveal that posrs achieves the best performance through reducing bias and variance simultaneously compared to the base learner, i.e., support vector machine. these results illustrate that posrs can be used as a viable method for sentiment classification and has the potential of being successfully applied to other text classification problems.	2	3.6666666666666665
bi-view semi-supervised active learning for cross-lingual sentiment classification	recently, sentiment classification has received considerable attention within the natural language processing research community. however, since most recent works regarding sentiment classification have been done in the english language, there are accordingly not enough sentiment resources in other languages. manual construction of reliable sentiment resources is a very difficult and timeconsuming task. crosslingual sentiment classification aims to utilize annotated sentiment resources in one language (typically english) for sentiment classification of text documents in another language. most existing research works rely on automatic machine translation services to directly project information from one language to another. however, different term distribution between original and translated text documents and translation errors are two main problems faced in the case of using only machine translation. to overcome these problems, we propose a novel learning model based on active learning and semisupervised cotraining to incorporate unlabelled data from the target language into the learning process in a biview framework. this model attempts to enrich training data by adding the most confident automaticallylabelled examples, as well as a few of the most informative manuallylabelled examples from unlabelled data in an iterative process.	1	2.75
bi-view semi-supervised active learning for cross-lingual sentiment classification	recently, sentiment classification has received considerable attention within the natural language processing research community. however, since most recent works regarding sentiment classification have been done in the english language, there are accordingly not enough sentiment resources in other languages. manual construction of reliable sentiment resources is a very difficult and timeconsuming task. crosslingual sentiment classification aims to utilize annotated sentiment resources in one language (typically english) for sentiment classification of text documents in another language. most existing research works rely on automatic machine translation services to directly project information from one language to another. however, different term distribution between original and	1	2.5
learning bilingual sentiment word embeddings for cross-language sentiment classification	the sentiment classification performance relies on highquality sentiment resources. however, these resources are imbalanced in different languages. crosslanguage sentiment classification (clsc) can leverage the rich resources in one language (source language) for sentiment classification in a resourcescarce language (target language). bilingual embeddings could eliminate the semantic gap between two languages for clsc, but ignore the sentiment information of text. this paper proposes an approach to learning bilingual sentiment word embeddings (bswe) for englishchinese clsc. the proposed bswe incorporate sentiment information of text into bilingual embeddings. furthermore , we can learn highquality bswe by simply employing labeled corpora and their translations, without relying on largescale parallel corpora. experiments on nlp&cc 2013 clsc dataset show that our approach outperforms the stateoftheart systems.	2	3.0
aspect level sentiment classification with deep memory network	we introduce a deep memory network for aspect level sentiment classification. unlike featurebased svm and sequential neural models such as lstm, this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect. such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory. experiments on laptop and restaurant datasets demonstrate that our approach performs comparable to stateofart feature based svm system, and substantially better than lstm and attentionbased lstm architectures. on both datasets we show that multiple computational layers could improve the performance. moreover, our approach is also fast. the deep memory network with 9 layers is 15 times faster than lstm with a cpu implementation.	3	3.5
different feature selection for sentiment classification	sentiment analysis (sa) research has increased tremendously in recent times .sentiment analysis means to extract opinion of users from review documents. sentiment classification using machine learning (ml ) methods faces the problem of high dimensionality of feature vector. therefore, a feature selection method is required to eliminate the irrelevant and noisy features from the feature vector for efficient working of ml algorithms rough set theory provides an important concept for feature reduction called reduct. the cost of reduct set computation is highly influenced by the attribute size of the dataset where the problem of finding reducts has been proven as np hard problems.different feature selection are applied on different data set, experimental results show that mrmr is better compared to ig for sentiment classification, hybrid feature selection method based on the rst and information gain (ig) is better compared to the previous methods. proposed methods are evaluated on four standard datasets viz. movie review, product (book, dvd, and electronics) reviewed datasets, and experimental results show that hybrid feature selection method outperforms than feature selection methods for sentimental classification.	1	2.25
a hybrid approach for sentiment classification of egyptian dialect tweets	sentiment analysis has recently become one of the growing areas of research related to text mining and natural language processing. the main task of sentiment classification is to classify a sentence (i.e. tweet, review, blog, comment, news, etc.) as holding an overall positive, negative or neutral sentiment. most of the current studies related to this topic focus mainly on english texts with very limited resources available for other languages like arabic, especially for the egyptian dialect. in this research work, we would like to improve the performance measures of egyptian dialect sentencelevel sentiment analysis by proposing a hybrid approach which combines both the machine learning approach using support vector machines and the semantic orientation approach. two methodologies were proposed, one for each approach, which were then joined, creating the hybrid proposed approach. the results obtained show significant improvements in terms of the accuracy, precision, recall and fmeasure, indicating that our proposed hybrid approach is effective in sentencelevel sentiment classification. also, the results are very promising which encourages continuing in this line of research.	2	2.6666666666666665
an ensemble sentiment classification system of twitter data for airline services analysis	in airline service industry, it is difficult to collect data about customers' feedback by questionnaires, but twitter provides a sound data source for them to do customer sentiment analysis. however, little research has been done in the domain of twitter sentiment classification about airline services. in this paper, an ensemble sentiment classification strategy was applied based on majority vote principle of multiple classification methods, including naive bayes, svm, bayesian network, c4.5 decision tree and random forest algorithms. in our experiments, six individual classification approaches, and the proposed ensemble approach were all trained and tested using the same dataset of 12864 tweets, in which 10 fold evaluation is used to validate the classifiers. the results show that the proposed ensemble approach outperforms these individual classifiers in this airline service twitter dataset. based on our observations, the ensemble approach could improve the overall accuracy in twitter sentiment classification for other services as well.	3	3.5
an empirical study on sentiment classification of chinese review using word embedding	in this article, how word embeddings can be used as features in chinese sentiment classification is presented. firstly, a chinese opinion corpus is built with a million comments from hotel review websites. then the word embeddings which represent each comment are used as input in different machine learning methods for sentiment classification, including svm, logistic regression, convolutional neural network (cnn) and ensemble methods. these methods get better performance compared with ngram models using naive bayes (nb) and maximum entropy (me). finally, a combination of machine learning methods is proposed which presents an outstanding performance in precision, recall and f1 score. after selecting the most useful methods to construct the combinational model and testing over the corpus, the final f1 score is 0.920.	2	3.0
impact of feature selection techniques for tweet sentiment classification	sentiment analysis of tweets is a powerful application of mining social media sites that can be used for a variety of social sensing tasks. common feature engineering techniques frequently result in a large numbers of features being generated to represent tweets. many of these features may degrade classifier performance and increasing computational cost. feature selection techniques can be used to select an optimal subset of features, reducing the computational cost of training a classifier, and potentially improving classification performance. despite its benefits, feature selection has received little attention within the tweet sentiment domain. we study the impact of ten filterbased feature selection techniques on classification performance, using ten feature subset sizes and four different learners. our experimental results demonstrate that feature selection can significantly improve classification performance in comparison to not using feature selection. additionally, both choice of ranker and feature subset size significantly impact classifier performance. to the best of our knowledge, this is the first work which extensively studies feature selections effect on tweet sentiment classification.	2	2.6666666666666665
machine learning and lexicon based methods for sentiment classification: a survey	sentiment classification is an important subject in text mining research, which concerns the application of automatic methods for predicting the orientation of sentiment present on text documents, with many applications on a number of areas including recommender and advertising systems, customer intelligence and information retrieval. in this paper, we provide a survey and comparative study of existing techniques for opinion mining including machine learning and lexiconbased approaches, together with evaluation metrics. also crossdomain and crosslingual approaches are explored. experimental results show that supervised machine learning methods, such as svm and naive bayes, have higher precision, while lexiconbased methods are also very competitive because they require few effort in humanlabeled document and isn't sensitive to the quantity and quality of the training dataset.	2	3.0
simpler is better? lexicon-based ensemble sentiment classification beats supervised methods	it has been shown in this paper that simplistic bag of words (bow) lexicon methods for sentiment polarity assignment with ensemble classifiers are much faster than a supervised approach to sentiment classification while yielding similar accuracy. bow methods also proved to be efficient and fast across all examined datasets. moreover, a new approach to lexicon extraction that can be successfully used for sentiment polarity assignment is presented in the paper. it has been shown that accuracy obtained from such lexicons outperforms other lexicon based approaches.	1	2.25
a comparative analysis of opinion mining and sentiment classification in non-english languages	in the past decade many opinion mining and sentiment classification studies have been carried out for opinions in english. however, the amount of work done for nonenglish text opinions is very limited. in this review, we investigate opinion mining and sentiment classification studies in three nonenglish languages to find the classification methods and the efficiency of each algorithm used in these methods. it is found that most of the research conducted for nonenglish has followed the methods used in the english language with only limited usage of language specific properties, such as morphological variations. the application domains seem to be restricted to particular fields and significantly less research has been conducted in cross domains.	1	2.25
a fuzzy logic based sentiment classification	sentiment classification aims to detect information such as opinions, explicit , implicit feelings expressed in text. the most existing approaches are able to detect either explicit expressions or implicit expressions of sentiments in the text separately. in this proposed framework it will detect both implicit and explicit expressions available in the meeting transcripts. it will classify the positive, negative, neutral words and also identify the topic of the particular meeting transcripts by using fuzzy logic. this paper aims to add some additional features for improving the classification method. the quality of the sentiment classification is improved using proposed fuzzy logic framework .in this fuzzy logic it includes the features like fuzzy rules and fuzzy cmeans algorithm.the quality of the output is evaluated using the parameters such as precision, recall, fmeasure. here fuzzy cmeans clustering technique measured in terms of purity and entropy. the data set was validated using 10fold cross validation method and observed 95% confidence interval between the accuracy values .finally, the proposed fuzzy logic method produced more than 85 % accurate results and error rate is very less compared to existing sentiment classification techniques.	1	2.0
collaborative multi-domain sentiment classification	sentiment classification is a hot research topic in both industrial and academic fields. the mainstream sentiment classification methods are based on machine learning and treat sentiment classification as a text classification problem. however, sentiment classification is widely recognized as a highly domaindependent task. the sentiment classifier trained in one domain may not perform well in another domain. a simple solution to this problem is training a domainspecific sentiment classifier for each domain. however, it is difficult to label enough data for every domain since they are in a large quantity. in addition, this method omits the sentiment information in other domains. in this paper, we propose to train sentiment classifiers for multiple domains in a collaborative way based on multitask learning. specifically, we decompose the sentiment classifier in each domain into two components, a general one and a domainspecific one. the general sentiment classifier can capture the global sentiment information and is trained across various domains to obtain better generalization ability. the domainspecific sentiment classifier is trained using the labeled data in one domain to capture the domainspecific sentiment information. in addition, we explore two kinds of relations between domains, one based on textual content and the other one based on sentiment word distribution.	3	3.0
chinese sentiment classification using a neural network tool — word2vec	sentiment classification is the main and popular task in the field of sentiment analysis. most of the existing researches focus on how to extract the effective features, such as lexical features and syntactic features, while limited work has been done on the extraction of semantic features, which can make more contributions to sentiment classification. this paper presents a method for sentiment classification based on word2vec. word2vec is a tool, which establishes the neural network models to learn the vector representations of words in the high dimensional vector space. so it can extract the deep semantic relationships between words. in this paper, firstly, we cluster the similar features together using word2vec. and then we use word2vec again to learn the word representations as candidate feature vectors. after feature selection, the svmperf package is adopted to train and classify the comment texts. to conduct the experiments, we collect a large number of chinese comments on clothing products as data set. the experimental results show that the accuracy of sentiment classification is over 90 percent, which proves the effectiveness of proposed method for chinese sentiment classification.	1	2.0
an ensemble sentiment classification system of twitter data for airline services analysis	in airline service industry, it is difficult to collect data about customers' feedback by questionnaires, but twitter provides a sound data source for them to do customer sentiment analysis. however, little research has been done in the domain of twitter sentiment classification about airline services. in this paper, an ensemble sentiment classification strategy was applied based on majority vote principle of multiple classification methods, including naive bayes, svm, bayesian network, c4.5 decision tree and random forest algorithms. in our experiments, six individual classification approaches, and the proposed ensemble approach were all trained and tested using the same dataset of 12864 tweets, in which 10 fold evaluation is used to validate the classifiers. the results show that the proposed ensemble approach outperforms these individual classifiers in this airline service twitter dataset. based on our observations, the ensemble approach could improve the overall accuracy in twitter sentiment classification for other services as well.	2	2.3333333333333335
sentiment classification in under-resourced languages using graph-based semi-supervised learning methods	in sentiment classification, conventional supervised approaches heavily rely on a large amount of linguistic resources, which are costly to obtain for underresourced languages. to overcome this scarce resource problem, there exist several methods that exploit graphbased semisupervised learning (ssl). however, fundamental issues such as controlling label propagation, choosing the initial seeds, selecting edges have barely been studied. our evaluation on three real datasets demonstrates that manipulating the label propagating behavior and choosing labeled seeds appropriately play a critical role in adopting graphbased ssl approaches for this task.	1	1.75
enhancing machine-learning methods for sentiment classification of web data	with advances in web technologies, more and more people are turning to popular social media platforms such as twitter to express their feelings and opinions on a variety of topics and current issues online. sentiment analysis of web data is becoming a fast and effective way of evaluating public opinion and sentiment for use in marketing and social behavioral studies. this research investigates the enhancement techniques in machinelearning methods for sentiment classification of web data. feature selection, negation dealing, and emoticon handling are studied in this paper for their ability to improve the performance of machinelearning methods. the range of enhancement techniques is tested using different text data sets, such as tweets and movie reviews. the results show that different enhancement methods can improve classification efficacy and accuracy differently.	1	1.75
cross-lingual sentiment classification using multiple source languages in multi-view semi-supervised learning	crosslingual sentiment classification aims to utilize annotated sentiment resources in one language (typically english) for sentiment classification of text documents in another language. most existing research works rely on automatic machine translation services to directly project information from one language to another. however, due to the existence of differing linguistic terms and writing styles between different languages, translated data cannot cover all vocabularies which exist in the original data. further, different term distribution between translated data and original data can lead to low performance in crosslingual sentiment classification. to overcome these problems, we propose a new model which uses labelled data from multiple source languages in a multiview semisupervised learning approach so as to incorporate unlabelled data from the target language into the learning process. the proposed model was applied to book review datasets in four different languages. experiments have shown that our model can effectively improve the crosslingual sentiment classification performance in comparison with some baseline methods.	1	2.0
a comparative performance evaluation of neural network based approach for sentiment classification of online reviews	the aim of sentiment classification is to efficiently identify the emotions expressed in the form of text messages. machine learning methods for sentiment classification have been extensively studied, due to their predominant classification performance. recent studies suggest that ensemble based machine learning methods provide better performance in classification. artificial neural networks (anns) are rarely being investigated in the literature of sentiment classification. this paper compares neural network based sentiment classification methods (back propagation neural network (bpn), probabilistic neural network (pnn) & homogeneous ensemble of pnn (hen)) using varying levels of word granularity as features for feature level sentiment classification. they are validated using a dataset of product reviews collected from the amazon reviews website. an empirical analysis is done to compare results of ann based methods with two statistical individual methods. the methods are evaluated using five different quality measures and results show that the homogeneous ensemble of the neural network method provides better performance. among the two neural network approaches used, probabilistic neural networks (pnns) outperform in classifying the sentiment of the product reviews.	3	3.0
a sentiment classification model based on multiple classifiers	with the widespread usage of social networks, forums and blogs, customer reviews emerged as a critical factor for the customers鈥 purchase decisions. since the beginning of 2000s, researchers started to focus on these reviews to automatically categorize them into polarity levels such as positive, negative, and neutral. this research problem is known as sentiment classification. the objective of this study is to investigate the potential benefit of multiple classifier systems concept on turkish sentiment classification problem and propose a novel classification technique. vote algorithm has been used in conjunction with three classifiers, namely naive bayes, support vector machine (svm), and bagging. parameters of the svm have been optimized when it was used as an individual classifier. experimental results showed that multiple classifier systems increase the performance of individual classifiers on turkish sentiment classification datasets and meta classifiers contribute to the power of these multiple classifier systems. the proposed approach achieved better performance than naive bayes, which was reported the best individual classifier for these datasets, and support vector machines. multiple classifier systems (mcs) is a good approach for sentiment classification, and parameter optimization of individual classifiers must be taken into account while developing mcsbased prediction systems.	4	5.0
sentiment classification technology based on markov logic networks	with diverse online media emerging, there is a growing concern of sentiment classification problem. at present, text sentiment classification mainly utilizes supervised machine learning methods, which feature certain domain dependency. on the basis of markov logic networks (mlns), this study proposed a crossdomain multitask text sentiment classification method rooted in transfer learning. through manytoone knowledge transfer, labeled text sentiment classification, knowledge was successfully transferred into other domains, and the precision of the sentiment classification analysis in the text tendency domain was improved. the experimental results revealed the following (1) the model based on a mln demonstrated higher precision than the single individual learning plan model. (2) multitask transfer learning based on markov logical networks could acquire more knowledge than selfdomain learning. the crossdomain text sentiment classification model could significantly improve the precision and efficiency of text sentiment classification.	3	2.5
polarity shifting for romanian sentiment classification	there are three main classes of modifiers that can affect the polarity of the sentiments described in natural language texts negations, intensifiers and diminishers. in this paper, we concentrate on the study of these particular words which have a very important semantic role in any natural language description. our study is applied on a real data set extracted from the popular romanian web site amfostacolo dedicated to tourist impressions.	3	2.5
twise at semeval-2016 task 4: twitter sentiment classification	this paper describes the participation of the team twise in the semeval 2016 challenge. specifically, we participated in task 4, namely sentiment analysis in twitter for which we implemented sentiment classification systems for subtasks a, b, c and d. our approach consists of two steps. in the first step, we generate and validate diverse feature sets for twitter sentiment evaluation, inspired by the work of participants of previous editions of such challenges. in the second step, we focus on the optimization of the evaluation measures of the different subtasks. to this end, we examine different learning strategies by validating them on the data provided by the task organisers. for our final submissions we used an ensemble learning approach (stacked generalization) for subtask a and single linear models for the rest of the subtasks.	3	2.5
enhancing machine-learning methods for sentiment classification of web data	with advances in web technologies, more and more people are turning to popular social media platforms such as twitter to express their feelings and opinions on a variety of topics and current issues online. sentiment analysis of web data is becoming a fast and effective way of evaluating public opinion and sentiment for use in marketing and social behavioral studies. this research investigates the enhancement techniques in machinelearning methods for sentiment classification of web data. feature selection, negation dealing, and emoticon handling are studied in this paper for their ability to improve the performance of machinelearning methods. the range of enhancement techniques is tested using different text data sets, such as tweets and movie reviews. the results show that different enhancement methods can improve classification efficacy and accuracy differently.	1	1.75
hybrid deep belief networks for semi-supervised sentiment classification	in this paper, we develop a novel semisupervised learning algorithm called hybrid deep be lief networks (hdbn), to address the semisupervised sentiment classification problem with deep learning. first, we construct the previous several hidden layers using restricted boltzmann machines (rbm), which can reduce the dimension and  the information of the reviews quickly. second, we construct the following hidden layers using convolutional restricted boltz mann machines (crbm), which can  the information of reviews effectively. third, the constructed deep architecture is finetuned by gradientdescent based supervised learning with an exponential loss function. we did several experiments on five sentiment classification datasets, and show that hdbn is competitive with previous semisupervised learning algorithm. ex periments are also conducted to verify the effectiveness of our proposed method with different number of unlabeled reviews.	1	1.75
study on feature selection and machine learning algorithms for malay sentiment classification	online social media is used to show the sentiments of different individuals about various subjects. sentiment analysis or opinion mining has recently been considered as one of the highly dynamic research fields in natural language processing, web mining, and machine learning. there has been a very limited amount of research that focuses on sentiment analysis in the malay language. this study investigates how feature selection methods contribute to the improvement of malay sentiment classification performance. three supervised machinelearning classifiers and seven feature selection methods are used to conduct a series of experiments for the effective selection of the appropriate methods for the automatic sentiment classification of online malaywritten reviews. findings show that the classifications of malay sentiment improve using feature selections approaches. this work demonstrates that all feature reduction methods generally improve classifier performance. support vector machine (svm) approach provide the highest accuracy performance of features selection in order to classify malay sentiment comparing with other classifications approaches such as pca and chi square. svm records 87% as experimental accuracy result of feature selection.	2	2.0
combination of multi-view multi-source language classifiers for cross-lingual sentiment classification	crosslingual sentiment classification aims to conduct sentiment classification in a target language using labeled sentiment data in a source language. most existing research works rely on machine translation to directly project information from one language to another. but crosslingual classifiers always cannot learn all characteristics of target language data by using only translated data from one language. in this paper, we propose a new learning model that uses labeled sentiment data from more than one language to compensate some of the limitations of resource translation. in this model, we first create different views of sentiment data via machine translation, then train individual classifiers in every view and finally combine the classifiers for final decision. we have applied this model to the sentiment classification datasets in three different languages using different combination methods. the results show that the combination methods improve the performances obtained separately by each individual classifier.	1	1.75
sentiment classification of online political discussions	online political discussions have received a lot of attention over the past years. in this paper we compare two sentiment lexicon approaches to classify the sentiment of sentences from political discussions. the first approach is based on applying the number of words between the target and the sentiment words to weight the sentence sentiment score. the second approach is based on using the shortest paths between target and sentiment words in a dependency graph and linguistically motivated syntactic patterns expressed as dependency paths. the methods are tested on a corpus of sentences from online norwegian political discussions. the results show that the method based on dependency graphs performs significantly better than the wordbased approach.	1	1.5
sentiment classification using enhanced contextual valence shifters	we have explored different methods of improving the accuracy of sentiment classification. the sentiment orientation of a document can be positive (+), negative (), or neutral (0). we combine five dictionaries from [2, 3, 4, 5, 6] into the new one with 21137 entries. the new dictionary has many verbs, adverbs, phrases and idioms, that are not in five ones before. the paper shows that our proposed method based on the combination of termcounting method and enhanced contextual valence shifters method has improved the accuracy of sentiment classification. the combined method has accuracy 68.984% on the testing dataset, and 69.224% on the training dataset. all of these methods are implemented to classify the reviews based on our new dictionary and the internet movie data set.	1	1.5
twitter sentiment classification for measuring public health concerns	an important task of public health officials is to keep track of health issues, such as spreading epidemics. in this paper, we are addressing the issue of spreading public concernabout epidemics.	2	2.0
semantic orientation approach for sentiment classification	opinions are the fundamental aspect to almost all decision making activities. the increased usage of internet and the exchange of user opinions through social media and public forums on the web has become the motivation for sentiment analysis. due to the infinite amount of user opinions available throughout the web it is necessary to automatically analyze and classify sentiment expressed in opinions. the basic task of sentiment analysis or opinion mining is sentiment classification which classifies the content as positive, negative and irrelevant. this paper discusses an approach where an exposed stream of tweets from the twitter micro blogging site are preprocessed and classified based on their sentiments. in sentiment classification system the concept of opinion subjectivity has been accounted. in this paper, we present opinion detection and organization subsystem, which have already been integrated into our larger questionanswering system. the subjectivity classification system uses geneticbased machine learning (gbml) technique that considers subjectivity as a semantic problem. the classification of a review is predicted through the average semantic orientation of the phrases in the review that contain adjectives or adverbs. experimental results of the proposed techniques are efficient and generate eminent evaluations.	1	1.5
sentitfidf – sentiment classification using relative term frequency inverse document frequency	sentiment classification refers to the computational techniques for classifying whether the sentiments of text are positive or negative. statistical techniques based on term presence and term frequency, using support vector machine are popularly used for sentiment classification. this paper presents an approach for classifying a term as positive or negative based on its proportional frequency count distribution and proportional presence count distribution across positively tagged documents in comparison with negatively tagged documents. our approach is based on term weighting techniques that are used for information retrieval and sentiment classification. it differs significantly from these traditional methods due to our model of logarithmic differential term frequency and term presence distribution for sentiment classification. terms with nearly equal distribution in positively tagged documents and negatively tagged documents were classified as a sentistopword and discarded. the proportional distribution of a term to be classified as sentistopword was determined experimentally. we evaluated the sentitfidf model by comparing it with state of art techniques for sentiment classification using the movie dataset.	1	1.5
density based active self-training for cross-lingual sentiment classification	crosslingual sentiment classification aims to utilize annotated sentiment resources in one language (typically english) for sentiment classification in another language. most existing research works rely on automatic machine translation services to directly project information from one language to another. however, since machine translation quality is still far from satisfactory and also term distribution across languages may be dissimilar, these techniques cannot reach the performance of monolingual approaches. to overcome these limitations, we propose a novel learning model based on active learning and selftraining to incorporate unlabeled data from the target language into the learning process. further, in this model, we consider the density of unlabeled data to avoid outlier selection in active learning. the proposed model was applied to book review datasets in two different languages. experiments showed that the proposed model could effectively reduce labeling efforts in comparison with some baseline methods.	1	1.5
using unsupervised information to improve semi-supervised tweet sentiment classification	supervised algorithms require a set of representative labeled data for building classification models. however, labeled data are usually difficult and expensive to obtain, which motivates the interest in semisupervised learning. this type of learning uses both labeled and unlabeled data in the training process and is particularly useful in applications such as tweet sentiment analysis, where a large amount of unlabeled data is available. semisupervised learning for tweet sentiment analysis, although quite appealing, is relatively new. we propose a semisupervised learning framework that combines unsupervised information, captured from a similarity matrix constructed from unlabeled data, with a classifier. our motivation is that such a similarity matrix is a powerful knowledgediscovery tool that can help classify unlabeled tweet sets. our framework makes use of the wellknown selftraining algorithm to induce a better tweet sentiment classifier. experimental results in realworld datasets demonstrate that the proposed framework can improve the accuracy of tweet sentiment analysis.	3	2.0
cached long short-term memory neural networks for document-level sentiment classification	recently, neural networks have achieved great success on sentiment classification due to their ability to alleviate feature engineering. however, one of the remaining challenges is to model long texts in documentlevel sentiment classification under a recurrent architecture because of the deficiency of the memory unit. to address this problem, we present a cached long shortterm memory neural networks (clstm) to capture the overall semantic information in long texts. clstm introduces a cache mechanism, which divides memory into several groups with different forgetting rates and thus enables the network to keep sentiment information better within a recurrent unit. the proposed clstm outperforms the stateoftheart models on three publicly available documentlevel sentiment analysis datasets.	3	2.0
combination of multi-view multi-source language classifiers for cross-lingual sentiment classification	crosslingual sentiment classification aims to conduct sentiment classification in a target language using labeled sentiment data in a source language. most existing research works rely on machine translation to directly project information from one language to another. but crosslingual classifiers always cannot learn all characteristics of target language data by using only translated data from one language. in this paper, we propose a new learning model that uses labeled sentiment data from more than one language to compensate some of the limitations of resource translation. in this model, we first create different views of sentiment data via machine translation, then train individual classifiers in every view and finally combine the classifiers for final decision. we have applied this model to the sentiment classification datasets in three different languages using different combination methods. the results show that the combination methods improve the performances obtained separately by each individual classifier.	1	1.5
unimelb at semeval-2016 tasks 4a and 4b: an ensemble of neural networks and a word2vec based model for sentiment classification	this paper describes a support vector machinebased approach to different tasks related to sentiment analysis in twitter for spanish. we focus on parameter optimization of the models and the combination of several models by means of voting techniques. we evaluate the proposed approach in all the tasks that were defined in the five editions of the tass workshop, between 2012 and 2016.	3	2.0
sentiment classification based on latent dirichlet allocation	opinion miningrefers to the use of natural language processing, text analysis and computational linguistics to identify and extract the subjective information. opinion mining has become an indispensible part of online reviews which is in the present scenario. in the field of information retrieval, a various kinds of probabilistic topic modeling techniques have been used to analyze contents present in a document. a topic model is a generative technique for document. all topic models share the idea that documents are having mixture of topics, and the topic is a probability distribution over words. recently topic modeling techniques have been used to identify the meaningful review aspects, but existing topic models like latent dirichlet markov allocation (ldma), hierarchical aspect sentiment model (hasm) do not identify aspect specific opinion words and also not suitable for shared features. in the proposed system, movie review dataset is collected from the imdb database and is preprocessed. tfidf is calculated for the preprocessed data and result is given to lda model which is then used to discover both the aspects and aspect specific opinion words. after that chi value has been determined, svm classifier is used to classify the topics preferable to each and every document.	2	1.6666666666666667
sentiment classification techniques for arabic language: a survey	with the advent of online data, sentiment analysis has received growing attention in recent years. sentiment analysis aims to determine the overall sentiment orientation of a speaker or writer towards a specific entity or towards a specific feature of a specific entity. a fundamental task of sentiment analysis is sentiment classification, which aims to automatically classify opinionated text as being positive, negative, or neutral. although the literature on sentiment classification is quite extensive, only a few endeavors to classify opinionated text written in the arabic language can be found. this paper provides a comprehensive survey of existing lexicon, machine learning, and hybrid sentiment classification techniques for arabic language.	3	2.0
structured microblog sentiment classification via social context regularization	microblog sentiment analysis is a fundamental problem for many interesting applications. existing microblog sentiment classification methods judge the sentiment polarity mainly according to textual content. however, since microblog messages are very short and noisy, and their sentiment polarities are often ambiguous and contextdependent, the accuracy of microblog sentiment classification is usually unsatisfactory. fortunately, microblog messages lie in social media and contain rich social contexts. the social context information often implies sentiment connections between microblog messages. for example, a microblogging user usually expresses the same sentiment when posting multiple messages towards the same topic. motivated by these observations, in this paper we propose a structured microblog sentiment classification (smsc) framework. our framework can combine social context information with textual content information to improve microblog sentiment classification accuracy. two kinds of social contexts are used in our framework, i.e., social connections between microblog messages brought by the same author and social connections brought by social relations between users. in our framework, social context information is formulated as the graph structure over the sentiments of microblog messages.	3	2.0
sentiment classification of online political discussions: a comparison of a word-based and dependency-based method	online political discussions have received a lot of attention over the past years. in this paper we compare two sentiment lexicon approaches to classify the sentiment of sentences from political discussions. the first approach is based on applying the number of words between the target and the sentiment words to weight the sentence sentiment score. the second approach is based on using the shortest paths between target and sentiment words in a dependency graph and linguistically motivated syntactic patterns expressed as dependency paths. the methods are tested on a corpus of sentences from online norwegian political discussions. the results show that the method based on dependency graphs performs significantly better than the wordbased approach.	2	1.6666666666666667
extreme learning machine for multi-class sentiment classification of tweets	the increasing popularity of social media in recent years has created new opportunities to study and evaluate public opinions and sentiments for use in marketing and social behavioural studies.	3	2.0
chinese microblog sentiment classification based on convolution neural network with content extension method	related research for sentiment analysis on chinese microblog is aiming at analyzing the emotion of posters. this paper presents a content extension method that combines post with its' comments into a microblog conversation for sentiment analysis. a new convolutional auto encoder which can extract contextual sentiment information from microblog conversation of the post is proposed. furthermore, a dbn model, which is composed by several layers of rbm(restricted boltzmann machine) stacked together, is implemented to extract some higher level feature for short text of a post. these rbm layers can encoder observed short text to learn hidden structures or semantics information for better feature representation. a classrbm (classification rbm) layer, which is stacked on top of rbm layers, is adapted to achieve the final sentiment classification. the experiment results demonstrate that, with proper structure and parameter, the performance of the proposed deep learning method on sentiment classification is better than stateoftheart surface learning models such as svm or nb, which also proves that dbn is suitable for shortlength document classification with the proposed feature dimensionality extension method.	2	1.6666666666666667
comparative analysis of effect of stopwords removal on sentiment classification	classification refers to the computational techniques for classifying whether the sentiments of text are positive or negative. sentiment classification being a specialized domain of text mining is expected to benefit after preprocessing such as removing stopwords. stopwords are frequently occurring words that hardly carry any information and orientation. in this paper the effect of stopwords removal on various sentiment classification models was analyzed. sentiment classification models were evaluated using the movie document dataset. accuracy increased from unprocessed dataset to stopwords removed dataset for traditional sentiment classifiers. our classifiers had hardly any impact of stopwords removal which indicates that they handled stopwords at the time of classification itself. our classifiers also displayed accuracy better than traditional classifier and another surveyed classifier based on term weighting technique.	3	2.0
jointly learning bilingual sentiment and semantic representations for cross-language sentiment classification	crosslanguage sentiment classification (clsc) aims at leveraging the semantic and sentiment knowledge in a resourceabundant language (source language) for sentiment classification in a resourcescar.	4	4.0
sentiment classification using subjective and objective views	this work proposes a new semisupervised sentiment classification method by exploiting a large number of unlabeled instances to conduct sentiment classification for web consumer reviews. in the proposed method every consumer review has two views subjective view and objective view. the subjective view of a consumer review reflects the opinions expressed by opinion words, while the objective view is constructed by the remaining text features. this work is trying to combine two kinds of views to carry out sentiment classification. the method is based on the cotraining framework which needs three basic sentiment classifiers to iteratively get the final sentiment classifier. in the proposed method, the first sentiment classifier is constructed using the common unigram features coming from consumer reviews. the second sentiment classifier is trained on the subjective views constructed by opinion words extracted from consumer reviews. the remaining text features of these reviews are used for obtaining the objective views which can be trained for the third classifier. experimental results show the proposed method is effective, and it has better performance than the selflearning svm method.	1	1.25
target-dependent sentiment classification with long short term memory	targetdependent sentiment classification remains a challenge modeling the semantic relatedness of a target with its context words in a sentence. different context words have different influences on determining the sentiment polarity of a sentence towards the target. therefore, it is desirable to integrate the connections between target word and context words when building a learning system. in this paper, we develop two target dependent long shortterm memory (lstm) models, where target information is automatically taken into account. we evaluate our methods on a benchmark dataset from twitter. empirical results show that modeling sentence representation with standard lstm does not perform well. incorporating target information into lstm can significantly boost the classification accuracy. the targetdependent lstm models achieve stateoftheart performances without using syntactic parser or external sentiment lexicons.	2	1.6666666666666667
cross-domain sentiment classification via topical correspondence transfer	sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). in real applications, these users generated sentiment data can span so many different domains that it is difficult to manually label training data for all of them. in this article, we develop a general solution to crossdomain sentiment classification when we do not have any labeled data in a target domain but have some labeled data in a source domain. to bridge the gap between domains, we propose a novel algorithm, called topical correspondence transfer (tct). this is achieved by learning the domainspecific information from different domains into unified topics, with the help of shared topics across all domains. in this way, the topical correspondences behind the shared topics can be used as a bridge to reduce the gap between domains. we conduct experiments on a benchmark composed of reviews of 4 types of amazon products. experimental results show that our proposed tct significantly outperforms the baseline method, and achieves an accuracy which is competitive with the stateoftheart methods for crossdomain sentiment classification.	2	1.6666666666666667
role of emotion icons in sentiment classification of arabic tweets	in recent years, there is enormous increase of data content due to emergence of social media platforms in digital word of internet. the text mining is very important technique to discover the knowledge from unstructured data. automatic sentiment analysis is one of the important applications of text mining. the sentiment analysis is used to predict the text polarity (positive, negative, and neutral). furthermore, the most of users using social media such as twitter use informal language to express their opinions. in this paper, we propose an automatic approach to predict sentiments for informal arabic language. we chose arabic tweets as input for our study. we observed through our experiment results that although emotion icons presence in the tweets helps in development of comparatively more accurate classifier, however they play ambiguous role in defining the sentiments of tweets.	1	1.25
fuzzy sentiment membership determining for sentiment classification	traditional support vector machine treats all samples using the same weight. therefore it is very sensitive to noisy data. while the fuzzy support vector machine assigns lower weights to the samples which make small contributions to classification, thus it is beneficial to reduce the effects of noisy and unimportant data on the classification accuracy rate. in this paper, we propose a novel fuzzy sentiment membership determining method for solving sentiment classification task. we assume that strong intensity texts make more contributions to sentiment classification, while weak intensity texts are unimportant for the classification. in order to get the fuzzy sentiment membership of review texts, this paper proposes a threelayer sentiment propagation model. firstly, we calculate the sentiment score of texts by the interrelations of the texts, topics and words, and ensure that the absolute value of sentiment score as the fuzzy sentiment membership degree of texts. then, we train a fuzzy support vector machine to classify the samples from the test data sets. finally, we conduct some experiments on four english reviews data sets from amazon shopping websites. the experimental results show that the proposed method can improve the accuracy of sentiment classification effectively.	2	1.6666666666666667
applying three-way decisions to sentiment classification with sentiment uncertainty	summary sentiment uncertainty is a key problem of sentiment classification. in this paper, we mainly focus on two issues with sentiment uncertainty, i.e., contextdependent sentiment classification and topicdependent sentiment classification. this is the first work that applies threeway decisions to sentiment classification from the perspective of the decisiontheoretic rough set model. we discuss the relationship between sentiment classification rules and thresholds involved in threeway decisions and then prove it. the experiment results on real data sets validate that our methods are satisfactory and can achieve better performance.	1	1.25
applying three-way decisions to sentiment classification with sentiment uncertainty	sentiment uncertainty is a key problem of sentiment classification. in this paper, we mainly focus on two issues with sentiment uncertainty, i.e., contextdependent sentiment classification and topicdependent sentiment classification. this is the first work that applies threeway decisions to sentiment classification from the perspective of the decisiontheoretic rough set model. we discuss the relationship between sentiment classification rules and thresholds involved in threeway decisions and then prove it. the experiment results on real data sets validate that our methods are satisfactory and can achieve better performance.	1	1.25
facebook users relationships analysis based on sentiment classification	it is presented an approach aimed at analyzing the homepage of a facebook user or group in order to automatically detect who has discussed what and how it has been discussed. all public posts shared by an user are retrieved by an ad hoc built crawler. information such as a text messages, comments, likes, is extracted for each post. each post is classified as belonging to a set of predefined categories and its sentiment is also detected as being positive, negative or neutral. all the comments to that post are therefore analyzed and categorized together with its sentiment polarity. for each category it is created a graph where it is highlighted the concordance of sentiment between the posts and the related comments. the graph can be therefore used to profile the user relationships according to sentiment classification.	1	1.25
a comparative study of feature selection and machine learning algorithms for arabic sentiment classification	sentiment analysis is a very challenging and important task that involves natural language processing, web mining, and machine learning. sentiment analysis in the arabic language is a more challenging task than in other languages due to the morphological complexity of the arabic and the large variation of its dialects. this paper presents an empirical comparison of seven feature selection methods (information gain, principal components analysis, relieff, gini index, uncertainty, chisquared, and support vector machines (svms)), and three machine learning classifiers (svm, naive bayes, and knearest neighbor) for arabic sentiment classification. a wide range of comparative experiments are conducted on an opinion corpus for arabic (oca). this paper demonstrates that feature selection does improve the performance of arabic sentimentbased classification, but the result depends on the method used and the number of features selected. the experimental results demonstrate that feature reduction methods are found to improve the classifier performance. moreover, the experimental results indicate that svmbased feature selection yields the best performance for feature selection and that the svm classifier outperforms the other techniques for arabic sentimentbased classification.	1	1.25
sentiment classification: an approach for indian language tweets using decision tree	this paper describes the system we used for shared task on sentiment analysis in indian languages (sail) tweets, at mike2015. twitter is one of the most popular platform which allows users to share their opinion in the form of tweets. since it restricts the users with 140 characters, the tweets are actually very short to carry opinions and sentiments to analyze. we take the help of a twitter training dataset in indian language (hindi) and apply data mining approaches for analyzing the sentiments. we used a stateoftheart data mining tool weka to automatically classify the sentiment of hindi tweets into positive, negative or neutral.	2	1.3333333333333333
sentiment classification: an approach for indian language tweets using decision tree	this paper describes the system we used for shared task on sentiment analysis in indian languages (sail) tweets, at mike2015. twitter is one of the most popular platform which allows users to share.	2	1.3333333333333333
microblog sentiment classification with contextual knowledge regularization	microblog sentiment classification is an important research topic which has wide applications in both academia and industry. because microblog messages are short, noisy and contain masses of acronyms and informal words, microblog sentiment classification is a very challenging task. fortunately, collectively the contextual information about these idiosyncratic words provide knowledge about their sentiment orientations. in this paper, we propose to use the microblogs' contextual knowledge mined from a large amount of unlabeled data to help improve microblog sentiment classification. we define two kinds of contextual knowledge wordword association and wordsentiment association. the contextual knowledge is formulated as regularization terms in supervised learning algorithms. an efficient optimization procedure is proposed to learn the model. experimental results on benchmark datasets show that our method can consistently and significantly outperform the stateoftheart methods.	2	1.3333333333333333
semi-stacking for semi-supervised sentiment classification	reacttext 168 personal profile information on social media like linkedin.com and facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. however, personal profiles usually lack consistent organization confronted with the large amount of available information. therefore, it is always a challenge for people to quickly find desired information...  /reacttext  reacttext 169   /reacttext [show full ]	2	1.3333333333333333
lcct: a semi-supervised model for sentiment classification	analyzing public opinions towards products, services and social events is an important but challenging task. an accurate sentiment analyzer should take both lexiconlevel information and corpuslevel information into account. it also needs to exploit the domainspecific knowledge and utilize the common knowledge shared across domains. in addition, we want the algorithm being able to deal with missing labels and learning from incomplete sentiment lexicons. this paper presents a lcct (lexiconbased and corpusbased, cotraining) model for semisupervised sentiment classification. the proposed method combines the idea of lexiconbased learning and corpusbased learning in a unified cotraining framework. it is capable of incorporating both domainspecific and domainindependent knowledge. extensive experiments show that it achieves very competitive classification accuracy, even with a small portion of labeled data. comparing to stateoftheart sentiment classification methods, the lcct approach exhibits significantly better performances on a variety of datasets in both english and chinese. 漏 2015 association for computational linguistics	2	1.3333333333333333
feature selection for sentiment classification using matrix factorization	feature selection is a critical task in both sentiment classification and topical text classification. however, most existing feature selection algorithms ignore a significant contextual difference between them that sentiment classification is commonly depended more on the words conveying sentiments. based on this observation, a new feature selection method based on matrix factorization is proposed to identify the words with strong intersentiment distinguishability and intrasentiment similarity. furthermore, experiments show that our models require less features while still maintaining reasonable classification accuracy.	2	1.3333333333333333
distributional correspondence indexing for cross-lingual and cross-domain sentiment classification	summary domain adaptation (da) techniques aim at enabling machine learning methods learn effective classifiers for a “target” domain when the only available training data belongs to a different “source” domain. in this paper we present the distributional correspondence indexing (dci) method for domain adaptation in sentiment classification. dci derives term representations in a vector space common to both domains where each dimension reflects its distributional correspondence to a pivot, i.e., to a highly predictive term that behaves similarly across domains. term correspondence is quantified by means of a distributional correspondence function (dcf). we propose a number of efficient dcfs that are motivated by the distributional hypothesis, i.e., the hypothesis according to which terms with similar meaning tend to have similar distributions in text. experiments show that dci obtains better performance than current stateoftheart techniques for crosslingual and crossdomain sentiment classification. dci also brings about a significantly reduced computational cost, and requires a smaller amount of human intervention. as a final contribution, we discuss a more challenging formulation of the domain adaptation problem, in which both the crossdomain and crosslingual dimensions are tackled simultaneously.	3	1.5
enhanced sentiment classification of telugu text using ml techniques.	by using a single correlation matrix, classic music algorithm estimates subspaces through traditional eigenvalue decomposition. its performances suffered from these inaccurate subspaces greatly. in this paper, a set of spatial temporal correlation matrices are firstly constructed by exploiting the array received data. secondly, in order to get more accurate subspace, we establish a uniform cost function that exploits these matrices. thirdly, a cyclic optimization algorithm is designed to jointly estimate the signal subspace. moreover, by the relation between signal and noise subspace, the corresponding projection matrix of noise subspace is obtained, hence an improved music algorithm is implemented by this projection matrix. finally three experiments are conducted to validate the performances of the proposed algorithm.	3	1.5
transfer learning for cross-lingual sentiment classification with weakly shared deep neural networks	crosslingual sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of data in a labelscarce target language by exploiting labeled data from a labelrich language. the fundamental challenge of crosslingual learning stems from a lack of overlap between the feature spaces of source language data and that of target language data. to address this challenge, previous studies have been performed to make use of the translated resources for sentiment classification in the target language, and the classification performance is far from satisfactory because of the language gap between the source language and the translated target language. in this paper, to address the above challenge, we present a novel deep neural network structure, called weakly shared deep neural networks (wsdnns), to transfer the crosslingual information from a source language to a target language. to share the sentiment labels between two languages, we build multiple weakly shared layers of features. it allows to represent both shared interlanguage features and languagespecific ones, making this structure more flexible and powerful in capturing the feature representations of bilingual languages jointly. we conduct a set of experiments with crosslingual sentiment classification tasks on multilingual amazon product reviews.	3	1.5
learning sentence embeddings with auxiliary tasks for cross-domain sentiment classification	in this paper, we study crossdomain sentimentclassification with neural network architectures.we borrow the idea from structuralcorrespondence learning and use two auxiliarytasks to help induce a sentence embeddingthat supposedly works well across domains forsentiment classification. we also propose tojointly learn this sentence embedding togetherwith the sentiment classifier itself. experimentresults demonstrate that our proposedjoint model outperforms several stateofthe artmethods on five benchmark datasets.	3	1.5
leveraging large amounts of weakly supervised data for multi-language sentiment classification	this paper presents a novel approach for multilingual sentiment classification in short texts. this is a challenging task as the amount of training data in languages other than english is very limited. previously proposed multilingual approaches typically require to establish a correspondence to english for which powerful classifiers are already available. in contrast, our method does not require such supervision. we leverage large amounts of weaklysupervised data in various languages to train a multilayer convolutional network and demonstrate the importance of using pretraining of such networks. we thoroughly evaluate our approach on various multilingual datasets, including the recent semeval2016 sentiment prediction benchmark (task 4), where we achieved stateoftheart performance. we also compare the performance of our model trained individually for each language to a variant trained for all languages at once. we show that the latter model reaches slightly worse  but still acceptable  performance when compared to the single language model, while benefiting from better generalization properties across languages.	4	3.0
sentiment classification of hinglish text	in order to determine the sentiment polarity of hinglish text written in roman script, we experimented with different combinations of feature selection methods and a host of classifiers using term frequencyinverse document frequency feature representation. we carried out in total 840 experiments in order to determine the best classifiers for sentiment expressed in the news and facebook comments written in hinglish. we concluded that a triumvirate of term frequencyinverse document frequencybased feature representation, gain ratio based feature selection, and radial basis function neural network as the best combination to classify sentiment expressed in the hinglish text.	3	1.5
modeling rich contexts for sentiment classification with lstm	sentiment analysis on social media data such as tweets and weibo has become a very important and challenging task. due to the intrinsic properties of such data, tweets are short, noisy, and of divergent topics, and sentiment classification on these data requires to modeling various contexts such as the retweet/reply history of a tweet, and the social context about authors and relationships. while few prior study has approached the issue of modeling contexts in tweet, this paper proposes to use a hierarchical lstm to model rich contexts in tweet, particularly longrange context. experimental results show that contexts can help us to perform sentiment classification remarkably better.	3	1.5
role of emotion icons in sentiment classification of arabic tweets	in recent years, there is enormous increase of data content due to emergence of social media platforms in digital word of internet. the text mining is very important technique to discover the knowledge from unstructured data. automatic sentiment analysis is one of the important applications of text mining. the sentiment analysis is used to predict the text polarity (positive, negative, and neutral). furthermore, the most of users using social media such as twitter use informal language to express their opinions. in this paper, we propose an automatic approach to predict sentiments for informal arabic language. we chose arabic tweets as input for our study. we observed through our experiment results that although emotion icons presence in the tweets helps in development of comparatively more accurate classifier, however they play ambiguous role in defining the sentiments of tweets.	1	1.0
sentiment classification of chinese online reviews: a comparison of factors influencing performances	with the growing availability and popularity of online consumer reviews, people have been trying to seek sentimentaware applications to gather and understand these opinionrich texts. thus, sentiment classification arises in response to analyse opinions of others automatically. in this paper, experiments of sentiment classification of chinese online reviews across different domains are conducted by considering a couple of factors which potentially influence the sentiment classification performance. experimental results indicate that the size of training sets and the number of features have certain influence on classification accuracy. in addition, there is no significant difference in classification accuracy when using document frequency, chisquare statistic and information gain, respectively, to reduce dimensionality. loworder ngrams outperforms highorder ngrams in terms of accuracy if ngrams is taken as features. furthermore, when words and combination of words are selected as features, the accuracy of adjectives is much close to that of nvaa (the combination of nouns, verbs, adjectives and adverbs), and is better than others as well.	3	1.5
a novel deep learning architecture for sentiment classification	evolution of plethora of ecommerce sites resulted in fierce competition among their providers. in order to acquire new and retain existing customers, various producers and market managers effectively employ online feedback analytics tools. most of the online feedback analysis tools are built using sentiment analysis models. sentiment analysis evolved in the last one and half decades for review mining process. an important subtask of sentiment analysis called sentiment classification is used mainly to decide whether a written review is expressing either positive or negative sentiment towards a target entity. in order to have better sentiment classification accuracy, we proposed a hybrid deep learning architecture, which is a hybrid of a two layered restricted boltzmann machine and a probabilistic neural network. the proposed approach yielded better accuracy for five different datasets compared to the stateoftheart.	3	1.5
domain-specific sentiment classification via fusing sentiment knowledge from multiple sources	analyzing the sentiments in massive usergenerated online data, such as product reviews and microblogs, has become a hot research topic. it can help customers, companies and expert systems make more informed decisions. sentiment analysis is widely known as a domain dependent problem. different domains usually have different sentiment expressions and a general sentiment classifier is not suitable for all domains. a natural solution to this problem is to train a domainspecific sentiment classifier for each target domain. however, the labeled data in target domain is usually insufficient, and it is costly and timeconsuming to annotate enough samples. in order to tackle this problem, we propose a novel approach to train domainspecific sentiment classifiers by fusing the sentiment knowledge from multiple sources. sentiment information from four sources is extracted and fused in our approach. the first source is sentiment lexicons, which contain sentiment polarities of general sentiment words. the second source is the sentiment classifiers of multiple source domains. the third source is the unlabeled data in target domain, from which we extract domainspecific sentiment relations among words. the fourth source is the labeled data in target domain. we propose a unified framework to fuse these four kinds of sentiment knowledge and train domainspecific sentiment classifier for target domain.	4	3.0
slangsd: building and using a sentiment dictionary of slang words for short-text sentiment classification	sentiment in social media is increasingly considered as an important resource for customer segmentation, market understanding, and tackling other socioeconomic issues. however, sentiment in social media is difficult to measure since usergenerated content is usually short and informal. although many traditional sentiment analysis methods have been proposed, identifying slang sentiment words remains untackled. one of the reasons is that slang sentiment words are not available in existing dictionaries or sentiment lexicons. to this end, we propose to build the first sentiment dictionary of slang words to aid sentiment analysis of social media content. it is laborious and timeconsuming to collect and label the sentiment polarity of a comprehensive list of slang words. we present an approach to leverage web resources to construct an extensive slang sentiment word dictionary (slangsd) that is easy to maintain and extend. slangsd is publicly available for research purposes. we empirically show the advantages of using slangsd, the newlybuilt slang sentiment word dictionary for sentiment classification, and provide examples demonstrating its ease of use with an existing sentiment system.	3	1.5
a comparative study of feature selection and machine learning algorithms for arabic sentiment classification	sentiment analysis is a very challenging and important task that involves natural language processing, web mining, and machine learning. sentiment analysis in the arabic language is a more challenging.	1	1.0
sentiment classification based on as-lda model	we address the task of sentiment classification  identification of the polarity of the subjective document in this paper. we introduces a sentiment classification method called as lda. in this model, we assume that words in subjective documents consists of two parts sentiment element words and auxiliary words which are sampled accordingly from sentiment topics and auxiliary topics. sentiment element words include targets of the opinions, polarity words and modifiers of polarity words. experimental results demonstrate that our approach outperforms latent dirichlet allocation (lda).	1	1.0
sentiment classification based on lda using smo classifier	opinion mining is also known as sentiment analysis which refers to the use of natural language processing, text analysis and computational linguistics to identify and extract the subjective information. a commonly adopted framework generates structured review summaries with aspects and opinions. recently topic models have been used to identify the meaningful review aspects, topic modeling is a form of text mining, a way of identifying patterns in a corpus. . in the proposed system, latent dirichlet allocation (lda) model is introduced to discover both the aspects and aspect specific opinion words. support vector machine (svm) and sequential minimal optimization (smo) classifier is used to classify the topics preferable to each and every document.	2	1.0
twitter sentiment classification using machine learning techniques for stock markets	sentiment classification of twitter data has been successfully applied in finding predictions in a variety of domains. however, using sentiment classification to predict stock market variables is still challenging and ongoing research. the main objective of this study is to compare the overall accuracy of two machine learning techniques (logistic regression and neural network) with respect to providing a positive, negative and neutral sentiment for stockrelated tweets. both classifiers are compared using bigram term frequency (tf) and unigram term frequency  inverse document term frequency (tfidf) weighting schemes. classifiers are trained using a dataset that contains 42,000 automatically annotated tweets. the training dataset forms positive, negative and neutral tweets covering four technologyrelated stocks (twitter, google, facebook, and tesla) collected using twitter search api. classifiers give the same results in terms of overall accuracy (58%). however, empirical experiments show that using unigram tfidf outperforms tf.	2	1.0
a survey of sentiment classification techniques used for indian regional languages	sentiment analysis is a natural language processing task that extracts sentiment from various text forms and classifies them according to positive, negative or neutral polarity. it analyzes emotions, feelings, and the attitude of a speaker or a writer towards a context. this paper gives comparative study of various sentiment classification techniques and also discusses in detail two main categories of sentiment classification techniques these are machine based and lexicon based. the paper also presents challenges associated with sentiment analysis along with lexical resources available.	2	1.0
aspect-level cross-lingual sentiment classification with constrained smt	most crosslingual sentiment classifica tion (clsc) research so far has been per formed at sentence or document level. aspectlevel clsc, which is more appro priate for many applications, presents the additional difficulty that we consider sub sentential opinionated units which have to be mapped across languages. in this pa per, we extend the possible crosslingual sentiment analysis settings to aspectlevel specific use cases. we propose a method, based on constrained smt, to transfer opinionated units across languages by pre serving their boundaries. we show that crosslanguage sentiment classifiers built with this method achieve comparable re sults to monolingual ones, and we com pare different crosslingual settings.	2	1.0
diegolab: an approach for message-level sentiment classification in twitter	we present our supervised sentiment classifi cation system which competed in semeval 2015 task 10b sentiment classification in twitter message polarity classification. our system employs a support vector ma chine classifier trained using a number of fea tures including ngrams, dependency parses, synset expansions, word prior polarities, and embedding clusters. using weighted sup port vector machines, to address the issue of class imbalance, our system obtains positive class fscores of 0.701 and 0.656, and nega tive class fscores of 0.515 and 0.478 over the training and test sets, respectively.	2	1.0
jeam: a novel model for cross-domain sentiment classification based on emotion analysis	crossdomain sentiment classification (csc) aims at learning a sentiment classifier for unlabeled data in the target domain based on the labeled data from a different source domain. due to the differences of data distribution of two domains in terms of the raw features, the csc problem is difficult and challenging. previous researches mainly focused on concepts mining by clustering words across data domains, which ignored the importance of authors’ emotion contained in data, or the different representations of the emotion between domains. in this paper, we propose a novel framework to solve the csc problem, by modelling the emotion across domains. we first develop a probabilistic model named jeam to model author’s emotion state when writing. then, an em algorithm is introduced to solve the likelihood maximum problem and to obtain the latent emotion distribution of the author. finally, a supervised learning method is utilized to assign the sentiment polarity to a given online review. experiments show that our approach is effective and outperforms stateoftheart approaches.	2	1.0
a subspace learning framework for cross-lingual sentiment classification with partial parallel data	crosslingual sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of data in a labelscarce target language by exploiting labeled data from a labelrich language. the fundamental challenge of crosslingual learning stems from a lack of overlap between the feature spaces of the source language data and that of the target language data. to address this challenge, previous work in the literature mainly relies on the large amount of bilingual parallel corpora to bridge the language gap. in many real applications, however, it is often the case that we have some partial parallel data but it is an expensive and timeconsuming job to acquire large amount of parallel data on different languages. in this paper, we propose a novel subspace learning framework by leveraging the partial parallel data for crosslingual sentiment classification. the proposed approach is achieved by jointly learning the documentaligned review data and unaligned data from the source language and the target language via a nonnegative matrix factorization framework. we conduct a set of experiments with crosslingual sentiment classification tasks on multilingual amazon product reviews. our experimental results demonstrate the efficacy of the proposed crosslingual approach.	2	1.0
learning document embeddings by predicting n-grams for sentiment classification of long movie reviews	bagofngram based methods still achieve stateoftheart results for tasks such as sentiment classification of long movie reviews, despite semantic information is partially lost for these methods. many document embeddings methods have been proposed to capture semantics, but they still can't outperform bagofngram based methods on this task. in this paper, we modify the architecture of the recently proposed paragraph vector, allowing it to learn document vectors by predicting not only words, but ngram features as well. our model is able to capture both semantics and word order in documents while keeping the expressive power of learned vectors. experimental results on imdb movie review dataset shows that our model outperforms previous deep learning models and bagofngram based models due to the above advantages. more robust results are also obtained when our model is combined with other models. the source code of our model will be also published together with this paper.	2	1.0
harnessing consumer reviews for marketing intelligence: a domain-adapted sentiment classification approach	with the success and proliferation of web 2.0 applications, consumers can use the internet for shopping, comparing products, and publishing product reviews on various social media sites. such consumer reviews are valuable assets in applications supporting marketing intelligence. however, the rapidly increasing number of consumer reviews makes it difficult for businesses or consumers to obtain a comprehensive view of consumer opinions pertaining to a product of interest when manual analysis techniques are used. thus, developing data analysis tools that can automatically analyze consumer reviews to summarize consumer sentiments is both desirable and essential. accordingly, this study was focused on the sentiment classification of consumer reviews. to address the domaindependency problem typically encountered in sentiment classification and other sentiment analysis applications, we propose a domainadapted sentimentclassification (dasc) technique for inducing a domainindependent base classifier and using a cotraining mechanism to adapt the base classifier to a specific application domain of interest. our empirical evaluation results show that the performance of the proposed dasc technique is superior or comparable to similar techniques for classifying consumer reviews into appropriate sentiment categories.	2	1.0
online and semi-online sentiment classification	with the advent of social media and ecommerce sites, people are posting their unilateral, possibly subjective views on different products and services. sentiment classification is the process of determining whether a given text is expressing positive or negative sentiment towards an entity (product or service) or its attributes. in this regard, we employed text mining involving steps like text preprocessing, feature extraction and selection and finally classification by machine learning algorithms to classify the customers' reviews on four mobile phone brands. the trio of tfidf, chisquare based feature selection and recurrent (jordan/elman)neural network classifier outperformed all other alternatives. the proposed combination yielded 19.13% higher accuracy compared to that of svm, which is reported as the best classifier for sentiment classification in several studies. it also outperformed two semionline classifiers proposed by us here.	2	1.0
multi-dimensional sentiment classification in online learning environment	textbased sentiment analysis as a tool for monitoring online learning environment has elicited increasing interesting and been widely used in practice. correctly identifying author sentiment in a stream of text presents a number of challenges including accurate language parsing, differing perspectives between author and reader, and the general difficulty in accurately classifying natural language semantics. this paper documents the development and initial results of a unique multidimensional sentiment analysis agent for online learning environment, in order to provide overall student feedback on a number of different levels as well as identify potential problems during the delivery of the course. this sentiment analysis agent monitors student interaction in the messaging, discussion and collaboration tools found in the moodle learning environment, and classifies textual data into one of six dimensions positive, negative, neutral, insightful, angry, and joke. ultimately we see this work being especially useful to larger digital learning environments  especially massive open online courses (moocs)  where instructors and administrators are unable to read every individual forum or discussion item, but require a way to identify significant changes in tone and sentiment in order to quickly address potential students or user issues.	2	1.0
cross-domain sentiment classification-feature divergence, polarity divergence or both?	sentiment classification, which aims to predict the polarity of users鈥 viewpoint hidden in reviews, is a domainspecific problem, it often fails to be tested in one domain as a classifier trained from another domain. it is hence significant and challenging for crossdomain sentiment classification due to the following two cases (1) the same feature is used to express different sentiments in different domains (we call itpolarity divergence), and (2) different features are used to express similar sentiments in different domains (we call itfeature divergence). existing efforts focus on the latter and consider little on the former. in this paper, we consider both cases in crossdomain sentiment classification and propose a novel algorithm by transferring the polarity of features (tpf). since the polarity of features is informative for sentiment classification, our algorithm transfers the polarity of features from the source domain to the target domain with the independent features as the bridge. it is worth to note that the polarities of independent features are reset when they are involved in the former case. in addition, the resetting of independent features鈥 polarities in our algorithm can also be used as a preprocessing step in existing efforts. empirical results show that our proposed method outperforms stateoftheart methods in crossdomain sentiment classification.	2	1.0
word sense disambiguation based sentiment lexicons for sentiment classification	sentiment analysis has attracted much attention from both researchers and practitioners as wordofmouth (wom) has a significant influence on consumer behavior. one core task of sentiment analysis is the discovery of sentimental words. this can be done efficiently when an accurate and largescale sentiment lexicon is used. sentiwordnet is one such lexicon which defines each synonym set within wordnet with sentiment scores and orientation. as human language is ambiguous, an exact sense for a word in sentiwordnet needs to be justified according to the context in which the word occurs. however, most sentimentbased classification tasks extract sentimental words from sentiwordnet without dealing with word sense disambiguation (wsd), but directly adopt the sentiment score of the first sense or average sense. this paper proposes three wsd techniques based on the context of wom documents to build wsdbased sentiwordnet lexicons. the experiments demonstrate that an improvement is achieved when the proposed wsdbased sentiwordnet is used.	3	1.0
boost phrase-level polarity labelling with review-level sentiment classification	sentiment analysis on user reviews helps to keep track of user reactions towards products, and make advices to users about what to buy. stateoftheart reviewlevel sentiment classification techniques could give pretty good precisions of above 90%. however, current phraselevel sentiment analysis approaches might only give sentiment polarity labelling precisions of around 70%~80%, which is far from satisfaction and restricts its application in many practical tasks. in this paper, we focus on the problem of phraselevel sentiment polarity labelling and attempt to bridge the gap between phraselevel and reviewlevel sentiment analysis. we investigate the inconsistency between the numerical star ratings and the sentiment orientation of textual user reviews. although they have long been treated as identical, which serves as a basic assumption in previous work, we find that this assumption is not necessarily true. we further propose to leverage the results of reviewlevel sentiment classification to boost the performance of phraselevel polarity labelling using a novel constrained convex optimization framework. besides, the framework is capable of integrating various kinds of information sources and heuristics, while giving the global optimal solution due to its convexity. experimental results on both english and chinese reviews show that our framework achieves high labelling precisions of up to 89%.	2	1.0
cached long short-term memory neural networks for document-level sentiment classification	reacttext 384 the objective of knowledge graph embedding is to encode both entities and relations of knowledge graphs into continuous lowdimensional vector spaces. previously, most works focused on symbolic representation of knowledge graph with structure information, which can not handle new entities or entities with few facts well. in this paper, we propose a novel deep architecture to utilize both...  /reacttext  reacttext 385   /reacttext [show full ]	3	1.0
harnessing consumer reviews for marketing intelligence: a domain-adapted sentiment classification approach	with the success and proliferation of web 2.0 applications, consumers can use the internet for shopping, comparing products, and publishing product reviews on various social media sites. such consumer reviews are valuable assets in applications supporting marketing intelligence. however, the rapidly increasing number of consumer reviews makes it difficult for businesses or consumers to obtain a comprehensive view of consumer opinions pertaining to a product of interest when manual analysis techniques are used. thus, developing data analysis tools that can automatically analyze consumer reviews to summarize consumer sentiments is both desirable and essential. accordingly, this study was focused on the sentiment classification of consumer reviews. to address the domaindependency problem typically encountered in sentiment classification and other sentiment analysis applications, we propose a domainadapted sentimentclassification (dasc) technique for inducing a domainindependent base classifier and using a cotraining mechanism to adapt the base classifier to a specific application domain of interest. our empirical evaluation results show that the performance of the proposed dasc technique is superior or comparable to similar techniques for classifying consumer reviews into appropriate sentiment categories.	2	1.0
twitter sentiment classification using naive bayes based on trainer perception	this paper presents strategy to classify tweets sentiment using naive bayes techniques based on trainers' perception into three categories; positive, negative or neutral. 50 tweets of `malaysia' and `maybank' keywords were selected from twitter for perception training. in this study, there were 27 trainers participated. each trainer was asked to classify the sentiment of 25 tweets of each keyword. results from the classification training was then be used as the input for naive bayes training for the remaining 25 tweets. the trainers were then asked to validate the results of sentiment classification by the naive bayes technique. the accuracy of this study is 90% 卤 14% measured by total number of correct per total classified tweets.	3	1.0
convolutional neural networks for sentiment classification and quantification	reacttext 152 humans continuously adapt their style and language to a variety of domains. however, a reliable definition of `domain' has eluded researchers thus far. additionally, the notion of discrete domains stands in contrast to the multiplicity of heterogeneous domains that humans navigate, many of which overlap. in order to better understand the change and variation of human language, we draw on...  /reacttext  reacttext 153   /reacttext [show full ]	3	1.0
attention-based lstm network for cross-lingual sentiment classification	most of the stateoftheart sentiment classifi cation methods are based on supervised learn ing algorithms which require large amounts of manually labeled data. however, the labeled resources are usually imbalanced in different languages. crosslingual sentiment classification tackles the problem by adapting the sentiment resources in a resourcerich language to resourcepoor languages. in this study, we propose an attentionbased bilingual representation learning model which learns the distributed semantics of the documents in both the source and the target languages. in each language, we use long short term mem ory (lstm) network to model the documents, which has been proved to be very effective for word sequences. meanwhile, we propose a hierarchical attention mechanism for the bilingual lstm network. the sentencelevel attention model learns which sentences of a document are more important for determining the overall sentiment while the wordlevel attention model learns which words in each sentence are decisive. the proposed model achieves good results on a benchmark dataset using english as the source language and chinese as the target language.	3	1.0
deep belief networks with feature selection for sentiment classification	due to the complexity of human languages, most of sentiment classification algorithms are suffered from a hugescale dimension of vocabularies which are mostly noisy and redundant. deep belief networks (dbn) tackle this problem by learning useful information in input corpus with their several hidden layers. unfortunately, dbn is a timeconsuming and computationally expensive process for largescale applications. in this paper, a semisupervised learning algorithm, called deep belief networks with feature selection (dbnfs) is developed. using our chisquared based feature selection, the complexity of the vocabulary input is decreased since some irrelevant features are filtered which makes the learning phase of dbn more efficient. the experimental results of our proposed dbnfs shows that the proposed dbnfs can achieve higher classification accuracy and can speed up training time compared with others wellknown semisupervised learning algorithms.	4	2.0
cufe at semeval-2016 task 4: a gated recurrent model for sentiment classification	in this paper we describe a deep learning system that has been built for semeval 2016 task4 (subtask a and b). in this work we trained a gated recurrent unit (gru) neural network model on top of two sets of word embeddings (a) general word embeddings generated from unsupervised neural language model; and (b) task specific word embeddings generated from supervised neural language model that was trained to classify tweets into positive and negative categories. we also added a method for analyzing and splitting multiwords hashtags and appending them to the tweet body before feeding it to our model. our models achieved 0.58 f1measure for subtask a (ranked 12/34) and 0.679 recall for subtask b (ranked 12/19).	3	1.0
stem at semeval-2016 task 4: applying active learning to improve sentiment classification	this paper describes our approach to the semeval 2016 task 4, “sentiment analysis in twitter”, where we participated in subtask a. our system relies on alchemyapi and sentiwordnet to create 43 features based on which we select a feature subset as final representation. active learning then filters out noisy tweets from the provided training set, leaving a smaller set of only 900 tweets which we use for training a multinomial naive bayes classifier to predict the labels of the test set with an f1 score of 0.478.	3	1.0
unlocking super bowl insights: weighted word embeddings for twitter sentiment classification	sentiment classification plays an important role in sentiment analysis. it is challenging to develop an automatic method for classification problems without annotated training data. in this paper, we present a wwe (weighted word embeddings) method, which uses a continuous word representations algorithm (word2vec) to train a vector model. according to the cosine similarity between the vector of a word and the vectors of seed words, a polarity score of this word can be calculated. we then use the weighted polarity scores of words to compute a polarity score of the whole tweet. unlike the previous learningbased approaches, our method does not require annotated data gathered for the purpose of training models. we collected the super bowl 50 related tweets to demonstrate the wwe classification method. experiments are performed with promising outcomes.	3	1.0
leveraging latent sentiment constraint in probabilistic matrix factorization for cross-domain sentiment classification ☆	sentiment analysis is concerned with classifying a subjective text into positive or negative according to the opinion expressed in it. the performance of traditional sentiment classification algorithms rely heavily on manually labeled training data. however, not every domain has the labeled data because the labeling work is timeconsuming and expensive. in this paper, we propose a latent sentiment factorization (lsf) algorithm based on probabilistic matrix factorization technique for crossdomain sentiment classification. lsf works in the setting where there are only labeled data in the source domain and unlabeled data in the target domain. it bridges the gap between domains by exploiting the sentiment correlations between domainshared and domainspecific words in a twodimensional sentiment space. experimental results demonstrate the superiority of our method over the stateoftheart approaches.	3	1.0
sentiment classification using comprehensive attention recurrent models	sentiment classification has been a very hot topic in the field of natural language processing (nlp) and understanding in recent years. recurrent neural networks (rnn) is a widely used tool to deal with the classification problem of variablelength sentences. the standard rnn can only access the preceding context of a sentence. in this paper, a new architecture termed comprehensive attention recurrent neural networks (carnn) which can store preceding, succeeding and local contexts of any position in a sequence is developed. the bidirectional recurrent neural networks (brnn) is used to access the past and future information while a convolutional layer is employed to capture local information. the standard rnn is also replaced by two recently emerged rnn variants, namely long shortterm memory (lstm) and gated recurrent unit (gru), to enhance the effectiveness of the new architecture. another salient feature of the proposed model is that it can be trained endtoend without any human intervention. it is very easy to be implemented. we conduct experiments on several sentimentlabeled datasets and analysis tasks. experiment results demonstrate that capturing comprehensive contextual information can significantly enhance the classification accuracy compared with the standard recurrent models and the new models can achieve competitive performance compared with the stateoftheart approaches.	3	1.0
cross-lingual sentiment classification with stacked autoencoders	crosslingual sentiment classification is a popular research topic in natural language processing. the fundamental challenge of crosslingual learning stems from a lack of overlap between the feature.	3	1.0
text topic mining based on sentiment classification	there exist a great number of comments about ecommerce on the internet that contains personal emotions,which not only reflect product customer satisfaction,but also the market trends.with the thematic terms contained in these comments,this paper proposes an approach of combining text classification and thematic terms mining,which first classify the sentiment words by using support vector machines,then extract thematic terms from the comments dealed by lda model.the test results with realworld datasets indicate the proposed approach of this paper is with great effectiveness that can better classify the text and dig out the thematic terms more accurately.	3	1.0
efficient twitter sentiment classification using subjective distant supervision	as microblogging services like twitter are becoming more and more influential in today's globalized world, its facets like sentiment analysis are being extensively studied. we are no longer constrained by our own opinion. others' opinions and sentiments play a huge role in shaping our perspective. in this paper, we build on previous works on twitter sentiment analysis using distant supervision. the existing approach requires huge computation resource for analyzing large number of tweets. in this paper, we propose techniques to speed up the computation process for sentiment analysis. we use tweet subjectivity to select the right training samples. we also introduce the concept of efws (effective word score) of a tweet that is derived from polarity scores of frequently used words, which is an additional heuristic that can be used to speed up the sentiment classification with standard machine learning algorithms. we performed our experiments using 1.6 million tweets. experimental evaluations show that our proposed technique is more efficient and has higher accuracy compared to previously proposed methods. we achieve overall accuracies of around 80% (efws heuristic gives an accuracy around 85%) on a training dataset of 100k tweets, which is half the size of the dataset used for the baseline model.	4	2.0
linguistically regularized lstms for sentiment classification	sentiment understanding has been a longterm goal of ai in the past decades. this paper deals with sentencelevel sentiment classification. though a variety of neural network models have been proposed very recently, however, previous models either depend on expensive phraselevel annotation, whose performance drops substantially when trained with only sentencelevel annotation; or do not fully employ linguistic resources (e.g., sentiment lexicons, negation words, intensity words), thus not being able to produce linguistically coherent representations. in this paper, we propose simple models trained with sentencelevel annotation, but also attempt to generating linguistically coherent representations by employing regularizers that model the linguistic role of sentiment lexicons, negation words, and intensity words. results show that our models are effective to capture the sentiment shifting effect of sentiment, negation, and intensity words, while still obtain competitive results without sacrificing the models' simplicity.	4	2.0
sentiment classification by a hybrid method of greedy search and multinomial naïve bayes algorithm	in this paper, we proposed sentiment classification framework focusing on the hybrid method of greedy and multinomial naive bayes algorithm. we found greedy search feature selection most effective in our experiments with multinomial naive bayes algorithm. we also discovered that the multinomial naive bayes is suitable for combination with the greedy method. the hybrid method of greedy and multinomial naive bayes algorithm yielded the best performance with the accuracy over all traditional algorithms. based on our experiments, the multinomial naive bayes algorithm with the greedy search feature selection yielded the best performance with the accuracy of 85.00 %. our experimental results also reveal that hybrid methods have a positive effect on sentiment classification framework.	1	0.75
senti.ue: tweet overall sentiment classification approach for semeval-2014 task 9	this document describes the senti.ue system and how it was used for partici pation in semeval2014 task 9 challenge. our system is an evolution of our prior work, also used in last year edition of sentiment analysis in twitter. this sys tem maintains a supervised machine learn ing approach to classify the tweet overall sentiment, but with a change in the used features and the algorithm. we use a re stricted set of 47 features in subtask b and 31 features in subtask a. in the constrained mode, and for the five data sources, senti.ue achieved a score between 78,72 and 84,05 in subtask a, and a score between 55,31 and 71,39 in sub task b. for the unconstrained mode, our score was slightly below, except for one case in subtask a.	1	0.75
persentiment: a personalized sentiment classification system for microblog users	microblogging services are playing increasingly important roles in our daily life today. it is useful for microblog users to instantly understand the sentiment of a large number of microblogs posted by their friends and make appropriate response. despite considerable progress on microblog sentiment classification, most of the existing works ignore the influence of personal distinctions of different microblog users on the sentiments they convey, and none of them has provided realworld personalized sentiment classification systems. considering personal distinctions in sentiment analysis is natural and necessary as different people have different language habits, personal characters, opinion bias and so on. in this demonstration, we present a live system based on twitter called persentiment, an individualitydependent sentiment classification system which makes the first attempt to analyze the personalized sentiment of recent tweets and retweets posted by the authenticated user and the users he/she follows. our system consists of four steps, i.e., requesting tweets via twitter api, preprocessing collected tweets for extracting features, building personalized sentiment classifier based on a novel and extensible latent factor model (lfm) trained on emoticontagged tweets, and finally visualizing the sentiment of friends鈥 tweets to provide a guide for better sentiment understanding.	3	1.0
sentiment classification at the time of the tunisian uprising: machine learning techniques applied to a new corpus for arabic language	sentiment analysis is the field of study that analyzes people's opinions, sentiments, attitudes, and emotions from written language. it is one of the most active research areas in natural language processing and is also widely studied in data mining, web mining, and text mining. in recent years, text mining and sentiment analysis are being in almost every business and social domain which study all human activities and key influencers of our behaviors. even though there are, at present, several studies related to this theme, most of them focus mainly on english texts. the resources available for opinion mining in other languages, such as arabic, are still limited. in this paper, we propose a new sentiment analysis system destined to classify users' opinions which is performed with a new corpus for arabic language gathered from users' posts at the time of the tunisian revolution. furthermore, different experiments have been carried out on this corpus, using machine learning algorithms such as support vector machines and nai虉ve bayes.	1	0.75
insight-1 at semeval-2016 task 4: convolutional neural networks for sentiment classification and quantification	this paper describes our deep learningbased approach to sentiment analysis in twitter as part of semeval2016 task 4. we use a convolutional neural network to determine sentiment and participate in all subtasks, i.e. twopoint, threepoint, and fivepoint scale sentiment classification and twopoint and fivepoint scale sentiment quantification. we achieve competitive results for twopoint scale sentiment classification and quantification, ranking fifth and a close fourth (third and second by alternative metrics) respectively despite using only pretrained embeddings that contain no sentiment information. we achieve good performance on threepoint scale sentiment classification, ranking eighth out of 35, while performing poorly on fivepoint scale sentiment classification and quantification. an error analysis reveals that this is due to low expressiveness of the model to capture negative sentiment as well as an inability to take into account ordinal information. we propose improvements in order to address these and other issues.	3	1.0
sentiment classification analysis of chinese microblog network	in recent years, more and more people begin to publish information on online social platforms like sina weibo. via the facilities like posting tweets, retweeting tweets and making comments provided by weibo service, users can easily express their feelings, giving opinions and make interactions with their friends in real time. sentiment analysis of weibo messages is important for the analysis of human sentiment. the characteristics of chinese microblogs bring difficulty in sentiment classification. in this paper, an effective chinese microblogs sentiment classification model based on naive bayes is proposed. two strategies to do the three sentiment polarities classification are compared and the twostep strategy performs better than the onestep strategy.	2	0.6666666666666666
lexicon based approach for sentiment classification of user reviews	with the advent of web, online user reviews are getting more and more attention of the researchers because valuable information about products and services are available on social media like twitter1. these reviews are very helpful for organizations as well as for new customers showing interest in these products or services. but this data is generated in tremendous amount which is out of control of manual mining methods. these reviews need a model that has the ability to gauge these shared reviews according to predefined categories. this work introduces a rule based approach to find the opinion classification of reviews. the system can automatically crawl reviews from social media sites, classify these reviews as subjective and objective and then calculate polarity score for subjective reviews at word level. this method shows impressive results and outperforms the baseline method by achieving 86% and 82% accuracy at feedback and sentence level respectively for comments and 96% at feedback and 85 % at sentences for reviews.	1	0.5
research of unbalance sentiment classification based on denoising autoencoders	currently,the network comments sentiment classification studies usually use unbalanced sample data in which the number of positive samples generally much larger than the negative sample. that imbalance sample classification is prone to minority class large error. in addition the network comments expression varied,it is difficult to get a large number of supervised data. in order to solver these problems,the web reviews imbalance unsupervised sentiment classification is studied. first,through improving the denoising autoencoders,minority class characteristic value is increased to avoid the majority class classification sample deviation. then the eigenvalues is put in kmeans algorithm as input values to achieve unsupervised classification. experimental results show that the algorithm has a good adaptability for higher imbalance sample data,and verify the effectiveness of the algorithm.	1	0.5
sentrep: sentiment classification of movie reviews using efficient repetitive pre-processing	opinions are highly essential for decision making and popular among the internet users. people with malicious intentions tend to give fake reviews to encourage or degrade the products. reviewing movies is gaining popularity among web users, at the same time cannot be trusted. in this work, we propose a model sentiment classification of movie reviews using efficient repetitive preprocessing (sentrep) that is based on tested parameters and a focused preprocessing technique to classify opinions. working on the cornell movie review data set, this work significantly proves the accuracy and effectiveness of sentrep across different volumes of data and when compared to other different prevailing approaches. overall this approach is very efficient in analyzing sentiments of movie reviews.	1	0.5
semantic weight-based naive bayesian algorithm for text sentiment classification	summary to solve the drawback that the precision of the documentlevel sentiment classification is lower than that of the normal text classification, this paper proposes a semantic weightbased naive bayesian algorithm for text sentiment classification. first, the words in an emotion dictionary are scored and weighted by using a feature selection method. second, based on the correlation between the distribution of dictionary polar and the documentlevel sentiment classification, the semantic weight feature is merged into naive bayesian classification and a new algorithm is achieved. finally, lots of experiments on some standard chinese data sets are performed. results show that this algorithm is better than some existing algorithms on precision, recall, and $f_1$measure.	1	0.5
pre-processing online financial text for sentiment classification: a natural language processing approach	online financial textual information contains a large amount of investor sentiment, i.e. subjective assessment and discussion with respect to financial instruments. an effective solution to automate the sentiment analysis of such large amounts of online financial texts would be extremely beneficial. this paper presents a natural language processing (nlp) based preprocessing approach both for noise removal from raw online financial texts and for organizing such texts into an enhanced format that is more usable for feature extraction. the proposed approach integrates six nlp processing steps, including a developed syntactic and semantic combined negation handling algorithm, to reduce noise in the online informal text. threeclass sentiment classification is also introduced in each system implementation. experimental results show that the proposed preprocessing approach outperforms other preprocessing methods. the combined negation handling algorithm is also evaluated against three standard negation handling approaches.	1	0.5
a comparison of the effect of feature selection and balancing strategies upon the sentiment classification of portuguese news stories	sentiment classification of news stories using super vised learning is a mature task in the field of natural language processing. supervised learning strategies rely upon training data to induce a classifier. training data can be imbalanced, with typically the neutral class being the majority class. this imbalance can bias the induced classifier towards the majority class. balanc ing and feature selection can mitigate the effects of imbalanced data. this paper surveys a number of common balancing and feature selections techniques, and applies them to an imbalanced data set of manually labelled brazilian agricultural news stories. the strategies were appraised with a 9010 holdout evaluation and compared with a baseline strategy. we found that 1. the feature selection strategies provided no identifiable advantage over a baseline method and 2. balancing produced an advantage over baseline with random oversampling producing the best results.	1	0.5
sentiment lexicon interpolation and polarity estimation of objective and out-of-vocabulary words to improve sentiment classification on microblogging	sentiment analysis has become an important classification task because a large amount of usergenerated content is published over the internet. sentiment lexicons have been used successfully to classify the sentiment of user review datasets. more recently, microblog ging services such as twitter have become a popular data source in the domain of senti ment analysis. however, analyzing sentiments on tweets is still difficult because tweets are very short and contain slang, informal expres sions, emoticons, mistyping and many words not found in a dictionary. in addition, more than 90 percent of the words in public senti ment lexicons, such as sentiwordnet, are ob jective words, which are often considered less important in a classification module. in this paper, we introduce a hybrid approach that in corporates sentiment lexicons into a machine learning approach to improve sentiment clas sification in tweets. we automatically con struct an addon lexicon that compiles the po larity scores of objective words and outof vocabulary (oov) words from tweet corpora. we also introduce a novel feature weight ing method by interpolating sentiment lexi con score into unigram vectors in the support vector machine (svm).	1	1.0
sentiment classification of unstructured data using lexical based techniques	sentiment analysis is the computational study of people鈥檚 opinion or feedback, attitudes, and emotions toward entities, individuals, issues, events, topics and their attributes. there are many research conducted for other languages such as english, spanish, french, and german. however, lack of research is conducted to harvest the information in malay words and structure them into a meaningful data. the objective of this paper is to introduce a lexical based method in analysing sentiment of facebook comments in malay. three types of lexical based techniques are implemented in order to identify the sentiment of facebook comments. the techniques used are term counting, term score summation and average on comments. the comparison of accuracy, precision and recall for all techniques are computed. the result shows that the average on comments method outperforms the other two techniques.	2	0.6666666666666666
a common subspace construction method in cross-domain sentiment classification	in this paper, we study the problem of domain adaptation in sentiment classification. many existing approaches reduce the gap by extracting domainindependent topics. however these methods couldnt cope with features which have different sentiments in different domains. to solve this problem, a common subspace construction method (csc) is proposed in our paper. firstly, the consistency of features' sentiment orientation in different domains is introduced to identify the common subspace. then, domaindependent features will be projected to this subspace. empirical studies on benchmark tasks of sentiment analysis validate our assumption and demonstrated significant improvement of our method over competing ones in classification accuracies.	2	0.6666666666666666
co-training for semi-supervised sentiment classification based on dual-view bags-of-words representation	a review text is normally represented as a bagofwords (bow) in sentiment classification. such a simplified bow model has fundamental deficiencies in modeling some complex linguistic phenomena such as negation. in this work, we propose a dualview cotraining algorithm based on dualview bow representation for semisupervised sentiment classification. in dualview bow, we automatically construct antonymous reviews and model a review text by a pair of bagsofwords with opposite views. we make use of the original and antonymous views in pairs, in the training, bootstrapping and testing process, all based on a joint observation of two views. the experimental results demonstrate the advantages of our approach, in meeting the two cotraining requirements, addressing the negation problem, and enhancing the semisupervised sentiment classification efficiency.	2	0.6666666666666666
exploiting dependency relations for sentence level sentiment classification using svm	in the sentiment analysis, finding the subjective clues itself is a challenging task. in this work, we propose a new approach, which employs support vector machine (svm) for classification, exploits the dependency relations in a dependency tree coupled with a large lexicon resource obtained from twitter to create a feature vector. the experiment shows a significant improvement over the baseline approaches and results are on par with existing methods in twoclass classification.	2	0.6666666666666666
physiological signals based day-dependence analysis with metric multidimensional scaling for sentiment classification in wearable sensors	the interaction of the affective has emerged in implicit humancomputer interaction. given the physiological signals in the recognition process of the affective, the different positions by which the physiological signal sensors are installed in the body, along with the daily habits and moods of human beings, influence the affective physiological signals. the scalar product matrix was calculated in this study based on metric multidimensional scaling with dissimilarity matrix. subsequently, the matrix of individual attribute reconstructs was obtained using the principal component factor. the method proposed in this study eliminates day dependence, reduces the effect of time in the physiological signals of the affective, and improves the accuracy of affection classification.	2	0.6666666666666666
sentiment classification using principal component analysis based neural network model	the rapid growth of online social media acts as a medium where people contribute their opinion and emotions as text messages. the messages include reviews and opinions on certain topics such as movie, book, product, politics and so on. opinion mining refers to the application of natural language processing, computational linguistics, and text mining to identify or classify whether the opinion expressed in text message is positive or negative. back propagation neural networks is supervised machine learning methods that analyze data and recognize the patterns that are used for classification. this work focuses on binary classification to classify the text sentiment into positive and negative reviews. in this study principal component analysis (pca) is used to extract the principal components, to be used as predictors and back propagation neural network (bpn) have been employed as a classifier. the performance of pca+ bpn and bpn without pca has been compared using receiver operating characteristics (roc) analysis. the classifier is validated using 10fold cross validation. the result shows the effectiveness of bpn with pca used as a feature reduction method for text sentiment classification.	2	0.6666666666666666
entity-specific sentiment classification of yahoo news comments	sentiment classification is widely used for product reviews and in online social media such as forums, twitter, and blogs. however, the problem of classifying the sentiment of user comments on news sites has not been addressed yet. news sites cover a wide range of domains including politics, sports, technology, and entertainment, in contrast to other online social sites such as forums and review sites, which are specific to a particular domain. a user associated with a news site is likely to post comments on diverse topics (e.g., politics, smartphones, and sports) or diverse entities (e.g., obama, iphone, or google). classifying the sentiment of users tied to various entities may help obtain a holistic view of their personality, which could be useful in applications such as online advertising, content personalization, and political campaign planning. in this paper, we formulate the problem of entityspecific sentiment classification of comments posted on news articles in yahoo news and propose novel features that are specific to news comments. experimental results show that our models outperform stateoftheart baselines.	2	0.6666666666666666
a sentiment classification algorithm of chinese comments based on multi features fusion	to solve the problem that semantic relationships between words can not be well analyzed in sentiment classification,a method for sentiment classification based on word2 vec and svm is proposed to carry out the study of sentiment classification of ecommerce online reviews.first of all,we use word2 vec to cluster the similar features.and then,we train and classify the comment texts using word2 vec again and svm.in the process,the lexiconbased and partofspeech based feature selection methods are respectively adopted to generate the training file.we conduct the experiments on the data set of chinese comments of jingdong.the experimental result indicates that the precision and recall of sentiment classification of using word2 vec again and svm are superior to those of using the traditional optimalization method.	2	0.6666666666666666
using stylometric features for sentiment classification	this paper is a comparative study about text feature extraction methods in statistical learning of sentiment classification. feature extraction is one of the most important steps in classification systems. we use stylometry to compare with tfidf and delta tfidf baseline methods in sentiment classification. stylometry is a research area of linguistics that uses statistical techniques to analyze literary style. in order to assess the viability of the stylometry, we create a corpus of product reviews from the most traditional online service in portuguese, namely, buscap茅. we gathered 2000 review about smartphones. we use three classifiers, support vector machine (svm), naive bayes, and j48 to evaluate whether the stylometry has higher accuracy than the tfidf and delta tfidf methods in sentiment classification. we found the better result with the svm classifier (82,75%) of accuracy with stylometry and (72,62%) with delta tfidf and (56,25%) with tfidf. the results show that stylometry is quite feasible method for sentiment classification, outperforming the accuracy of the baseline methods. we may emphasize that approach used has promising results.	2	0.6666666666666666
sentiment classification analysis of chinese microblog network	in recent years, more and more people begin to publish information on online social platforms like sina weibo. via the facilities like posting tweets, retweeting tweets and making comments provided by weibo service, users can easily express their feelings, giving opinions and make interactions with their friends in real time. sentiment analysis of weibo messages is important for the analysis of human sentiment. the characteristics of chinese microblogs bring difficulty in sentiment classification. in this paper, an effective chinese microblogs sentiment classification model based on naive bayes is proposed. two strategies to do the three sentiment polarities classification are compared and the twostep strategy performs better than the onestep strategy.	2	0.6666666666666666
topic-dependent sentiment classification on twitter	in this paper, we investigate how discovering the topic dicussed in a tweet can be used to improve its sentiment classification. in particular, a classifier is introduced consisting of a topicspecific classifier, which is only trained on tweets of the same topic of the given tweet, and a generic classifier, which is trained on all the tweets in the training set. the set of considered topics is obtained by clustering the hashtags that occur in the training set. a classifier is then used to estimate the topic of a previously unseen tweet. experimental results based on a public twitter dataset show that considering topicspecific sentiment classifiers indeed leads to an improvement.	2	0.6666666666666666
sentiment classification analysis of chinese microblog network	in recent years, more and more people begin to publish information on online social platforms like sina weibo. via the facilities like posting tweets, retweeting tweets and making comments provided by weibo service, users can easily express their feelings, giving opinions and make interactions with their friends in real time. sentiment analysis of weibo messages is important for the analysis of human sentiment. the characteristics of chinese microblogs bring difficulty in sentiment classification. in this paper, an effective chinese microblogs sentiment classification model based on naive bayes is proposed. two strategies to do the three sentiment polarities classification are compared and the twostep strategy performs better than the onestep strategy.	2	0.6666666666666666
uyghur text sentiment classification based on discriminative keyword model	this paper presents a classification approach for uyghur text sentiment,such as angry and happy,based on discriminative key word extraction. combined with the characteristics of sentiment expression in uyghur text,the term frequency and document frequency are derived as primary statistics. various discriminative statistics which reflect the discrepancy of the positive and negative sentiment datasets are derived from the primary statistics for each vocabulary word,and are used to extract discriminative key words. features are extracted based on these keywords and are used to train discriminative sentiment models. this paper builds a sentiment text database by excerpting two sentimentsangriness and happiness from uyghur movie transcriptions and novels,and verifies the proposed approach.experimental results show that the method based on discriminative keyword extraction is effective in uyghur text sentence sentiment classification.	1	0.5
lexicon based approach for sentiment classification of user reviews	with the advent of web, online user reviews are getting more and more attention of the researchers because valuable information about products and services are available on social media like twitter1. these reviews are very helpful for organizations as well as for new customers showing interest in these products or services. but this data is generated in tremendous amount which is out of control of manual mining methods. these reviews need a model that has the ability to gauge these shared reviews according to predefined categories. this work introduces a rule based approach to find the opinion classification of reviews. the system can automatically crawl reviews from social media sites, classify these reviews as subjective and objective and then calculate polarity score for subjective reviews at word level. this method shows impressive results and outperforms the baseline method by achieving 86% and 82% accuracy at feedback and sentence level respectively for comments and 96% at feedback and 85 % at sentences for reviews.	1	0.5
research of unbalance sentiment classification based on denoising autoencoders	currently,the network comments sentiment classification studies usually use unbalanced sample data in which the number of positive samples generally much larger than the negative sample. that imbalance sample classification is prone to minority class large error. in addition the network comments expression varied,it is difficult to get a large number of supervised data. in order to solver these problems,the web reviews imbalance unsupervised sentiment classification is studied. first,through improving the denoising autoencoders,minority class characteristic value is increased to avoid the majority class classification sample deviation. then the eigenvalues is put in kmeans algorithm as input values to achieve unsupervised classification. experimental results show that the algorithm has a good adaptability for higher imbalance sample data,and verify the effectiveness of the algorithm.	1	0.5
sentrep: sentiment classification of movie reviews using efficient repetitive pre-processing	opinions are highly essential for decision making and popular among the internet users. people with malicious intentions tend to give fake reviews to encourage or degrade the products. reviewing movies is gaining popularity among web users, at the same time cannot be trusted. in this work, we propose a model sentiment classification of movie reviews using efficient repetitive preprocessing (sentrep) that is based on tested parameters and a focused preprocessing technique to classify opinions. working on the cornell movie review data set, this work significantly proves the accuracy and effectiveness of sentrep across different volumes of data and when compared to other different prevailing approaches. overall this approach is very efficient in analyzing sentiments of movie reviews.	1	0.5
machine learning algorithms for opinion mining and sentiment classification	in this paper we introduce an efficient stochastic method to solve the time evolution of a bivariate population balance equation which has been developed for modelling nanoparticle dynamics. we have adapted the existing stochastic models used in the study of coagulation dynamics to solve a variant of the sinteringcoagulation equation proposed by xiong & pratsinis. hitherto stochastic models based on markov jump processes have not taken into account the surface area evolution. we produce numerical results efficiently with the direct simulation and mass flow algorithms and study the convergence behaviour as the number of stochastic particles increases. we find a marked preference for using the mass flow algorithm to determine the higher order volume and area moments of the particle size distribution function. the computational efficiency of these algorithms is remarkable when compared to the sectional method that has been used previously to study this equation.	1	0.5
semantic weight-based naive bayesian algorithm for text sentiment classification	summary to solve the drawback that the precision of the documentlevel sentiment classification is lower than that of the normal text classification, this paper proposes a semantic weightbased naive bayesian algorithm for text sentiment classification. first, the words in an emotion dictionary are scored and weighted by using a feature selection method. second, based on the correlation between the distribution of dictionary polar and the documentlevel sentiment classification, the semantic weight feature is merged into naive bayesian classification and a new algorithm is achieved. finally, lots of experiments on some standard chinese data sets are performed. results show that this algorithm is better than some existing algorithms on precision, recall, and $f_1$measure.	1	0.5
pre-processing online financial text for sentiment classification: a natural language processing approach	online financial textual information contains a large amount of investor sentiment, i.e. subjective assessment and discussion with respect to financial instruments. an effective solution to automate the sentiment analysis of such large amounts of online financial texts would be extremely beneficial. this paper presents a natural language processing (nlp) based preprocessing approach both for noise removal from raw online financial texts and for organizing such texts into an enhanced format that is more usable for feature extraction. the proposed approach integrates six nlp processing steps, including a developed syntactic and semantic combined negation handling algorithm, to reduce noise in the online informal text. threeclass sentiment classification is also introduced in each system implementation. experimental results show that the proposed preprocessing approach outperforms other preprocessing methods. the combined negation handling algorithm is also evaluated against three standard negation handling approaches.	1	0.5
a comparison of the effect of feature selection and balancing strategies upon the sentiment classification of portuguese news stories	sentiment classification of news stories using super vised learning is a mature task in the field of natural language processing. supervised learning strategies rely upon training data to induce a classifier. training data can be imbalanced, with typically the neutral class being the majority class. this imbalance can bias the induced classifier towards the majority class. balanc ing and feature selection can mitigate the effects of imbalanced data. this paper surveys a number of common balancing and feature selections techniques, and applies them to an imbalanced data set of manually labelled brazilian agricultural news stories. the strategies were appraised with a 9010 holdout evaluation and compared with a baseline strategy. we found that 1. the feature selection strategies provided no identifiable advantage over a baseline method and 2. balancing produced an advantage over baseline with random oversampling producing the best results.	1	0.5
sentiment classification in hindi	traditional approaches for classification of sentiments depend on lexical or syntax based feature or on both. different methods for sentiments classifications are described .the main goal of analysis of the sentiments is to obtain the writer's feelings whether +ve or ve.sentiment analysis is having its importance because in this world of internet the opinion of public is very important.so the need for analysis of sentiment is increasing heavily.keywords corpus, wordnet, sentiments, synset, disambiguation	1	0.5
sentiment classification of news articles	the advent use of new online social media such as articles, blogs, message boards, news channels, and in general web content has dramatically changed the way people look at various things around them. today, it's a daily practice for many people to read news online. people's perspective tends to undergo a change as per the news content they read. the majority of the content that we read today is on the negative aspects of various things e.g. corruption, rapes, thefts etc. reading such news is spreading negativity amongst the people. positive news seems to have gone into a hiding. the positivity surrounding the good news has been drastically reduced by the number of bad news. this has made a great practical use of sentiment analysis and there has been more innovation in this area in recent days. sentiment analysis refers to a broad range of fields of text mining, natural language processing and computational linguistics. it traditionally emphasizes on classification of text document into positive and negative categories. sentiment analysis of any text document has emerged as the most useful application in the area of sentiment analysis. the objective of this project is to provide a platform for serving good news and create a positive environment. this is achieved by finding the sentiments of the news articles and filtering out the negative articles.	1	0.5
sentiment classification of chinese reviews in different domain: a comparative study	with the rapid development of microblog, blog and other types of social media, users’ reviews on the social media increase dramatically. users’ reviews mining plays an important role in the application of product information or public opinion monitoring. sentiment classification of users’ reviews is one of key issues in the review mining. comparative study on sentiment classification results of reviews in different domains and the adaptability of sentiment classification methods is an interesting research topic. this paper classifies users’ reviews in three different domains based on support vector machine with six kinds of feature weighting methods. experiment results in three domains indicate that different domains have their own characteristics and the selection of feature weighting methods should consider the domain characteristics.	1	0.5
semi-supervised sentiment classification with self-training on feature subspaces	in sentiment classification, labeled data is often limited while unlabeled data is ample. this motivates semisupervised learning for sentiment classification to improve the performance by exploring the knowledge in unlabeled data. in this paper, we analyze the possibility and the difficulty of semisupervised sentiment classification and indicate that noisy features may be the main reason for badly influencing the performance. to overcome this problem, we propose a novel selftraining approach where multiple feature subspacebased classifiers are utilized to explore a set of good features for better classification decision and to select the informative samples for automatically labeling. evaluation over multiple data sets shows the effectiveness of our selftraining approach for semisupervised sentiment classification.	1	0.5
artfsc – average relative term frequency sentiment classification	sentiment classification refers to the computational techniques for classifying whether the sentiments of text are positive or negative. statistical techniques based on term presence and term frequency, using support vector machine are popularly used for sentiment classification. this paper presents an approach for classifying a term as positive or negative based on its average frequency in positively tagged documents in comparison with negatively tagged documents. our approach is based on term weighting techniques that are used for information retrieval and sentiment classification. it differs significantly from these traditional methods due to our model of logarithmic differential average term distribution for sentiment classification. terms with emnearly/em equal distribution in positively tagged documents and negatively tagged documents were classified as a sentistopword and discarded. the proportional distribution of a term to be classified as sentistopword was determined experimentally. our model was evaluated by comparing it with state of art techniques for sentiment classification using the movie review dataset.	1	0.5
low-resource cross-domain product review sentiment classification based on a cnn with an auxiliary large-scale corpus	the literature [5]contains several reports evaluating the abilities of deep neural networks in text transfer learning. to our knowledge, however, there have been few efforts to fully realize the potential of deep neural networks in crossdomain product review sentiment classification. in this paper, we propose a twolayer convolutional neural network (cnn) for crossdomain product review sentiment classification (lmcnnlb). transfer learning research into product review sentiment classification based on deep neural networks has been limited by the lack of a largescale corpus; we sought to remedy this problem using a largescale auxiliary crossdomain dataset collected from amazon product reviews. our proposed framework exhibits the dramatic transferability of deep neural networks for crossdomain product review sentiment classification and achieves stateoftheart performance. the framework also outperforms complex engineered features used with a nondeep neural network method. the experiments demonstrate that introducing largescale data from similar domains is an effective way to resolve the lack of training data. the lmcnnlb trained on the multisource related domain dataset outperformed the one trained on a single similar domain.	4	1.0
cross-domain sentiment classification via topic-related tradaboost	crossdomain sentiment classification aims to tag sentiments for a target domain by labeled data from a source domain. due to the difference between domains, the accuracy of a trained classifier may be very low. in this paper, we propose a boostingbased learning framework named trtradaboost for crossdomain sentiment classification. we firstly explore the topic distribution of documents, and then combine it with the unigram tradaboost. the topic distribution captures the domain information of documents, which is valuable for crossdomain sentiment classification. experimental results indicate that trtradaboost represents documents well and boost the performance and robustness of tradaboost.	4	1.0
linguistically regularized lstm for sentiment classification	endowing a chatbot with personality or an identity is quite challenging but critical to deliver more realistic and natural conversations. in this paper, we address the issue of generating responses that are coherent to a prespecified agent profile. we design a model consisting of three modules a profile detector to decide whether a post should be responded using the profile and which key.	4	1.0
from opinion lexicons to sentiment classification of tweets and vice versa: a transfer learning approach	messagelevel and wordlevel polarity classification are two popular tasks in twitter sentiment analysis. they have been commonly addressed by training supervised models from labelled data. the main limitation of these models is the high cost of data annotation. transferring existing labels from a related problem domain is one possible solution for this problem. in this paper, we propose a simple model for transferring sentiment labels from words to tweets and vice versa by representing both tweets and words using feature vectors residing in the same feature space. tweets are represented by standard nlp features such as unigrams and partofspeech tags. words are represented by averaging the vectors of the tweets in which they occur. we evaluate our approach in two transfer learning problems 1) training a tweetlevel polarity classifier from a polarity lexicon, and 2) inducing a polarity lexicon from a collection of polarityannotated tweets. our results show that the proposed approach can successfully classify words and tweets after transfer.	4	1.0
particle swarm optimization-based feature selection in sentiment classification	sentiment classification is one of the important tasks in text mining, which is to classify documents according to their opinion or sentiment. documents in sentiment classification can be represented in the form of feature vectors, which are employed by machine learning algorithms to perform classification. for the feature vectors, the feature selection process is necessary. in this paper, we will propose a feature selection method called fitness proportionate selection binary particle swarm optimization (fbpso). binary particle swarm optimization (bpso) is the binary version of particle swam optimization and can be applied to feature selection domain. fbpso is a modification of bpso and can overcome the problems of traditional bpso including unreasonable update formula of velocity and lack of evaluation on every single feature. then, some detailed changes are made on the original fbpso including using fitness sum instead of average fitness in the fitness proportionate selection step. the modified method is, thus, called fitness sum proportionate selection binary particle swarm optimization (fsbpso). moreover, further modifications are made on the fsbpso method to make it more suitable for sentiment classificationoriented feature selection domain. the modified method is named as scofsbpso where sco stands for 鈥渟entiment classificationoriented.	3	0.5
word embeddings and convolutional neural network for arabic sentiment classification	with the development and the advancement of social networks, forums, blogs and online sales, a growing number of arabs are expressing their opinions on the web. in this paper, a scheme of arabic sentiment classification, which evaluates and detects the sentiment polarity from arabic reviews and arabic social media, is studied. we investigated in several architectures to build a quality neural word embeddings using a 3.4 billion words corpus from a collected 10 billion words webcrawled corpus. moreover, a convolutional neural network trained on top of pre trained arabic word embeddings is used for sentiment classification to evaluate the quality of these word embeddings. the simulation results show that the proposed scheme outperforms the existed methods on 4 out of 5 balanced and unbalanced datasets.	3	0.5
a deep neural architecture for sentence-level sentiment classification in twitter social networking	this paper introduces a novel deep learning framework including a lexiconbased approach for sentencelevel prediction of sentiment label distribution. we propose to first apply semantic rules and then use a deep convolutional neural network (deepcnn) for characterlevel embeddings in order to increase information for wordlevel embedding. after that, a bidirectional long shortterm memory network (bilstm) produces a sentencewide feature representation from the wordlevel embedding. we evaluate our approach on three twitter sentiment classification datasets. experimental results show that our model can improve the classification accuracy of sentencelevel sentiment analysis in twitter social networking.	4	1.0
uofl at semeval-2016 task 4: multi domain word2vec for twitter sentiment classification	in this paper, we present a transfer learning sys tem for twitter sentiment classification and compare its performance using different fea ture sets that include different word represen tation vectors. we utilized data from a different source domain to increase the performance of our system in the target domain. our approach was based on training various word2vec mod els on data from the source and target domains combined, then using these models to calculate the average word vector of all the word vectors in a tweet observation, then input the average word vector as a feature to our classifiers for training. we further developed one doc2vec model that was trained on the positive, nega tive and neutral tweets in the target domain only. we then used these models in calculating the average word vector for every tweet in the training set as a preprocessing step. the final evaluation results show that our approach gave a prediction accuracy on the twitter2016 test dataset that outperformed two teams that were among the top 10 in terms of avgf1 scores.	3	0.5
yzu-nlp team at semeval-2016 task 4: ordinal sentiment classification using a recurrent convolutional network	sentiment analysis of tweets has attracted considerable attention recently for potential use in commercial and public sector applica tions. typical sentiment analysis classifies the sentiment of sentences into several discrete classes (e.g., positive and negative). the aim of task 4 subtask c of semeval2016 is to classify the sentiment of tweets into an ordinal fivepoint scale. in this paper, we present a system that uses word embeddings and recur rent convolutional networks to complete the competition task. the word embeddings pro vide a continuous vector representation of words for the recurrent convolutional network to use in building sentence vectors for multi point classification. the proposed method ranked second among eleven teams in terms of microaveraged mae (mean absolute error) and eighth for macroaveraged mae.	3	0.5
lys at semeval-2016 task 4: exploiting neural activation values for twitter sentiment classification and quantification	in this paper we describe our deep learning approach for solving both two, three and fiveclass tweet polarity classification, and twoand fiveclass quantification. we first trained a convolutional neural network using pretrained twitter word embeddings, so that we could extract the hidden activation values from the hidden layers once some input had been fed to the network. these values were then used as features for a support vector machine in both the classification and quantification subtasks, together with additional linguistic information in the former scenario. the results obtained for the classification subtasks show that this approach performs better than a single convolutional network, and for the quantification part it also yields good results. official rankings locate us 2nd (practically tied with 1st) for the binary classification task, 2nd for binary quantification and 4th (practically tied with 3rd) for the fiveclass polarity classification challenge.	3	0.5
sentiment classification based on domain prediction	sentiment classification has received increasing attention in recent years. supervised learning methods for sentiment classification require considerable amount of labeled data for training purposes. as the number of domains increases, the task of collecting data becomes impractical. therefore, domain adaptation techniques are employed. however, most of the studies dealing with the domain adaptation problem demand a few amount of labeled data or lots of unlabeled data belonging to the target domain, which may not be always possible. in this work, a novel method for sentiment classification, which does not require labeled and/or unlabeled data from the target domain, is proposed. the propose method mainly consists of two stages. at first, the target domain is predicted even if it is not among the source domains in hand. then, sentiment is classified as either positive or negative using the sentiment classifier specifically trained for the predicted domain. extensive experimental analysis on two different datasets with distinct languages and domains verifies that the proposed method is superior to the domain independent sentiment classification approach at each case considered.  doi  http//dx.doi.org/10.5755/j01.eie.22.2.14599	3	0.5
a new method for sentiment classification on weibo	sentiment classification of posts on weibo is a key to analyse people's opinions and attitudes toward prod ucts, services, and social events. it is also at the core of many other natural language processing tasks. in this paper, we apply a new feature representation technique to building a sentiment classifier and classifying the posts. firstly, we crawled a set of posts from weibo and labelled them. then, we cleaned the data to remove the noisy information and transformed the varyinglength posts into fixedsized input vectors based on five different feature engineering tech niques. finally, we evaluated the performances of the five different feature representation techniques on a same data set with the use of support vector machines, naive bayes and classification and regression tree. experimental results demon strate that our new method is efficient and outperforms the other ones.	3	0.5
sentiment classification of consumer-generated online reviews using topic modeling	the development of the internet and mobile devices enabled the emergence of travel and hospitality review sites, leading to a large number of customer opinion posts. while such comments may influence future demand of the targeted hotels, they can also be used by hotel managers to improve customer experience. in this article, sentiment classification of an ecohotel is assessed through a text mining approach using several different sources of customer reviews. the latent dirichlet allocation modeling algorithm is applied to gather relevant topics that characterize a given hospitality issue by a sentiment. several findings were unveiled including that hotel food generates ordinary positive sentiments, while hospitality generates both ordinary and strong positive feelings. such results are valuable for hospitality management, validating the proposed approach.	4	1.0
deep neural network for short-text sentiment classification	as a concise medium to describe events, short text plays an important role to convey the opinions of users. the classification of user emotions based on short text has been a significant topic in social.	3	0.5
study of sentiment classification for chinese microblog based on recurrent neural network	the sentiment classification of chinese microblog is a meaningful topic. many studies has been done based on the methods of rule and wordbag, and to understand the structure information of a sentence will be the next target. we proposed a sentiment classification method based on recurrent neural network (rnn). we adopted the technology of distributed word representation to construct a vector for each word in a sentence;then train sentence vectors with fixed dimension for different length sentences with rnn, so that the sentence vectors contain both word semantic features and word sequence features; at last use softmax regression classifier in the output layer to predict each sentence鈥檚 sentiment orientation. experiment results revealed that our method can understand the structure information of negative sentence and double negative sentence and achieve better accuracy. the way of calculating sentence vector can help to learn the deep structure of sentence and will be valuable for different research area.	3	0.5
a teaching evaluation method based on sentiment classification	teaching evaluation is an important part of the teaching process, and is an effective measure to improve teaching method. in order to automatically analyse the massive teaching evaluation texts on internet, this paper proposes to apply the sentiment classification technology to the sentiment analysis of teaching evaluation texts, and introduces a teaching evaluation analysis method based on the sentiment dictionary. in order to deal with the problem of the frequent appearance of new words in these texts, propose a method to recognize the new words automatically, and then use these recognised words to expand the sentiment dictionary. experimental results show that the sentiment classification based on the expanded sentiment dictionary increases the recall rate of the system successfully, which brings the improvement of the overall performance of the teaching evaluation analysis system.	3	0.5
sting algorithm used english sentiment classification in a parallel environment	sentiment classification is significant in everyday life of everyone, in political activities, activities of commodity production, commercial activities. in this research, we propose a new model for big data sentiment classification in the parallel network environment. our new model uses sting algorithm (sa) (in the data mining field) for english documentlevel sentiment classification with hadoop map (m)/reduce (r) based on the 90,000 english sentences of the training data set in a cloudera parallel network environment 鈥 a distributed system. in the world there is not any scientific study which is similar to this survey. our new model can classify sentiment of millions of english documents with the shortest execution time in the parallel network environment. we test our new model on the 25,000 english documents of the testing data set and achieved on 61.2% accuracy. our english training data set includes 45,000 positive english sentences and 45,000 negative english sentences.	4	1.0
data properties and the performance of sentiment classification for electronic commerce applications	sentiment classification has played an important role in various research area including ecommerce applications and a number of advanced computational intelligence techniques including machine learning and computational linguistics have been proposed in the literature for improved sentiment classification results. while such studies focus on improving performance with new techniques or extending existing algorithms based on previously used dataset, few studies provide practitioners with insight on what techniques are better for their datasets that have different properties. this paper applies four different sentiment classification techniques from machine learning (na茂ve bayes, svm and decision tree) and sentiment orientation approaches to datasets obtained from various sources (imdb, twitter, hotel review, and amazon review datasets) to learn how different data properties including dataset size, length of target documents, and subjectivity of data affect the performance of those techniques. the results of computational experiments confirm the sensitivity of the techniques on data properties including training data size, the document length and subjectivity of training /test data in the improvement of performances of techniques. the theoretical and practical implications of the findings are discussed.	4	1.0
building thesaurus lexicon using dictionary-based approach for sentiment classification	sentiment classification categorizes people's opinions from the data. nowadays, people express their personal interests, feelings, and opinions on social media, and the posts on social media are frequently used as the data for sentiment classification. one of the sentiment classification approaches is a dictionarybased approach. a traditional dictionarybased sentiment classification approach uses word matching based on the lexicon. however, many posts cannot be analyzed by traditional dictionarybased sentiment classifier due to the absence of the sentiment words in the lexicon. for this reason, it is needed to expand the lexicon so that the lexicon can contain the words. in this paper, we propose a method to build thesaurus lexicon using dictionarybased approach for the sentiment classification. the proposed method uses three online dictionaries to collect thesauruses based on the seed words, and stores only cooccurrence words into the thesaurus lexicon in order to improve the reliability of the thesaurus lexicon. also, this method recursively collects thesauruses which are a set of synonyms and antonyms to expand the thesaurus lexicon. this recursive thesaurus collection provides effective expansion of the lexicon from small set without the use of human resource.	3	0.5
a comparative study of feature selection and machine learning methods for sentiment classification on movie data set	sentiment analysis has become a leading research domain with the advent of web 2.0 where web users express their opinions in user forums, blogs, discussion boards, and review sites. the online information is considered to be a valuable source for decision making, improving the quality of service, and helping the service providers to enhance their competitiveness. since the processing of highdimensional text data is not scalable, different feature selection mechanisms are being used to confine the study to only most informative features. these features are then used to train the classifier to improve the accuracy of sentimentbased classification. this paper explores six feature selection mechanisms (ig, gr, chi, oner, relieff, and sae) with five different machine learning classifiers (svm, nb, dt, knn, and me) thereby providing accuracy, on the movie review data set for each. comparative results show that naive bayes (nb) outperforms other classifiers and works better for gain ratio (gr) and significance attribute evaluation (sae) feature selection method.	2	0.3333333333333333
review-level sentiment classification with sentence-level polarity correction	we propose an effective technique to solving reviewlevel sentiment classification problem by using sentencelevel polarity correction. our polarity correction technique takes into account the consistency of the polarities (positive and negative) of sentences within each product review before performing the actual machine learning task. while sentences with inconsistent polarities are removed, sentences with consistent polarities are used to learn stateoftheart classifiers. the technique achieved better results on different types of products reviews and outperforms baseline models without the correction technique. experimental results show an average of 82% fmeasure on four different product review domains.	2	0.3333333333333333
hybrid model based sentiment classification of chinese micro-blog	through analysis and study of emotional characteristics in chinese microblog, such as sina weibo, this paper proposed a multidimensional sentiment classification method based on microblog emoticon by dividing microblog into 7 types of emotions categories happiness, fondness, sorrow, anger, fear, detestation and surprise. we used predefined microblog emoticon sets to initial screen largescale unmarked data, and automatically labeled them, then used this emotional corpus as training set to train the emotion classifier, which divided microblog data into multiple emotion categories. the experimental results show that accuracy rate of using unigram model for each class can reach 63.7%. and the adoption of different feature selection methods for support vector machines and naive bias classifier experiment, by which the obtained accuracy rate and recall rate has reached higher than 71%.	2	0.3333333333333333
no sentiment is an island: sentiment classification on medical forums	in this study we propose a new method to classify sentiments in messages posted on online forums. traditionally, sentiment classification relies on analysis of emotionallycharged words and discourse units found in the classified text. in coherent online discussions, however, messages’ nonlexical metainformation can be sufficient to achieve reliable classification results. our empirical evidence is obtained through multiclass classification of messages posted on a medical forum.	2	0.3333333333333333
sentiment classification with graph sparsity regularization	text representation is a preprocessing step in building a classifier for sentiment analysis. but in vector space model (vsm) or bagof features (bof) model, features are independent of each other when to learn a classifier model. in this paper, we firstly explore the text graph structure which can represent the structural features in natural language text. different to the bof model, by directly embedding the features into a graph, we propose a graph sparsity regularization method which can make use of the the graph embedded features. our proposed method can encourage a sparse model with a small number of features connected by a set of paths. the experiments on sentiment classification demonstrate our proposed method can get better results comparing with other methods. qualitative discussion also shows that our proposed method with graphbased representation is interpretable and effective in sentiment classification task.	2	0.3333333333333333
sentiment classification for turkish twitter feeds using lda	today, people are able to express their opinions and ideas on any subject using personal blogs or a variety of social media environments. contents shared by users with each passing day increases the data size on the web but this situation is a complication for meaningful information extraction. therefore, sentiment analysis studies aimed at automatically obtaining meaningful information from social media content showed a significant increase in recent years. in these studies, automatically analyzing the content of messages and identifying sentiment such as positive, neutral, negative etc. are intended. in this study, a system has been proposed for analyzing sentiment of turkish twitter feeds. in addition, sentiment classification which is a leading problem for sentiment analysis studies has been performed using topic modeling and the effect of modeling on results are examined. the topic model has been created using lda (latent dirichlet allocation) algorithm. experimental results obtained with different feature extraction model and classifiers. the results show that topic modeling is more successful compared to the methods used in the previous studies. also, sentiment classification based on topic model knowledge has been found to increase sentiment analysis success by %26 compared to our previous work.	3	0.5
sentiment classification for unlabeled dataset using doc2vec with jst	supervised learning require sentiment labeled corpus for training. but it is hard to apply automatic sentiment classification system to new domain because labeled dataset construction costs a lot of time. meanwhile, researches using doc2vec based document representation beat out other sentiment classification researches. however, these document representation methods only represent documents' context or sentiment. in this paper, we proposed supervised learning scheme for unlabeled corpus and also proposed document representation method which can simultaneously represent documents' context and sentiment.	3	0.5
a new sentiment classification method based on hybrid classification in twitter	social media including twitter create a space for expression and dissemination of thoughts and opinions on various topics and various events and they have created opportunity to apply theories and technology leading to search and explore the trends. mining stream data needs to be balanced in three different branches accuracy, time and memory. the optimal accuracy rate has obtained in the stream data using stochastic gradient descent algorithm. in this paper, we show that replacing the stochastic gradient descent algorithm in tree leaves causes improvement and reliability of the forecast. the proposed algorithm, hoeffding stochastic gradient descent, has not changed the time while increasing the accuracy. studies on the tweets that have been randomly selected shows that the proposed algorithm outperforms when assessing the sentiment stream data.	3	0.5
an ensemble method for unbalanced sentiment classification	current binary sentiment classification has been focusing on improving the performance of classification, while the imbalance of sentiment data set in practical applications, which means the number of samples in one category is several folds of that of another category, is neglected. most study on sentiment classification has been done on the balanced data, so these methods perform well on balanced data, while are unable to maintain the same performance on unbalanced data set. this paper proposed a method for unbalanced sentiment classification that combines unbalanced classification method and ensemble learning technique. both algorithm and data set are considered to enhance the classification performance of imbalance sentiment data set. under the framework of ensemble learning, this hybrid method integrates three different methods undersampling, bootstrap resampling and random feature selection to process the data set. experiments on the unbalanced data set prove that this ensemble method can improve the classification performance of unbalanced sentiment data set.	3	0.5
hierarchical micro-blog sentiment classification based on feature fusion	sentiment classification is an important issue of opinion mining. it has a high application value to classify sentiment in microblogs. as traditional feature selection method has semantic gap, a neural network language model was used to propose a deep feature representation method based on probability model to distribute weight to the word vector. using this method, text semantic vector could be built. in order to avoid the semantic gap, the deep features and shallow features of text were integrated and feature vector that contained semantic information was constructed. with svm hierarchical classification model, a variety of sentiments could be classified. experimental results show that the hierarchical sentiment classification method based on feature fusion can improve the accuracy of sentiment classification in microblogs.	3	0.5
cross-lingual sentiment classification: similarity discovery plus training data adjustment	the performance of crosslingual sentiment classification is sharply limited by the language gap, which means that each language has its own ways to express sentiments. many methods have been designed to transmit sentiment information across languages by making use of machine translation, parallel corpora, auxiliary unlabeled samples and other resources. in this paper, a new approach is proposed based on the selection of training data, where labeled samples highly similar to the target language are put into the training set. the refined training samples are used to build up an effective crosslingual sentiment classifier focusing on the target language. the proposed approach contains two major strategies the alignedtranslation topic model and the semisupervised training data adjustment. the alignedtranslation topic model provides a crosslanguage representation space in which the semisupervised training data adjustment procedure attempts to select effective training samples to eliminate the negative influence of the semantic distribution differences between the original and target languages. the experiments show that the proposed approach is feasible for crosslanguage sentiment classification tasks and provides insight into the semantic relationship between two different languages.	3	0.5
improving twitter sentiment classification via multi-level sentiment-enriched word embeddings	most of existing work learn sentimentspecific word representation for improving twitter sentiment classification, which encoded both ngram and distant supervised tweet sentiment information in learning process. they assume all words within a tweet have the same sentiment polarity as the whole tweet, which ignores the word its own sentiment polarity. to address this problem, we propose to learn sentimentspecific word embedding by exploiting both lexicon resource and distant supervised information. we develop a multilevel sentimentenriched word embedding learning method, which uses parallel asymmetric neural network to model ngram, word level sentiment and tweet level sentiment in learning process. experiments on standard benchmarks show our approach outperforms stateoftheart methods.	3	0.5
adding cnns to the mix: stacking models for sentiment classification	in the recent years, sentiment analysis has emerged as a major research problem in the field of natural language processing. here, the problem is to identify the sentiment/emotion in given sentence/paragraph. usually it is positive, negative and neutral. here, we consider only binary classification task (positive and negative). we have considered the best performing sentiment analysis model which is a ensemble of nbsvm, paragraph2vec and rnn. we added cnn into this stacking model and showed that our ensemble model perform better than the existing one. we achieved the state of the art performance on imdb movie review dataset, stanford sentiment treebank dataset (sst) and elec reviews dataset.	4	1.0
swatcs65: sentiment classification using an ensemble of class projects	this paper presents the swatcs65 ensem ble classifier used to identify the sentiment of tweets. the classifier was trained and tested using data provided by semeval2015, task 10, subtask b with the goal to label the sen timent of an entire tweet. the ensemble was constructed from 26 classifiers, each written by a group of one to three undergraduate stu dents in the fall 2014 offering of a natural lan guage processing course at swarthmore col lege. each of the classifiers was designed in dependently, though much of the early struc ture was provided by inclass lab assignments. there was high variability in the final perfor mance of each of these classifiers, which were combined using a weighted voting scheme with weights correlated with performance us ing 5fold crossvalidation on the provided training data. the system performed very well, achieving an f1 score of 61.89.	2	0.3333333333333333
cross-domain text sentiment classification based on grouping-adaboost ensemble	in the crossdomain sentiment classification, the labeled data in the target domain is often scarce and precious. to solve this problem, this paper proposes a groupingadaboost ensemble classifier method by comprehensively using the strategies and techniques of semisupervised learning, bootstrapping, data grouping, adaboost, ensemble learning. firstly, we adopt a small amount of labeled data in the target domain to generate a number of virtual data by using synthetic minority oversampling technique. on this basis, we can obtain more data with high credibility label in the target domain by using bootstrapping method. in the aspect of classifier construction, we firstly make an equivalent quantity partition to the labeled data in the source domain, and combine each part with the labeled data in the target domain to form the corresponding combined data sets. corresponding to each combined data set, a classifier is trained, and it is then promoted by adaboost method. at last, these classifiers corresponding to the combined data sets are linearly integrated into an ensemble classifier. the experimental results on four data sets from amazon online shopping reviews corpora indicate that the proposed method can improve the accuracy of crossdomain sentiment transformation effectively.	2	0.3333333333333333
sentence sentiment classification using fuzzy word matching combined with fuzzy sentiment classifier	this article focuses on semantic tagging of content in terms of sentimental meaning which may often lead to ambiguities between the primary sense of the word and its meaning in a particular expression. to address this issue, a specially modified levenshtein distance algorithm for suffixmitigation was used to measure similarity of words. sentence sentiment classification was based on fuzzy logic approach and a fuzzy classifier. the presented method was experimentally tested with the sentimental analysis of selected sentences in the polish language. limitations of the presented method and possible improvements are discussed. 漏 2005, wydawnictwo sigma  n o t sp. z o.o. all right reserved.	2	0.3333333333333333
fine grained sentiment classification of customer reviews using computational intelligent technique	online reviews are now popularly used for judging quality of product or service and influence decision making of users while selecting a product or service. due to innumerous number of customer reviews on the web, it is difficult to summarize them which require a faster opinion mining system to classify the reviews. many researchers have explored various supervised and unsupervised machine learning techniques for binary classification of reviews. compared to these techniques, fuzzy logic can provide a straightforward and comparatively faster way to model the fuzziness existing between the sentiment polarities classes due to the ambiguity present in most of the natural languages. but the fuzzy logic techniques are less explored in this domain. hence in this paper, a fuzzy logic model based on the most popularly known sentiment based lexicon sentiwordnet has been proposed for fine grained classification of the reviews into weak positive, moderate positive, strong positive, weak negative, moderate negative and strong negative classes. experiments have been conducted on datasets containing reviews of electronic products namely smart phones, led tv and laptops and have shown to provide fine grained classification accuracy approximately in the range of 74% to 77%.	2	0.3333333333333333
a survey of machine learning techniques for sentiment classification	opinion mining also called as sentiment analysis is a process that provides with the subjective information for the text provided. in other words we can say that it analyzes person's opinion, evaluations, emotions, appraisals, etc. towards a particular product, event, issue, service, topic, etc. this paper focuses on the machine learning techniques used for sentiment analysis and opinion mining. these methods are further compared on the basis of their accuracy, advantages and limitations.	2	0.3333333333333333
sentiment classification of roman-urdu opinions using navie baysian, decision tree and knn classification techniques	sentiment mining is a field of text mining to determine the attitude of people about a particular product, topic, politician in newsgroup posts, review sites, comments on facebook posts and twitter etc. there are many issues involved in opinion mining. one important issue is that opinions could be in different languages (english, urdu, arabic etc.). to tackle each language according to its orientation is a challenging task. most of the research work in sentiment mining has been done in english language. currently, limited research is being carried out on sentiment classification of other languages like arabic, italian, urdu and hindi. in this paper, three classification models are used for text classification using waikato environment for knowledge analysis (weka). opinions written in romanurdu and english are extracted from a blog. these extracted opinions are documented in text files to prepare a training dataset containing 150 positive and 150 negative opinions, as labeled examples. testing data set is supplied to three different models and the results in each case are analyzed. the results show that na茂ve baysian outperformed decision tree and knn in term of more accuracy, precision, recall and fmeasure.	2	0.3333333333333333
a feature selection model based on genetic rank aggregation for text sentiment classification	sentiment analysis is an important research direction of natural language processing, text mining and web mining which aims to extract subjective information in source materials. the main challenge encountered in machine learning methodbased sentiment classification is the abundant amount of data available. this amount makes it difficult to train the learning algorithms in a feasible time and degrades the classification accuracy of the built model. hence, feature selection becomes an essential task in developing robust and efficient classification models whilst reducing the training time. in text mining applications, individual filterbased feature selection methods have been widely utilized owing to their simplicity and relatively high performance. this paper presents an ensemble approach for feature selection, which aggregates the several individual feature lists obtained by the different feature selection methods so that a more robust and efficient feature subset can be obtained. in order to aggregate the individual feature lists, a genetic algorithm has been utilized. experimental evaluations indicated that the proposed aggregation model is an efficient method and it outperforms individual filterbased feature selection methods on sentiment classification.	2	0.3333333333333333
content-specific unigrams and syntactic phrases to enhance sentiwordnet based sentiment classification	sentiment classification intelligently detects the polarity of documents by ascertaining polar values encapsulated in the document to classify them into positive and negative sentiments. machine learning classifier completely relies on the feature set orientations. sentiwordnet is a lexical resource where each term is associated with numerical scores for subjective and objective sentiment information. sentiwordnet based sentiment classifier uses sentiment features generated from 7% subjective terms available in the resource. sentiment features bear generic orientation for multiple domains but lacks comprehensive coverage e.g. text unit with null or few sentiment features reflects ambiguous or null sentiments. use of content specific unigrams and syntactic phrases along with sentiment features ensures consistency in the classification while enhancing the performance paradigm. model proposed in this research is validated on sentiment and polarity datasets. results of this research, completely out performs previous approaches and methods.	2	0.3333333333333333
using feature selection in combination with ensemble learning techniques to improve tweet sentiment classification performance	performing sentiment analysis of tweets by training a classifier is a challenging and complex task, requiring that the classifier can correctly and reliably identify the emotional polarity of a tweet. poor data quality, due to class imbalance or mislabeled instances, may negatively impact classification performance. ensemble learning techniques combine multiple models in an attempt to improve classification performance, especially on poor quality or imbalanced data, however, these techniques do not address the concern of high dimensionality present in tweets sentiment data and may require a prohibitive amount of resources to train on high dimensional data. this work addresses these issues by studying bagging and boosting combined with feature selection. these two techniques are denoted as selectbagging and selectboost, and seek to address both poor data quality and high dimensionality. we compare the performance of selectbagging and selectboost against feature selection alone. these techniques are tested with four base learners, two datasets and ten feature subset sizes. our results show that selectboost offers the highest performance, is significantly better than using no ensemble technique, and is significantly better than selectbagging for most learners on both datasets.	2	0.3333333333333333
improving sentiment classification accuracy of financial news using n-gram approach and feature weighting methods	sentiment classification of financial news deals with the identification of positive and negative news so that they can be applied in decision support system to perform stock trend predictions. this paper explores several types of feature space as different datasets for sentiment classification of the news article. experiments are conducted based on ngram approach (unigram, bigram and the combination of unigram and bigram) used as feature extraction with different feature weighting methods, while, document frequency (df) is used as feature selection method. we performed experiments to measure the classification accuracy of support vector machine (svm) with two kernel methods of linear and radial basis function (rbf). results showed that an efficient feature extraction increased classification accuracy when it is used as a combination of unigram and bigram. moreover, we also found that df can be applied as a dimension reduction method to reduce the feature space without loss of accuracy.	2	0.3333333333333333
sentiment classification of portuguese news headlines	this paper addresses the problem of classifying news headlines into sentiment categories. using a supervised approach, we train a classifier for classifying each news headline as positive, negative, or neutral. a news headline is considered positive if it is associated with good things, negative if it is associated with bad things, and neutral in the remaining cases. the experiments show an accuracy that ranges from 59.00% to 63.50% when syntactic features (argument1verbargument2 relations) are combined with other features. the accuracy ranges from 57.50% to 62.5% when these relations are not used.	2	0.3333333333333333
documentmodeling with convolutional-gated recurrent neural network for sentimentclassification	document modeling with convolutional gated recurrent neural network for sentiment classification [ c ]// proceedings of the 2015 conference on empirical methods in natural language processing. stroudsburg, pa association for computational.	2	0.3333333333333333
a method for user sentiment classification using instagram hashtags	in recent times, studies sentiment analysis are being actively conducted by implementing natural language processing technologies for analyzing subjective data such as opinions and attitudes of users expressed on the web, blogs, and social networking services (snss). conventionally, to classify the sentiments in texts, most studies determine positive/negative/neutral sentiments by assigning polarity values for sentiment vocabulary using sentiment lexicons. however, in this study, sentiments are classified based on thayer's model, which is psychologically defined, unlike the polarity classification used in opinion mining. in this paper, as a method for classifying the sentiments, sentiment categories are proposed by extracting sentiment keywords for major sentiments by using hashtags, which are essential elements of instagram. by applying sentiment categories to user posts, sentiments can be determined through the similarity measurement between the sentiment adjective candidates and the sentiment keywords. the test results of the proposed method show that the average accuracy rate for all the sentiment categories was 90.7%, which indicates good performance. if a sentiment classification system with a large capacity is prepared using the proposed method, then it is expected that sentiment analysis in various fields will be possible, such as for determining social phenomena through sns.	2	0.3333333333333333
an combined sentiment classification system for sighan-8	this paper describes our system (msi ip thu) used for topicbased chinese message polarity classification task in sighan8. in our system, a lexicon based classifier and a statistical machine learningbased classifier are built up, fol lowed by a linear combination of these t wo models. the overall performance of the proposed framework ranks in the mid dle of all terms participating in the task.	2	0.3333333333333333
an improved k-nearest-neighbor algorithm using genetic algorithm for sentiment classification	sentiment classification is to find the polarity of product or user reviews. supervised machine learning algorithms are used for opinion mining such as navie bayes, knearest neighbor and support vector machine. knn is simple algorithm but less efficient classification algorithm. in this paper we propose an improved knn algorithm, genetic algorithm is developed which is a hybrid genetic algorithm that incorporates the information gain for feature selection and combined with knn to improve its classification performance. specifically, we compared other supervised machine learning approaches such as navie bayes and traditional knn for sentiment classification of movie reviews and book reviews. the experimental results using genetic algorithm with improved indicate high performance levels with fmeasure of over 87% on the movie reviews.	2	0.3333333333333333
a comparative study of feature selection and machine learning methods for sentiment classification on movie data set	sentiment analysis has become a leading research domain with the advent of web 2.0 where web users express their opinions in user forums, blogs, discussion boards, and review sites. the online information is considered to be a valuable source for decision making, improving the quality of service, and helping the service providers to enhance their competitiveness. since the processing of highdimensional text data is not scalable, different feature selection mechanisms are being used to confine the study to only most informative features. these features are then used to train the classifier to improve the accuracy of sentimentbased classification. this paper explores six feature selection mechanisms (ig, gr, chi, oner, relieff, and sae) with five different machine learning classifiers (svm, nb, dt, knn, and me) thereby providing accuracy, on the movie review data set for each. comparative results show that naive bayes (nb) outperforms other classifiers and works better for gain ratio (gr) and significance attribute evaluation (sae) feature selection method.	2	0.3333333333333333
review-level sentiment classification with sentence-level polarity correction	we propose an effective technique to solving reviewlevel sentiment classification problem by using sentencelevel polarity correction. our polarity correction technique takes into account the consistency of the polarities (positive and negative) of sentences within each product review before performing the actual machine learning task. while sentences with inconsistent polarities are removed, sentences with consistent polarities are used to learn stateoftheart classifiers. the technique achieved better results on different types of products reviews and outperforms baseline models without the correction technique. experimental results show an average of 82% fmeasure on four different product review domains.	2	0.3333333333333333
hybrid model based sentiment classification of chinese micro-blog	through analysis and study of emotional characteristics in chinese microblog, such as sina weibo, this paper proposed a multidimensional sentiment classification method based on microblog emoticon by dividing microblog into 7 types of emotions categories happiness, fondness, sorrow, anger, fear, detestation and surprise. we used predefined microblog emoticon sets to initial screen largescale unmarked data, and automatically labeled them, then used this emotional corpus as training set to train the emotion classifier, which divided microblog data into multiple emotion categories. the experimental results show that accuracy rate of using unigram model for each class can reach 63.7%. and the adoption of different feature selection methods for support vector machines and naive bias classifier experiment, by which the obtained accuracy rate and recall rate has reached higher than 71%.	2	0.3333333333333333
no sentiment is an island: sentiment classification on medical forums	in this study we propose a new method to classify sentiments in messages posted on online forums. traditionally, sentiment classification relies on analysis of emotionallycharged words and discourse units found in the classified text. in coherent online discussions, however, messages’ nonlexical metainformation can be sufficient to achieve reliable classification results. our empirical evidence is obtained through multiclass classification of messages posted on a medical forum.	2	0.3333333333333333
sentiment classification with graph sparsity regularization	text representation is a preprocessing step in building a classifier for sentiment analysis. but in vector space model (vsm) or bagof features (bof) model, features are independent of each other when to learn a classifier model. in this paper, we firstly explore the text graph structure which can represent the structural features in natural language text. different to the bof model, by directly embedding the features into a graph, we propose a graph sparsity regularization method which can make use of the the graph embedded features. our proposed method can encourage a sparse model with a small number of features connected by a set of paths. the experiments on sentiment classification demonstrate our proposed method can get better results comparing with other methods. qualitative discussion also shows that our proposed method with graphbased representation is interpretable and effective in sentiment classification task.	2	0.3333333333333333
personality based public sentiment classification in microblog	in recent years, microblog has become one of the most widely used social media for people to exchange ideas and express emotions. as information propagates fast in social network, it's crucial for governments and public agencies to effectively monitor public sentiment implied in usergenerated content. most previous work of public sentiment analysis takes tweets of different users as a whole without considering the diverse word use of people. thus, some sentiment words may be neglected in the process of analysis because they are only used by people of specific groups. inspired by previous psychological findings that personality influences the ways people write and talk, we propose a personality based sentiment classification method. in order to capture more useful but not widely used sentiment words, our approach extracts textual features for people of different personality traits based on the big five model. moreover, we adopt an ensemble learning strategy to utilize both personality related and commonly used textual features. experimental study shows the effectiveness of our method.	2	0.3333333333333333
a survey of sentiment classification techniques	sentiment classification is an ongoing field and interesting area of research because of its application in various fields collecting review from people about products and social and political events through the web. currently, sentiment analysis concentrates for subjective statements or on subjectivity and overlook objective statements which carry sentiment(s). during the sentiment classification more challenging problem are faced due to the ambiguous sense of words, negation words and intensifier. due to its importance the correct sense of target word is extracted and determined for which the similarity arise in wordnet glosses. this paper presents a survey covering the techniques and methods in sentiment analysis and challenges appear in the field.keywords sentiment classification, word sense disambiguation, intensifier, sentiwordnet, wordnet.	2	0.3333333333333333