active learning and crowdsourcing for machine translation in low resource scenarios	corpus based approaches to automatic translation such as example based and statistical machine translation systems use large amounts of parallel data created by humans to train mathematical models for automatic language translation. large scale parallel data generation for new language pairs requires intensive human effort and availability of fluent bilinguals or expert translators. therefore it becomes immensely difficult and expensive to provide stateoftheart machine translation (mt) systems for rare languages.	-1	98
a productivity test of statistical machine translation post-editing in a typical localisation context	we evaluated the productivity increase of statistical mt postediting as compared to traditional translation in a twoday test involving twelve participants translating from english to french, italian, german, and spanish. the test setup followed an empirical methodology. a random subset of the entire new content produced in our company during a given year was translated with statistical mt engines trained on data from the previous year. the translation environment recorded translation and postediting times for each sentence. the results show a productivity increase for each participant, with significant variance across inviduals.	-3	118
a novel string-to-string distance measure with applications to machine translation evaluation	we introduce a stringtostring distance measure which extends the edit distance by block transpositions as constant cost edit operation. an algorithm for the calculation of this distance measure in polynomial time is presented. we then demonstrate how this distance measure can be used as an evaluation criterion in machine translation. the correlation between this evaluation criterion and human judgment is systematically compared with that of other automatic evaluation measures on two translation tasks. in general, like other automatic evaluation measures, the criterion shows low correlation at sentence level, but good correlation at system level.	-10	161
word reordering and a dynamic programming beam search algorithm for statistical machine translation	summary in this article, we describe an efficient beam search algorithm for statistical machine translation based on dynamic programming (dp). the search algorithm uses the translation model presented in [{\it p. f. brown}, {\it s. a. della pietra}, {\it v. j. della pietra} and {\it r. l. mercer}, 鈥淭he mathematics of statistical machine translation parameter estimation, ibid. 19, no. 2, 263鈥311 (1993)]. starting from a dpbased solution to the travelingsalesman problem, we present a novel technique to restrict the possible word reorderings between source and target language in order to achieve an efficient search algorithm. word reordering restrictions especially useful for the translation direction german to english are presented. the restrictions are generalized, and a set of four parameters to control the word reordering is introduced, which then can easily be adopted to new translation directions. the beam search procedure has been successfully tested on the verbmobil task (german to english, 8,000word vocabulary) and on the canadian hansards task (french to english, 100,000word vocabulary).	-10	164
the candide system for machine translation	we present an overview of candide, a system for automatic translation of french text to english text. candide uses methods of information theory and statistics to develop a probability model of the translation process. this model, which is made to accord as closely as possible with a large body of french and english sentence pairs, is then used to generate english translations of previously unseen french sentences. this paper provides a tutorial in these methods, discussions of the training and operation of the system, and a summary of test results. 1. introduction candide is an experimental computer program, now in its fifth year of development at ibm, for translation of french text to english text. our goal is to perform fullyautomatic, highquality texttotext translation. however, because we are still far from achieving this goal, the program can be used in both fullyautomatic and translator'sassistant modes. our approach is founded upon the statistical analysis of language....	-19	179
word-sense disambiguation for machine translation	in word sense disambiguation, a system attempts to determine the sense of a word from contextual fea tures. major barriers to building a highperforming word sense disambiguation system include the dif ficulty of labeling dat...	-8	144
re-examining machine translation metrics for paraphrase identification	we propose to reexamine the hypothesis that automated metrics developed for mt evaluation can prove useful for paraphrase identification in light of the significant work on the development of new mt metrics over the last 4 years. we show that a metaclassifier trained using nothing but recent mt metrics outperforms all previous paraphrase identification approaches on the microsoft research paraphrase corpus. in addition, we apply our system to a second corpus developed for the task of plagiarism detection and obtain extremely positive results. finally, we conduct extensive error analysis and uncover the top systematic sources of error for a paraphrase identification approach relying solely on mt metrics. we release both the new dataset and the error analysis annotations for use by the community.	-1	91
translation engines: techniques for machine translation	machine translation (mt) is the area of computer science and applied linguistics dealing with the translation of human languages such as english and german. mt on the internet has become an important tool by providing fast, economical and useful translations. with globalisation and expanding trade, demand for translation is set to grow. translation engines covers theoretical and practical aspects of mt, both classic and new, including  character sets and formatting languages  translation memory  linguistic and computational foundations  basic computational linguistic techniques  transfer and interlingua mt  evaluation software accompanies the text, providing readers with hands on experience of the main algorithms.	-14	167
following directions using statistical machine translation	mobile robots that interact with humans in an intuitive way must be able to follow directions provided by humans in unconstrained natural language. in this work we investigate how statistical machine translation techniques can be used to bridge the gap between natural language route instructions and a map of an environment built by a robot. our approach uses training data to learn to translate from natural language instructions to an automaticallylabeled map. the complexity of the translation process is controlled by taking advantage of physical constraints imposed by the map. as a result, our technique can efficiently handle uncertainty in both map labeling and parsing. our experiments demonstrate the promising capabilities achieved by our approach.	-3	108
word sense disambiguation vs. statistical machine translation	we directly investigate a subject of much recent debate do word sense disambiga tion models help statistical machine trans lation quality? we present empirical re sults casting doubt on this common, but unproved, assumption. using a stateof theart chinese word sense disambigua tion model to choose translation candi dates for a typical ibm statistical mt system, we find that word sense disam biguation does not yield significantly bet ter translation quality than the statistical machine translation system alone. error analysis suggests several key factors be hind this surprising finding, including in herent limitations of current statistical mt architectures.	-8	149
lattice minimum bayes-risk decoding for statistical machine translation	we present minimum bayesrisk (mbr) decoding for statistical machine translation. this statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance. we describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, wordtoword alignments from an mt system, and syntactic structure from parsetrees of source and target language sentences. we report the performance of the mbr decoders on a chinesetoenglish translation task. our results show that mbr decoding can be used to tune statistical mt performance for specific loss functions.	-5	127
reordering constraints for phrase-based statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary reorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible reorderings in an appropriate way, we obtain a polynomialtime search algorithm. we investigate different reordering constraints for phrasebased statistical machine translation, namely the ibm constraints and the itg constraints. we present efficient dynamic programming algorithms for both constraints. we evaluate the constraints with respect to translation quality on two japanese鈥揈nglish tasks. we show that the reordering constraints improve translation quality compared to an unconstrained search that permits arbitrary phrase reorderings. the itg constraints preform best on both tasks and yield statistically significant improvements compared to the unconstrained search.	-9	149
a comparative study on reordering constraints in statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary wordreorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible wordreorderings in an appropriate way, we obtain a polynomialtime search algorithm.in this paper, we compare two different reordering constraints, namely the itg constraints and the ibm constraints. this comparison includes a theoretical discussion on the permitted number of reorderings for each of these constraints. we show a connection between the itg constraints and the since 1870 known schröder numbers.we evaluate these constraints on two tasks the verbmobil task and the canadian hansards task. the evaluation consists of two parts first, we check how many of the viterbi alignments of the training corpus satisfy each of these constraints. second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.the experiments will show that the baseline itg constraints are not sufficient on the canadian hansards task. therefore, we present an extension to the itg constraints.	-10	157
machine translation evaluation versus quality estimation	most evaluation metrics for machine translation (mt) require reference translations for each sentence in order to produce a score reflecting certain aspects of its quality. the de facto metrics, bleu and nist, are known to have good correlation with human evaluation at the corpus level, but this is not the case at the segment level. as an attempt to overcome these two limitations, we address the problem of evaluating the quality of mt as a prediction task, where referenceindependent features are extracted from the input sentences and their translation, and a quality score is obtained based on models produced from training data. we show that this approach yields better correlation with human evaluation as compared to commonly used metrics, even with models trained on different mt systems, languagepairs and text domains.	-3	84
machine translation with a stochastic grammatical channel	we introduce a stochastic grammatical channel model for machine translation, that synthesizes several desirable characteristics of both statistical and grammatical machine translation. as with the pure statistical translation model described by wu (1996) (in which a bracketing transduction grammar models the channel), alternative hypotheses compete probabilistically, exhaustive search of the translation hypothesis space can be performed in polynomial time, and robustness heuristics arise naturally from a languageindependent inversiontransduction model. however, unlike pure statistical translation models, the generated output string is guaranteed to conform to a given target grammar. the model employs only (1) a translation lexicon, (2) a contextfree grammar for the target language, and (3) a bigram language model. the fact that no explicit bilingual translation rules are used makes the model easily portable to a variety of source languages. initial experiments show that it also achieves significant speed gains over our earlier model.	-15	131
multi-engine machine translation guided by explicit word matching	we describe a new approach for synthetically combining the output of several different machine translation (mt) engines operating on the same input. the goal is to pro duce a synthetic combination that surpasses all of the original systems in translation quality. our approach uses the individual mt engines as black boxes and does not require any explicit cooperation from the original mt systems. an explicit word matcher is first used in order to identify the words that are common between the mt engine outputs. a decoding algorithm then uses this information, in conjunction with confidence estimates for the vari ous engines and a trigram language model in order to score and rank a collection of sen tence hypotheses that are synthetic combinations of words from the various original en gines. the highest scoring sentence hypothesis is selected as the final output of our system.	-8	108
machine translation by triangulation: making effective use of multi-parallel corpora	current phrasebased smt systems perform poorly when using small training sets. this is a consequence of unreliable translation es timates and low coverage over source and target phrases. this paper presents a method which alleviates this problem by exploit ing multiple translations of the same source phrase. central to our approach is triangula tion, the process of translating from a source to a target language via an intermediate third language. this allows the use of a much wider range of parallel corpora for train ing, and can be combined with a standard phrasetable using conventional smoothing methods. experimental results demonstrate bleu improvements for triangulated mod els over a standard phrasebased system.	-6	103
bilingual framenet dictionaries for machine translation	this paper describes issues surrounding the planning and design of germanframenet (gfn), a counterpart to the englishbased framenet project. the goals of gfn are (a) to create lexical entries for german nouns, verbs, and adjectives that correspond to existing framenet entries, and (b) to link the parallel lexicon fragments by means of common semantic frames and numerical indexing mechanisms. gfn will take a finegrained approach towards polysemy that seeks to split word senses based on the semantic frames that underlie their analysis. the parallel lexicon fragments represent an important step towards capturing valuable information about the different syntactic realizations of frame semantic concepts across languages, which is relevant for information retrieval, machine translation, and language generation.	-11	119
statistical machine translation with word- and sentence-aligned parallel corpora.	the parameters of statistical translation models are typically estimated from sentencealigned parallel corpora. we show that significant improvements in the alignment and translation quality of such models can be achieved by additionall...	-9	115
applying morphology generation models to machine translation	we improve the quality of statistical machine translation (smt) by applying models that predict word forms from their stems using extensive morphological and syntactic infor mation from both the source and target lan guages. our inflection generation models are trained independently of the smt system. we investigate different ways of combining the in flection prediction component with the smt system by training the base mt system on fully inflected forms or on word stems. we applied our inflection generation models in translating english into two morphologically complex languages, russian and arabic, and show that our model improves the quality of smt over both phrasal and syntaxbased smt systems according to bleu and human judge ments.	-5	94
a probabilistic approach to syntax-based reordering for statistical machine translation	inspired by previous preprocessing ap proaches to smt, this paper proposes a novel, probabilistic approach to reordering which combines the merits of syntax and phrasebased smt. given a source sentence and its parse tree, our method generates, by tree operations, an nbest list of re ordered inputs, which are then fed to stan dard phrasebased decoder to produce the optimal translation. experiments show that, for the nist mt05 task of chineseto english translation, the proposal leads to bleu improvement of 1.56%.	-6	103
word-dependent transition models in hmm based word alignment for statistical machine translation	a word alignment modeler uses probabilistic learning techniques to train “worddependent transition models” for use in constructing phrase level hidden markov model (hmm) based word alignment models. as defined herein, “worddependent transition models” provide a probabilistic model wherein for each source word in training data, a selftransition probability is modeled in combination with a probability of jumping from that particular word to a different word, thereby providing a full transition model for each word in a source phrase. hmm based word alignment models are then used for various word alignment and machine translation tasks. in additional embodiments sparse data problems (i.e., rarely used words) are addressed by using probabilistic learning techniques to estimate worddependent transition model parameters by maximum a posteriori (map) training.	-2	75
machine translation system	a machine translation system includes a database for storing various information, database management section for performing database management, a bilingual correspondence data record subsystem for performing recording/learning processing of translation examples, a translation subsystem for performing translation processing, and dictionary management utilities for performing dictionary management and database transmission/reception processing. the bilingual correspondence data recording section records english and japanese bilingual correspondences by using english and japanese sentences stored in the same file or different files. the recorded bilingual correspondences are linked in units of parts by a bilingual correspondence learning section. in performing translation, an englishtojapanese translation section and the like generate a translation of an original sentence as a translation target by using parts and the like which have undergone learning/recording processing. the dictionary management utilities perform database transmission/reception processing to/from another machine translation system.	-16	99
robust machine translation evaluation with entailment features	existing evaluation metrics for machine translation lack crucial robustness their correlations with hu man quality judgments vary considerably across lan guages and genres. we believe that the main reason is their inability to properly capturemeaning a good translation candidate means the same thing as the reference translation, regardless of formulation. we propose a metric that evaluates mt output based on a rich set of features motivated by textual entailment, such as lexicalsemantic (in)compatibility and ar gument structure overlap. we compare this metric against a combination metric of four stateofthe art scores (bleu, nist, ter, and meteor) in two different settings. the combination metric out performs the individual scores, but is bested by the entailmentbased metric. combining the entailment and traditional features yields further improvements.	-4	66
platform-independent automated machine translation system	a client computer program designed to run in operating systems with various primary character sets is provided. the client computer program further allows the user to choose a preferred destination for translated documents. for example, the translation can be appended to the original document, written into a new document, sent to the clipboard, or turned out to any other supported destination according to the specifications of the user. in addition, the client computer program provides a translation job queue window that lists documents awaiting analysis and transmission for translation. through the translation job queue window, the user can dynamically add to and delete from the translation job queue, as well as suspend or reorder jobs, and open completed files directly from the list. furthermore, the user can choose to display either the requested translation alone or the requested translation together with the untranslated email message in the same window. finally, the client computer program interacts with an email program so that the user can initiate translation directly from the email program's user interface.	-10	88
syntactic preprocessing for statistical machine translation	we describe an approach to automatic sourcelanguage syntactic preprocessing in the context of arabicenglish phrasebased machine translation. sourcelanguage labeled dependencies, that are word aligned with target language words in a parallel corpus, are used to automatically extract syntactic reordering rules in the same spirit of xia and mccord (2004) and zhang et al. (2007). the extracted rules are used to reorder the sourcelanguage side of the training and test data. our results show that when using monotonic decoding and translations for unigram sourcelanguage phrases only, sourcelanguage reordering gives very significant gains over no reordering (25% relative increase in bleu score). with decoder distortion turned on and with access to all phrase translations, the differences in bleu scores are diminished. however, an analysis of sentencelevel bleu scores shows reordering outperforms noreordering in over 40% of the sentences. these results suggest that the approach holds big promise but much more work on arabic parsing may be needed.	-6	75
phrase-based backoff models for machine translation of highly inflected languages	we propose a backoff model for phrase based machine translation that translates unseen word forms in foreignlanguage text by hierarchical morphological ab stractions at the word and the phrase level. the model is evaluated on the europarl corpus for germanenglish and finnish english translation and shows improve ments over stateoftheart phrasebased models.	-7	79
using multiple edit distances to automatically rank machine translation output	this paper addresses the challenging problem of automatically evaluating output from machine translation (mt) systems in order to support the developers of these systems. conventional approaches to the problem include methods that automatically assign a rank such as a, b, c, or d to mt output according to a single edit distance between this output and a correct translation example. the single edit distance can be differently designed, but changing its design makes assigning a certain rank more accurate, but another rank less accurate. this inhibits improving accuracy of rank assignment. to overcome this obstacle, this paper proposes an automatic ranking method that, by using multiple edit distances, encodes machinetranslated sentences with a rank assigned by humans into multidimensional vectors from which a classifier of ranks is learned in the form of a decision tree (dt). the proposed method assigns a rank to mt output through the learned dt. the proposed method is evaluated using transcribed texts of real conversations in the travel arrangement domain. experimental results show that the proposed method is more accurate than the singleeditdistancebased ranking methods, in both closed and open tests.	-12	92
towards the use of word stems and suffixes for statistical machine translation	in this paper we present methods for improving the quality of translation from an inflected language into english by making use of partofspeech tags and word stems and suffixes in the source language. results for translations from spanish and catalan into english are presented on the lcstar trilingual corpus which consists of spontaneously spoken dialogues in the domain of travelling and appointment scheduling. results for translation from serbian into english are presented on the assimil language course, the bilingual corpus from unrestricted domain. we achieve up to 5% relative reduction of error rates for spanish and catalan and about 8% for serbian.	-6	75
cross-lingual ontology mapping --- an investigation of the impact of machine translation	ontologies are at the heart of knowledge management and make use of information that is not only written in english but also in many other natural languages. in order to enable knowledge discovery, sharing and reuse of these multilingual ontologies, it is necessary to support ontology mapping despite natural language barriers. this paper examines the soundness of a generic approach that involves machine translation tools and monolingual ontology matching techniques in crosslingual ontology mapping scenarios. in particular, experimental results collected from case studies which engage mappings of independent ontologies that are labeled in english and chinese are presented. based on findings derived from these studies, limitations of this generic approach are discussed. it is shown with evidence that appropriate translations of conceptual labels in ontologies are of crucial importance when applying monolingual matching techniques in crosslingual ontology mapping. finally, to address the identified challenges, a semanticoriented crosslingual ontology mapping (socom) framework is proposed and discussed.	-4	66
translation system, translation communication system, machine translation method, and medium embodying program	a translation means determination section of a translation system determines whether translation processing of language data input from an input section is to be performed in an internal translation section or on an external translation server connected by a communication line through a communication control section. in the latter case, it is also determined what processing the translation server is requested to perform. the translation means determination section flexibly switches between internal processing and processing on the translation server by using information such as a language pair to which translation is applied, the communication line state, and a comparison of abilities between the translation system and the translation server. a translation result of the translation section is output from an output section. this configuration allows easy implementation of function extension viewed from a user while minimizing communication cost and overhead.	-7	79
462 machine translation systems for europe	we built 462 machine translation systems for all language pairs of the acquis communautaire corpus. we report and analyse the performance of these system, and compare them against pivot translation and a number of system combination methods (multipivot, multisource) that are possible due to the available systems. 1	-4	65
statistical machine translation. final report	search all the public and authenticated articles in citeulike. include unauthenticated resultstoo (may include spam) enter a search phrase. you can also specify a citeulike article id(123456),. a doi (doi10.1234/12345678). or a pubmed id (pmid12345678).	-14	93
using lexicalized tags for machine translation	lexicalized tree adjoining grammar (ltag) is an attractive formalism for linguistic description mainly because of its extended domain of locality and its factoring recursion out from the domain of local dependencies (joshi, 1984, kroch and joshi, 1985, abeill茅, 1988). ltag's extended domain of locality enables one to localize syntactic dependencies (such as fillergap), as well as semantic dependencies (such as predicatearguments). the aim of this paper is to show that these properties combined with the lexicalized property of ltag are especially attractive for machine translation. the transfer between two languages, such as french and english, can be done by putting directly into correspondence large elementary universe without going through some interlingual representation and without major changes to the source and target grammars. the underlying formalism from the transfer is synchronous tree adjoining grammars (sheiber and schabes [1990]). transfer rules are stated as correspondences between nodes of trees of large domain of locality which are associated with words. we can thus define lexical transfer rules that avoid the defects of a mere wordtoword approach but still benefit from the simplicity and elegance of a lexical approach.	-23	102
target-text mediated interactive machine translation	the use of machine translation as a tool for professional or other highly skilled translators is for the most part currently limited to postediting arrangements in which the translator invokes mt when desired and then manually cleans up the results. a theoretically promising but hitherto largely unsuccessful alternative to postediting for this application is interactive machine translation (imt), in which the translator and mt system work in tandem. we argue that past failures to make imt viable as a tool for skilled translators have been the result of an infelicitous mode of interaction rather than any inherent flaw in the idea. as a solution, we propose a new style of imt in which the target text under construction serves as the medium of communication between an mt system and its user. we describe the design, implementation, and performance of an automatic word completion system for translators which is intended to demonstrate the feasibility of the proposed approach, albeit in a very rudimentary form.	-16	96
a matching technique in example-based machine translation	this paper addresses an important problem in examplebased machine translation (ebmt), namely how to measure similarity between a sentence fragment and a set of stored examples. a new method is proposed that measures similarity according to both surface structure and content. a second contribution is the use of clustering to make retrieval of the best matching example from the database more efficient. results on a large number of test cases from the celex database are presented.cranias, l; papageorgiou, h; piperidis, s	-19	100
an example-based method for transfer-driven machine translation	this paper presents a method called transferdriven machine translation (tdmt), which utilizes an examplebased framework for various process and combines multilevel knowledge. an examplebased framework can achieve quick processing and consistently describe knowledge. it is useful for spokenlanguage translation, which needs robust and efficient translation. tdmt strengthens the examplebased framework by integrating it with other frameworks. the feasibility of tdmt and the advantages of the examplebased framework have been confirmed with a prototype system, which translates spoken dialog sentences from japanese to english.	-21	102
the use of lexical semantics in interlingual machine translation	this paper describes the lexicalsemantic basis for unitran, an implemented scheme for translating spanish, english, and german bidirectionally. two claims made here are that the current representation handles many distinctions (or divergences ) across languages without recourse to languagespecific rules and that the lexicalsemantic framework provides the basis for a systematic mapping between the interlingua and the syntactic structure. the representation adopted is an extended version of lexical conceptual structure  which is suitable to the task of translating between divergent structures for two reasons (1) it provides an ion  of languageindependent properties from structural idiosyncrasies; and (2) it is compositional  in nature. the lexicalsemantic approach addresses the divergence problem by using a linguistically grounded mapping that has access to parameter settings in the lexicon. we will examine a number of relevant issues including the problem of defining primitives, the issue of interlinguality, the crosslinguistic coverage of the system, and the mapping between the syntactic structure and the interlingua. a detailed example of lexicalsemantic composition will be presented.	-21	102
maxsim: a maximum similarity metric for machine translation evaluation	we propose an automatic machine translation (mt) evaluation metric that calculates a sim ilarity score (based on precision and recall) of a pair of sentences. unlike most metrics, we compute a similarity score between items across the two sentences. we then find a maxi mum weight matching between the items such that each item in one sentence is mapped to at most one item in the other sentence. this general framework allows us to use arbitrary similarity functions between items, and to in corporate different information in our com parison, such as ngrams, dependency rela tions, etc. when evaluated on data from the acl07 mt workshop, our proposed metric achieves higher correlation with human judge ments than all 11 automatic mt evaluation metrics that were evaluated during the work shop.	-5	70
segmentation for english-to-arabic statistical machine translation	in this paper, we report on a set of ini tial results for englishtoarabic statistical machine translation (smt). we show that morphological decomposition of the arabic source is beneficial, especially for smallersize corpora, and investigate different recombina tion techniques. we also report on the use of factored translation models for english toarabic translation.	-5	70
novel reordering approaches in phrase-based statistical machine translation	this paper presents novel approaches to reordering in phrasebased statistical machine translation. we perform consistent reordering of source sentences in training and estimate a statistical translation model. using this model, we follow a phrasebased monotonic machine translation approach, for which we develop an efficient and flexible reordering framework that allows to easily introduce different reordering constraints. in translation, we apply source sentence reordering on word level and use a reordering automaton as input. we show how to compute reordering automata ondemand using ibm or itg constraints, and also introduce two new types of reordering constraints. we further add weights to the reordering automata. we present detailed experimental results and show that reordering significantly improves translation quality.	-8	80
machine translation system	methods and apparatus for machine translation are disclosed. in one embodiment of the invention, information is stored in a memory which is contained in a computer, or some other device. the stored information includes a set of eigens for a number of languages, a crosslanguage eigen dictionary, a pattern dictionary, and a crosslanguage pattern dictionary. the first step of the translation is the conversion of a sentence in a first language to an instantiated pattern form. a corresponding pattern is then found in the crosslanguage pattern dictionary. eigens are then found using the crosslanguage eigen dictionary, and a translation in a second language is assembled.	-10	85
the lrc machine translation system: linguistics research center	sourcelanguage text is analyzed according to phrasestructure grammar rules augmented with procedures incorporating syntactic and semantic restrictions, surface and deep case analysis, and transformations; transformed to targetlanguage structures and lexical items representing an equivalent utterance; then synthesized into targetlanguage text.	-31	106
example-based machine translation using dp-matching between word sequences	summary we propose a new approach to the examplebased machine translation paradigm. first, the proposed approach retrieves the most similar example by carrying out dpmatching of the input sentence and source sentences in an example database while measuring the semantic distances of the words. second, the approach adjusts the gap between the input and the most similar example by using a bilingual dictionary. we demonstrate its high coverage and accuracy through a computational experiment for a limited domain.	-12	88
machine translation system incorporating syntactic dependency treelets into a statistical framework	in one embodiment of the present invention, a decoder receives a dependency tree as a source language input and accesses a set of statistical models that produce outputs combined in a log linear framework. the decoder also accesses a table of treelet translation pairs and returns a target dependency tree based on the source dependency tree, based on access to the table of treelet translation pairs, and based on the application of the statistical models.	-3	59
shallow parsing for portuguese--spanish machine translation	to produce fast, reasonably intelligible and easily correctable translations between related languages, it suffices to use a machine translation strategy which uses shallow parsing techniques to refine what would usually be called wordforword machine translation. this paper describes the application of shallow parsing techniques (morphological analysis, lexical disambiguation, and flat, local parsing) in a portuguese–spanish, spanish–portuguese machine translation system which is currently being developed by our group and is publicly and freely available at http//copacabana.dlsi.ua.es.	-10	84
can crowds build parallel corpora for machine translation systems?	corpus based approaches to machine translation (mt) rely on the availability of parallel corpora. in this paper we explore the effectiveness of mechanical turk for creating parallel corpora. we explore the task of sentence translation, both into and out of a language. we also perform preliminary experiments for the task of phrase translation, where ambiguous phrases are provided to the turker for translation in isolation and in the context of the sentence it originated from.	-3	59
multiple-parts-of-speech disambiguating method and apparatus for machine translation system	a machine translation system comprises input means for inputting a sentence written in a natural language, processor for parsing the input sentence, a word dictionary memory referred to by the processor, and a memory for storing multiplepartsofspeech disambiguating rules in the form of a table. the parts of speech of words capable of functioning as multiple parts of speech should be in the inputted sentence are determined in consideration of an array of the parts of speech by applying the multiplepartsofspeech disambiguating rules. additionally, rate of appearance of each part of speech which the word of the input sentence can function as is previously calculated, and the part of speech which can not be determined by consulting the disambiguating rule table is determined in dependence on whether the rate of appearance exceeds a predetermined threshold value.	-26	102
cross-lingual ontology mapping – an investigation of the impact of machine translation	ontologies are at the heart of knowledge management and make use of information that is not only written in english but also in many other natural languages. in order to enable knowledge discovery, sharing and reuse of these multilingual ontologies, it is necessary to support ontology mapping despite natural language barriers. this paper examines the soundness of a generic approach that involves machine translation tools and monolingual ontology matching techniques in crosslingual ontology mapping scenarios. in particular, experimental results collected from case studies which engage mappings of independent ontologies that are labeled in english and chinese are presented. based on findings derived from these studies, limitations of this generic approach are discussed. it is shown with evidence that appropriate translations of conceptual labels in ontologies are of crucial importance when applying monolingual matching techniques in crosslingual ontology mapping. finally, to address the identified challenges, a semanticoriented crosslingual ontology mapping (socom) framework is proposed and discussed.	-4	64
dialectal to standard arabic paraphrasing to improve arabic-english statistical machine translation	this paper is interested in improving the quality of arabicenglish statistical machine translation (smt) on highly dialectal arabic text using morphological knowledge. we present a lightweight rulebased approach to producing modern standard arabic (msa) paraphrases of dialectal arabic outofvocabulary words and low frequency words. our approach extends an existing msa analyzer with a small number of morphological clitics and transfer rules. the generated paraphrase lattices are input to a stateoftheart phrasebased smt system resulting in improved bleu scores on a blind test set by 0.56 absolute bleu (or 1.5% relative).	-2	54
incremental hypothesis alignment for building confusion networks with application to machine translation system combination	confusion network decoding has been the most successful approach in combining out puts from multiple machine translation (mt) systems in the recent darpa gale and nist open mt evaluations. due to the vary ing word order between outputs from differ ent mt systems, the hypothesis alignment presents the biggest challenge in confusion network decoding. this paper describes an incremental alignment method to build confu sion networks based on the translation edit rate (ter) algorithm. this new algorithm yields significant bleu score improvements over other recent alignment methods on the gale test sets and was used in bbn's submission to the wmt08 shared translation task.	-5	68
syntax-based language models for machine translation	reacttext 435 we propose and evaluate computational techniques for deciphering unknown scripts. we focus on the case in which an unfamiliar script encodes a known language. the decipherment of a brief document or inscription is driven by data about the spoken language. we consider which scripts are easy or hard to decipher, how much data is required, and whether the techniques are robust against language...  /reacttext  reacttext 436   /reacttext [show full ]	-10	83
displaying and correcting method for machine translation system	in a system wherein a first text in a first natural language is translated into a second text in a second natural language; a text displaying and correcting system comprising a first memory area for storing parts of the first text divided in predetermined units, with identifications assigned to the respective parts, and a second memory area for storing predetermined units of the second text corresponding to the aforementioned units of the first text, with the same identifications assigned thereto, so that the first and second texts are simultaneously displayed on a screen of a display unit, and that the text is revised in each unit with identification assigned.	-27	99
online learning for interactive statistical machine translation	stateoftheart machine translation (mt) systems are still far from being perfect. an alternative is the socalled interactive machine translation (imt) framework. in this framework, the knowledge of a human translator is combined with a mt system. the vast majority of the existing work on imt makes use of the wellknown batch learning paradigm. in the batch learning paradigm, the training of the imt system and the interactive translation process are carried out in separate stages. this paradigm is not able to take advantage of the new knowledge produced by the user of the imt system. in this paper, we present an application of the online learning paradigm to the imt framework. in the online learning paradigm, the training and prediction stages are no longer separated. this feature is particularly useful in imt since it allows the user feedback to be taken into account. the online learning techniques proposed here incrementally update the statistical models involved in the translation process. empirical results show the great potential of online learning in the imt framework.	-3	57
e-services translation utilizing machine translation and translation memory	a system and method for translating data from a source language to a target language is provided wherein machine generated target translation of a source sentence is compared to a database of human generated target sentences. if a matching human generated target sentence is found, the human generated target sentence may be used instead of the machine generated sentence, since the human generated target sentence is more likely to be a wellformed sentence than the machine generated sentence. the system and method does not rely on a translation memory containing pairs of sentences in both source and target languages, and minimizes the reliance on a human translator to correct a translation generated by machine translation.	-2	52
translating with examples: a new approach to machine translation	atr interpreting telephony research laboratories sanpeidani, inuidani seikacho, sorakugun kyoto 61902, japan email sumita%atrla.atr.co.jp@uunet.uu.net    this paper proposes examplebased machine translation (ebmt). ebmt retrieves similar examples	-23	100
error detection for statistical machine translation using linguistic features	automatic error detection is desired in the postprocessing to improve machine translation quality. the previous work is largely based on confidence estimation using systembased features, such as word posterior probabilities calculated from nbest lists or word lattices. we propose to incorporate two groups of linguistic features, which convey information from outside machine translation systems, into error detection lexical and syntactic features. we use a maximum entropy classifier to predict translation errors by integrating word posterior probability feature and linguistic features. the experimental results show that 1) linguistic features alone outperform word posterior probability based confidence estimation in error detection; and 2) linguistic features can further provide complementary information when combined with word confidence scores, which collectively reduce the classification error rate by 18.52% and improve the f measure by 16.37%.	-3	58
maxsim: a maximum similarity metric for machine translation evaluation	we propose an automatic machine translation (mt) evaluation metric that calculates a similarity score (based on precision and recall) of a pair of sentences. unlike most metrics, we compute a similarity score between items across the two sentences. we then find a maximum weight matching between the items such that each item in one sentence is mapped to at most one item in the other sentence. this general framework allows us to use arbitrary similarity functions between items, and to incorporate different information in our comparison, such as ngrams, dependency relations, etc. when evaluated on data from the acl07 mt workshop, our proposed metric achieves higher correlation with human judgements than all 11 automatic mt evaluation metrics that were evaluated during the workshop. 漏 2008 association for computational linguistics.	-5	65
stochastic finite-state models for spoken language machine translation	the problem of machine translation can be viewed as consisting of twosubproblems (a) lexical selection and (b) lexical reordering. in thispaper, we propose stochastic finitestate models for these two subproblems. stochastic finitestate models are efficiently learnablefrom data, effective for decoding and are associated with a calculusfor composing models which allows for tight integration of constraintsfrom various levels of language processing. we present a method forlearning stochastic finitestate models for lexical selection andlexical reordering that are trained automatically from pairs of sourceand target utterances. we use this method to develop models forenglish–japanese and english–spanish translation and present the performance of these models for translation on speech and text. we also evaluate the efficacy of such a translation model in the context of a call routing task of unconstrained speech utterances.	-11	85
language model adaptation for statistical machine translation based on information retrieval	language modeling is an important part for both speech recognition and machine translation systems. adaptation has been successfully applied to language models for speech recognition. in this paper we present experiments concerning language model adaptation for statistical machine translation. we develop a method to adapt language models using information retrieval methods. the adapted language models drastically reduce perplexity over a general language model and we can show that it is possible to improve the translation quality of a statistical machine translation using those adapted language models instead of a general language model.	-9	79
handbook of natural language processing and machine translation: darpa global autonomous language exploitation	this comprehensive handbook, written by leading experts in the field, details the groundbreaking research conducted under the breakthrough gale program  the global autonomous language exploitation within the defense advanced research projects agency (darpa), while placing it in the context of previous research in the fields of natural language and signal processing, artificial intelligence and machine translation. the most fundamental contrast between gale and its predecessor programs was its holistic integration of previously separate or sequential processes. in earlier language research proolive, joseph p; christianson, caitlin; mccary, john	-2	53
machine translation using vector space representations	an embodiment of the present invention provides a method for automatically translating text. first, a conceptual representation space is generated based on sourcelanguage documents and targetlanguage documents, wherein respective terms from the sourcelanguage and targetlanguage documents have a representation in the conceptual representation space. second, a new sourcelanguage document is represented in the conceptual representation space, wherein a subset of terms in the new sourcelanguage document is represented in the conceptual representation space, such that each term in the subset has a representation in the conceptual representation space. then, a term in the new sourcelanguage document is automatically translated into a corresponding targetlanguage term based on a similarity between the representation of the term and the representation of the corresponding targetlanguage term.	-3	56
statistical machine translation gains respect	as business, finance, education, and the internet become increasingly international and multilingual, google and other organizations are investing more time, money, and talent into researching the effectiveness of machinetranslation technologies.	-8	75
generation-heavy hybrid machine translation	this paper describes generationheavy hybrid machine translation (ghmt), a novel approach for trans lating between structurallydivergent language pairs with asymmetrical resources. the approach depends on the existence of rich target language resources such as word lexical semantics, categorial variations and subcategorization frames. these resources are used to overgenerate multiple lexicostructural variations from a targetglossed syntactic dependency representation of the source language sentence. this symbolic overgeneration, which accounts for a wide range of possible variations, is constrained by a statistical targetlanguage model. the exploitation of target language resources (symbolic and statistical) to handle a problem usually reserved for transfer and interlingual mt is useful for translation from source languages with scarce linguistic resources. a preliminary evaluation on the application of this approach to spanishenglish mt is conducted with promising results.	-11	81
a finite-state approach to machine translation	the problem of machine translation can be viewed as consisting of two subproblems (a) lexical selection; (b) lexical reordering. we propose stochastic finitestate models for these two subproblems. stochastic finitestate models are efficiently able to learn from data, effective for decoding and are associated with a calculus for composing models which allows for tight integration of constraints from various levels of language processing. we present a method for learning stochastic finitestate models for lexical choice and lexical reordering that are trained automatically from pairs of source and target utterances. we use this method to develop models for englishjapanese translation and present the performance of these models for translation of speech and text. we also evaluate the efficacy of such a translation model in the context of a call routing task of unconstrained speech utterances.	-12	84
the lrc machine translation system: an overview of the linguistic component of metal	the lrc machine translation system an overview of the linguistic component of metaldoi10.3115/990100.990105winfield s. bennettthe university of texas at austinacademia prahaconference on computational linguisticsbennett, w. and slocum, j., the lrc machine translation system, computational linguistics, vol. 11, no. 23, pp. 111121, 1985....	-31	100
cache-based document-level statistical machine translation	statistical machine translation systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time, ignoring documentlevel information. in this paper, we propose a cachebased approach to documentlevel translation. since caches mainly depend on relevant data to supervise subsequent decisions, it is critical to fill the caches with highlyrelevant data of a reasonable size. in this paper, we present three kinds of caches to store relevant documentlevel information 1) a dynamic cache, which stores bilingual phrase pairs from the best translation hypotheses of previous sentences in the test document; 2) a static cache, which stores relevant bilingual phrase pairs extracted from similar bilingual document pairs (i.e. source documents similar to the test document and their corresponding target documents) in the training parallel corpus; 3) a topic cache, which stores the targetside topic words related with the test document in the sourceside. in particular, three new features are designed to explore various kinds of documentlevel information in above three kinds of caches.	-2	51
purest ever example-based machine translation: detailed presentation and assessment	we have designed, implemented and assessed an ebmt system that can be dubbed the 'purest ever built' it strictly does not make any use of variables, templates or patterns, does not have any explicit transfer component, and does not require any preprocessing or training of the aligned examples. it only uses a specific operation, proportional analogy, that implicitly neutralises divergences between languages and captures lexical and syntactical variations along the paradigmatic and syntagmatic axes without explicitly decomposing sentences into fragments. exactly the same genuine implementation of such a core engine was evaluated on different tasks and language pairs. to begin with, we compared our system on two tasks of a previous mt evaluation campaign to rank it among other current stateoftheart systems. then, we illustrated the 'universality' of our system by participating in a recent mt evaluation campaign, with exactly the same core engine, for a wide variety of language pairs. finally, we studied the in uence of extra data like dictionaries and paraphrases on the system performance.	-6	68
cohesive phrase-based decoding for statistical machine translation	phrasebased decoding produces stateofthe art translations with no regard for syntax. we add syntax to this process with a cohesion constraint based on a dependency tree for the source sentence. the constraint allows the decoder to employ arbitrary, nonsyntactic phrases, but ensures that those phrases are translated in an order that respects the source tree's structure. in this way, we target the phrasal decoder's weakness in order model ing, without affecting its strengths. to fur ther increase flexibility, we incorporate cohe sion as a decoder feature, creating a soft con straint. the resulting cohesive, phrasebased decoder is shown to produce translations that are preferred over noncohesive output in both automatic and human evaluations.	-5	64
system and method for machine learning a confidence metric for machine translation	a machine translation system is trained to generate confidence scores indicative of a quality of a translation result. a source string is translated with a machine translator to generate a target string. features indicative of translation operations performed are extracted from the machine translator. a trusted entityassigned translation score is obtained and is indicative of a trusted entityassigned translation quality of the translated string. a relationship between a subset of the extracted features and the trusted entityassigned translation score is identified.	-4	60
neural machine translation of rare words with subword units	neural machine translation (nmt) models typically operate with a fixed vocabulary, but translation is an openvocabulary problem. previous work addresses the translation of outofvocabulary words by backing off to a dictionary. in this paper, we introduce a simpler and more effective approach, making the nmt model capable of openvocabulary translation by encoding rare and unknown words as sequences of subword units. this is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). we discuss the suitability of different word segmentation techniques, including simple character ngram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a backoff dictionary baseline for the wmt 15 translation tasks englishgerman and englishrussian by 1.1 and 1.3 bleu, respectively.	3	169
neural machine translation by jointly learning to align and translate	neural machine translation is a recently proposed approach to machine translation. unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. the models proposed recently for neural machine translation often belong to a family of encoderdecoders and consists of an encoder that encodes a source sentence into a fixedlength vector from which a decoder generates a translation. in this paper, we conjecture that the use of a fixedlength vector is a bottleneck in improving the performance of this basic encoderdecoder architecture, and propose to extend this by allowing a model to automatically (soft)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. with this new approach, we achieve a translation performance comparable to the existing stateoftheart phrasebased system on the task of englishtofrench translation.	1	1890
on the properties of neural machine translation: encoder-decoder approaches	neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. the neural machine translation models often consist of an encoder and a decoder. the encoder extracts a fixedlength representation from a variablelength input sentence, and the decoder generates a correct translation from this representation. in this paper, we focus on analyzing the properties of the neural machine translation using two models; rnn encoderdecoder and a newly proposed gated recursive convolutional neural network. we show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.	1	467
