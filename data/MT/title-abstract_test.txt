involving language professionals in the evaluation of machine translation	significant breakthroughs in machine translation only seem possible if human translators are taken into the loop. while automatic evaluation and scoring mechanisms such as bleu have enabled the fast development of systems, it is not clear how systems can meet realworld (quality) requirements in industrial translation scenarios today. tara x u project paves the way for wide usage of hybrid machine translation outputs through various feedback loops in system development. in a consortium of research and industry partners, taraxu project integrates human translators into the development process for rating and postediting of machine translation outputs collecting feedback for possible improvements.	1	11
modelling and optimizing on syntactic n-grams for statistical machine translation	the role of language models in smt is to promote fluent translation output, but traditional ngram language models are unable to capture fluency phenomena between distant words, such as some morphological agreement phenomena, subcategorisation, and syntactic collocations with stringlevel gaps. syntactic language models have the potential to fill this modelling gap. we propose a language model for dependency structures that is relational rather than configurational and thus particularly suited for languages with a (relatively) free word order. it is trainable with neural networks, and not only improves over standard ngram language models, but also outperforms related syntactic language models. we empirically demonstrate its effectiveness in terms of perplexity and as a feature function in stringtotree smt from english to german and russian. we also show that using a syntactic evaluation metric to tune the loglinear parameters of an smt system further increases translation quality when coupled with a syntactic language model.	2	9
what’s in a domain? analyzing genre and topic differences in statistical machine translation	reacttext 371 as larger and more diverse parallel texts become available, how can we leverage heterogeneous data to train robust machine translation systems that achieve good translation quality on various test domains? this challenge has been addressed so far by repurposing techniques developed for domain adaptation, such as linear mixture models which combine estimates learned on homogeneous subdomains....  /reacttext  reacttext 372   /reacttext [show full ]	2	9
non-projective dependency-based pre-reordering with recurrent neural network for machine translation	the quality of statistical machine translation performed with phrase based approaches can be increased by permuting the words in the source sentences in an order which resembles that of the target language. we propose a class of recurrent neural models which exploit sourceside dependency syntax features to reorder the words into a targetlike order. we evaluate these models on the germantoenglish and italiantoenglish language pairs, showing significant improvements over a phrasebased moses baseline. we also compare with state of the art germantoenglish prereordering rules, showing that our method obtains similar or better results.	2	9
pushdown automata in statistical machine translation	2014 association for computational linguistics.this article describes the use of pushdown automata (pda) in the context of statistical machine translation and alignment under a synchronous contextfree grammar. we use pdas to compactly represent the space of candidate translations generated by the grammar when applied to an input sentence. generalpurpose pda algorithms for replacement, composition, shortest path, and expansion are presented. we describe hipdt, a hierarchical phrasebased decoder using the pda representation and these algorithms.we contrast the complexity of this decoder with a decoder based on a finite state automata representation, showing that pdas provide a more suitable framework to achieve exact decoding for larger synchronous contextfree grammars and smaller language models. we assess this experimentally on a largescale chinesetoenglish alignment and translation task. in translation, we propose a twopass decoding strategy involving a weaker language model in the firstpass to address the results of pda complexity analysis. we study in depth the experimental conditions and tradeoffs in which hipdt can achieve stateoftheart performance for largescale smt.	1	10
automatic spelling correction for machine translation	methods, systems, and apparatus, including computer program products, for correcting spelling in text. a text input is received for translation. one or more suspect words in the text input are identified. for each suspect word, one or more candidate words are identified. a score for the text input and scores for each of one or more candidate inputs are determined, where each candidate input is the text input with one or more of the suspect words each replaced by a respective candidate word. if any, a candidate input whose score is highest among the scores for the candidate inputs and is greater than the text input score by at least a threshold is selected. otherwise, the text input is selected. a translation of a selected candidate input or the selected text input is provided as the translation of the text input.	1	10
evaluation of machine translation systems at cls corporate language services ag	this paper describes the evaluation of machine translation (mt) system for use in a large company. to take into account the specific requirements of such an environment, a pragmatic approach for the evaluation was developed. it consists of five steps ranging from a specification of the evaluation process to the integration of the chosen mt system in a given infrastructure. the process includes a specification of mt evaluation criteria relevant to systems which have to be employed for a large customer base. the paper also shows the results of such an evaluation study which was recently carried out at cls corporate language services ag, where comprendium is in the meantime being employed as corporate mt system.	1	10
controlling politeness in neural machine translation via side constraints	many languages use honorifics to express politeness, social distance, or the relative social status between the speaker and their addressee(s). in machine translation from a language without honorifics such as english, it is difficult to...	3	6
models and inference for prefix-constrained machine translation	reacttext 435 many phrase alignment models operate over the combinatorial space of bijective phrase alignments. we prove that finding an optimal alignment in this space is nphard, while com puting alignment expectations is #phard. on the other hand, we show that the problem of finding an optimal alignment can be cast as an integer linear program, which provides a simple, declarative approach to viterbi...  /reacttext  reacttext 436   /reacttext [show full ]	3	6
statistical machine translation in the translation curriculum: overcoming obstacles and empowering translators	in this paper we argue that the time is ripe for translator educators to engage with statistical machine translation (smt) in more profound ways than they have done to date. we explain the basic principles of smt and reflect on the role of humans in smt workflows. against a background of diverging opinions on the latter, we argue for a holistic approach to the integration of smt into translator training programmes, one that empowers rather than marginalises translators. we discuss potential barriers to the use of smt by translators generally and in translator training in particular, and propose some solutions to problems thus identified. more specifically, cloudbased services are proposed as a means of overcoming some of the technical and ethical challenges posed by more advanced uses of smt in the classroom. ultimately the paper aims to pave the way for the design and implementation of a new translatororiented smt syllabus at our own university and elsewhere.	1	10
rationalization: a neural machine translation approach to generating natural language explanations	we introduce ai rationalization, an approach for generating explanations of autonomous system behavior as if a human had done the behavior. we describe a rationalization technique that uses neural machine translation to translate internal stateaction representations of the autonomous agent into natural language. we evaluate our technique in the frogger game environment. the natural language is collected from human players thinking out loud as they play the game. we motivate the use of rationalization as an approach to explanation generation, show the results of experiments on the accuracy of our rationalization technique, and describe future research agenda.	4	6
online adaptation to post-edits for phrase-based statistical machine translation	recent research has shown that accuracy and speed of human translators can benefit from postediting output of machine translation systems, with larger benefits for higher quality output.	1	10
incorporating global visual features into attention-based neural machine translation	we introduce multimodal, attentionbased neural machine translation (nmt) models which incorporate visual features into different parts of both the encoder and the decoder. we utilise global image features extracted using a pretrained convolutional neural network and incorporate them (i) as words in the source sentence, (ii) to initialise the encoder hidden state, and (iii) as additional data to initialise the decoder hidden state. in our experiments, we evaluate how these different strategies to incorporate global image features compare and which ones perform best. we also study the impact that adding synthetic multimodal, multilingual data brings and find that the additional data have a positive impact on multimodal models. we report new stateoftheart results and our best models also significantly improve on a comparable phrasebased statistical mt (pbsmt) model trained on the multi30k data set according to all metrics evaluated. to the best of our knowledge, it is the first time a purely neural model significantly improves over a pbsmt model on all metrics evaluated on this data set.	4	6
the new thot toolkit for fully-automatic and interactive statistical machine translation	we present the new thot toolkit for fully automatic and interactive statistical ma chine translation (smt). initial public ver sions of thot date back to 2005 and did only include estimation of phrasebased models. by contrast, the new version of fers several new features that had not been previously incorporated. the key innova tions provided by the toolkit are computer aided translation, including postediting and interactive smt, incremental learn ing and robust generation of alignments at phrase level. in addition to this, the toolkit also provides standard smt fea tures such as fullyautomatic translation, scalable and parallel algorithms for model training, clientserver implementation of the translation functionality, etc. the toolkit can be compiled in unixlike and windows platforms and it is released un der the gnu lesser general public li cense (lgpl).	1	10
bridging neural machine translation and bilingual dictionaries	neural machine translation (nmt) has become the new stateoftheart in several language pairs. however, it remains a challenging problem how to integrate nmt with a bilingual dictionary which mainly contains words rarely or never seen in the bilingual training data. in this paper, we propose two methods to bridge nmt and the bilingual dictionaries. the core idea behind is to design novel models that transform the bilingual dictionaries into adequate sentence pairs, so that nmt can distil latent bilingual mappings from the ample and repetitive phenomena. one method leverages a mixed word/character model and the other attempts at synthesizing parallel sentences guaranteeing massive occurrence of the translation lexicon. extensive experiments demonstrate that the proposed methods can remarkably improve the translation quality, and most of the rare words in the test sentences can obtain correct translations if they are covered by the dictionary.	3	6
compression of neural machine translation models via pruning	neural machine translation (nmt), like many other deep learning domains, typically suffers from overparameterization, resulting in large storage sizes. this paper examines three simple magnitudebased pruning schemes to compress nmt models, namely classblind, classuniform, and classdistribution, which differ in terms of how pruning thresholds are computed for the different classes of weights in the nmt architecture. we demonstrate the efficacy of weight pruning as a compression technique for a stateoftheart nmt system. we show that an nmt model with over 200 million parameters can be pruned by 40% with very little performance loss as measured on the wmt'14 englishgerman translation task. this sheds light on the distribution of redundancy in the nmt architecture. our main result is that with retraining, we can recover and even surpass the original performance with an 80%pruned model.	3	6
memory-enhanced decoder for neural machine translation	we propose to enhance the rnn decoder in a neural machine translator (nmt) with external memory, as a natural but powerful extension to the state in the decoding rnn. this memoryenhanced rnn decoder is called \textsc{memdec}. at each time during decoding, \textsc{memdec} will read from this memory and write to this memory once, both with contentbased addressing. unlike the unbounded memory in previous work\cite{rnnsearch} to store the representation of source sentence, the memory in \textsc{memdec} is a matrix with predetermined size designed to better capture the information important for the decoding process at each time step. our empirical study on chineseenglish translation shows that it can improve by $4.8$ bleu upon groundhog and $5.3$ bleu upon on moses, yielding the best performance achieved with the same training set.	3	6
hume: human ucca-based evaluation of machine translation	human evaluation of machine translation normally uses sentencelevel measures such as relative ranking or adequacy scales. however, these provide no insight into possible errors, and do not scale well with sentence length. we argue for a semanticsbased evaluation, which captures what meaning components are retained in the mt output, thus providing a more finegrained analysis of translation quality, and enabling the construction and tuning of semanticsbased mt. we present a novel human semantic evaluation measure, human uccabased mt evaluation (hume), building on the ucca semantic representation scheme. hume covers a wider range of semantic phenomena than previous methods and does not rely on semantic annotation of the potentially garbled mt output. we experiment with four language pairs, demonstrating hume's broad applicability, and report good interannotator agreement rates and correlation with human adequacy scores.	3	6
toward multilingual neural machine translation with universal encoder and decoder	in this paper, we present our first attempts in building a multilingual neural machine translation framework under a unified approach. we are then able to employ attentionbased nmt for manytomany multilingual translation tasks. our approach does not require any special treatment on the network architecture and it allows us to learn minimal number of free parameters in a standard way of training. our approach has shown its effectiveness in an underresourced translation scenario with considerable improvements up to 2.6 bleu points. in addition, the approach has achieved interesting and promising results when applied in the translation task that there is no direct parallel corpus between source and target languages.	3	6
zero-resource machine translation by multimodal encoder–decoder network with multimedia pivot	we propose an approach to build a neural machine translation system with no supervised resources (i.e., no parallel corpora) using multimodal embedded representation over texts and images. based on the assumption that text documents are often likely to be described with other multimedia information (e.g., images) somewhat related to the content, we try to indirectly estimate the relevance between two languages. using multimedia as the pivot, we project all modalities into one common hidden space where samples belonging to similar semantic concepts should come close to each other, whatever the observed space of each sample is. this modalityagnostic representation is the key to bridging the gap between different modalities. putting a decoder on top of it, our network can flexibly draw the outputs from any input modality. notably, in the testing phase, we need only source language texts as the input for translation. in experiments, we tested our method on two benchmarks to show that it can achieve reasonable translation performance. we compared and investigated several possible implementations and found that an endtoend model that simultaneously optimized both rank loss in multimodal encoders and crossentropy loss in decoders performed the best.	3	6
an evaluation methodology for english to sinhala machine translation	this paper presents evaluation methodology for english to sinhala machine tran slation system. the english to sinhala machine translation system has been developed by using multi agent approach and powered through the concept of “varanegeema”. translation system works through the communication among nine agents namely english morphological analyzer agent, english parser agent, english to sinhala base word translator agent, sinhala morphological generator agent, sinhala parser agent, transliteration agent, intermediate editor agent, message space agent and request agent. the evaluation was conducted through three steps. as the first step, evaluation was conducted through the white box testing approach and tested each module in the machine translation system through the developed testing tools. then, evaluated the system performance and calculated the error rate through the result of the evaluation test bed. finally, intelligibility and the accuracy test will be conducted through the human support. the experimental result shows 89% accuracy of the overall system and 7.2% word error rate and the 5.4% sentence error rate. details of the evaluation and results are given in the paper	3	6
a survey of word reordering in statistical machine translation: computational models and language phenomena	2016. a survey of word reordering in statistical machine translation computational models and language phenomena. computational linguistics, 42.arianna bisazza and marcello federico. 2016. a survey of word reordering in statistical machine ...	3	6
how grammatical is character-level neural machine translation? assessing mt quality with contrastive translation pairs	analysing translation quality in regards to specific linguistic phenomena has historically been difficult and timeconsuming. neural machine translation has the attractive property that it can produce scores for arbitrary translations, and we propose a novel method to assess how well nmt systems model specific linguistic phenomena such as agreement over long distances, the production of novel words, and the faithful translation of polarity. the core idea is that we measure whether a reference translation is more probable under a nmt model than a contrastive translation which introduces a specific type of error. we present lingeval97, a largescale data set of 97000 contrastive translation pairs based on the wmt english>german translation task, with errors automatically created with simple rules. we report results for a number of systems, and find that recently introduced characterlevel nmt systems perform better at transliteration than models with bytepair encoding (bpe) segmentation, but perform more poorly at morphosyntactic agreement, and translating discontiguous units of meaning.	3	6
learning local word reorderings for hierarchical phrase-based statistical machine translation	statistical models for reordering source words have been used to enhance hierarchical phrasebased statistical machine translation. there are existing wordreordering models that learn reorderings for.	3	6
context gates for neural machine translation	in neural machine translation (nmt), generation of a target word depends on both source and target contexts. we find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency. intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. due to the lack of effective control over the influence from source and target contexts, conventional nmt tends to yield fluent but inadequate translations. to address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words. in this way, we can enhance both the adequacy and fluency of nmt with more careful control of the information flow from contexts. experiments show that our approach significantly improves upon a standard attentionbased nmt system by +2.3 bleu points.	4	6
six challenges for neural machine translation	we explore six challenges for neural machine translation domain mismatch, amount of training data, rare words, long sentences, word alignment, and beam search. we show both deficiencies and improvements over the quality of phrasebased statistical machine translation.	4	6
interactive attention for neural machine translation	conventional attentionbased neural machine translation (nmt) conducts dynamic alignment in generating the target sentence. by repeatedly reading the representation of source sentence, which keeps fixed after generated by the encoder (bahdanau et al., 2015), the attention mechanism has greatly enhanced stateoftheart nmt. in this paper, we propose a new attention mechanism, called interactive attention, which models the interaction between the decoder and the representation of source sentence during translation by both reading and writing operations. interactive attention can keep track of the interaction history and therefore improve the translation performance. experiments on nist chineseenglish translation task show that interactive attention can achieve significant improvements over both the previous attentionbased nmt baseline and some stateoftheart variants of attentionbased nmt (i.e., coverage models (tu et al., 2016)). and neural machine translator with our interactive attention can outperform the open source attentionbased nmt system groundhog by 4.22 bleu points and the open source phrasebased system moses by 3.94 bleu points averagely on multiple test sets.	3	6
real time adaptive machine translation for post-editing with cdec and transcenter	as sentences are translated, the models gain valuable context infor mation, allowing them toadapt to the specific tar  on line learning of loglinear weights in interactive ma chine translation online adaptation strategies for statistical machine translation in post editing scenarios	1	9
using syntax-based machine translation to parse english into abstract meaning representation	we present a parser for  meaning representation (amr). we treat englishtoamr conversion within the framework of stringtotree, syntaxbased machine translation (sbmt). to make this work, we transform the amr structure into a form suitable for the mechanics of sbmt and useful for modeling. we introduce an amrspecific language model and add data and features drawn from semantic resources. our resulting amr parser improves upon stateoftheart results by 7 smatch points.	2	8
enhancing statistical machine translation with bilingual terminology in a cat environment	in this paper, we address the problem of extracting and integrating bilingual terminology into a statistical machine translation (smt) system for a computer aided translation (cat) tool scenario. we develop a framework that, taking as input a small amount of parallel indomain data, gathers domainspecific bilingual terms and injects them in an smt system to enhance the translation productivity. therefore, we investigate several strategies to extract and align bilingual terminology, and to embed it into the smt. we compare two embedding methods that can be easily used at runtime without altering the normal activity of an smt system xml markup and the cachebased model. we tested our framework on two different domains showing improvements up to 15% bleu score points.	1	9
a new string-to-dependency machine translation algorithm with a target dependency language model	in this paper, we propose a novel stringto dependency algorithm for statistical machine translation. with this new framework, we em ploy a target dependency language model dur ing decoding to exploit long distance word relations, which are unavailable with a tra ditional ngram language model. our ex periments show that the stringtodependency decoder achieves 1.48 point improvement in bleu and 2.53 point improvement in ter compared to a standard hierarchical stringto string system on the nist 04 chineseenglish evaluation set.	-5	294
better hypothesis testing for statistical machine translation: controlling for optimizer instability	in statistical machine translation, a researcher seeks to determine whether some innovation (e.g., a new feature, model, or inference algorithm) improves translation quality in comparison to a baseline system. to answer this question, he runs an experiment to evaluate the behavior of the two systems on heldout data. in this paper, we consider how to make such experiments more statistically reliable. we provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accurately	-2	223
syntax augmented machine translation via chart parsing	we present translation results on the shared task exploiting parallel texts for statistical machine translation generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories. we use a target language parser to generate parse trees for each sentence on the target side of the bilingual training corpus, matching them with phrase table lattices built for the corresponding source sentence. considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar. we present results on the frenchtoenglish task for this workshop, representing significant improvements over the workshop's baseline system. our translation system is available opensource under the gnu general public license.	-7	301
syntax augmented machine translation via chart parsing	we present translation results on the shared task exploiting parallel texts for statistical machine translation generated by a chart parsing decoder operating on phrase tables augmented and generalized with target language syntactic categories. we use a target language parser to generate parse trees for each sentence on the target side of the bilingual training corpus, matching them with phrase table lattices built for the corresponding source sentence. considering phrases that correspond to syntactic categories in the parse trees we develop techniques to augment (declare a syntactically motivated category for a phrase pair) and generalize (form mixed terminal and nonterminal phrases) the phrase table into a synchronous bilingual grammar. we present results on the frenchtoenglish task for this workshop, representing significant improvements over the workshop's baseline system. our translation system is available opensource under the gnu general public license.	-7	298
the mathematics of machine translation: parameter estimation	this paper, we focus on the translation modeling problem. before we turn to this problem, however, we should address an issue that may be a concern to some readers why do we estimate pr(e) and pr(fle) rather than estimate pr(elf ) directly? we are really interested in this latter probability. wouldn't we reduce our problems from three to two by this direct approach? if we can estimate pr(fle) adequately, why can't we just turn the whole process around to estimate pr(elf)? to understand this, imagine that we divide french and english strings into those that are wellformed and those that are illformed. this is not a precise notion. we have in mind that strings like il va la bibliothque, or i live in a house, or even colorless green ideas sleep furiously are wellformed, but that strings like lava i1 bibliothque or a i in live house are not. when we translate a french string into english, we can think of ourselves as springing from a wellformed french string into the sea of wellformed english strings with the hope of landing on a good one. it is important, therefore, that our model for pr(elf ) concentrate its probability as much as possible on wellformed english strings. but it is not important that our model for pr(fle ) concentrate its probability on wellformed french strings.	-20	392
improved statistical machine translation using paraphrases	parallel corpora are crucial for training smt systems. however, for many lan guage pairs they are available only in very limited quantities. for these lan guage pairs a huge portion of phrases en countered at runtime will be unknown. we show how techniques from paraphras ing can be used to deal with these oth erwise unknown source language phrases. our results show that augmenting a state oftheart smt system with paraphrases leads to significantly improved coverage and translation quality. for a training corpus with 10,000 sentence pairs we in crease the coverage of unique test set un igrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.	-7	301
learning non-isomorphic tree mappings for machine translation	often one may wish to learn a treetotree mapping, training it on unaligned pairs of trees, or on a mixture of trees and strings. unlike previous statistical formalisms (limited to isomorphic trees), allows local distortion of the tree topology. we reformulate it to permit dependency trees, and sketch em/viterbi algorithms for alignment, training, and decoding.	-10	337
word sense disambiguation improves statistical machine translation	recent research presents conflicting evidence on whether word sense disambiguation (wsd) systems can help to improve the performance of statistical machine translation (mt) systems. in this paper, we successfully integrate a stateoftheart wsd system into a stateoftheart hierarchical phrasebased mt system, hiero. we show for the first time that integrating a wsd system improves the performance of a stateoftheart statistical mt system on an actual translation task. furthermore, the improvement is statistically significant. 漏 2007 association for computational linguistics.	-6	288
optimizing chinese word segmentation for machine translation performance	previous work has shown that chinese word segmentation is useful for machine translation to english, yet the way different segmentation strategies affect mt is still poorly understood. in this paper, we demonstrate that optimizing segmentation for an existing segmentation standard does not always yield better mt performance. we find that other factors such as segmentation consistency and granularity of chinese words can be more important for machine translation. based on these findings, we implement methods inside a conditional random field segmenter that directly optimize segmentation granularity with respect to the mt task, providing an improvement of 0.73 bleu. we also show that improving segmentation consistency using external lexicon and proper noun features yields a 0.32 bleu increase. 1	-5	264
experiments in domain adaptation for statistical machine translation	the special challenge of the wmt 2007 shared task was domain adaptation. we took this opportunity to experiment with various ways of adapting a statistical machine translation systems to a special domain (here news commentary), when most of the training data is from a different domain (here european parliament speeches). this paper also gives a description of the submission of the university of edinburgh to the shared task.	-6	282
automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics.	in this paper we describe two new objective automatic evaluation methods for machine translation. the first method is based on long est common subsequence between a candidate translation and a set of reference translations. longest common subsequence takes into ac count sentence level structure similarity natu rally and identifies longest cooccurring in sequence ngrams automatically. the second method relaxes strict ngram matching to skip bigram matching. skipbigram is any pair of words in their sentence order. skipbigram co occurrence statistics measure the overlap of skipbigrams between a candidate translation and a set of reference translations. the empiri cal results show that both methods correlate with human judgments very well in both ade quacy and fluency.	-9	332
better hypothesis testing for statistical machine translation: controlling for optimizer instability	in statistical machine translation, a researcher seeks to determine whether some innovation (e.g., a new feature, model, or inference algorithm) improves translation quality in comparison to a baseline system. to answer this question, he runs an experiment to evaluate the behavior of the two systems on heldout data. in this paper, we consider how to make such experiments more statistically reliable. we provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accurately	-2	212
statistical machine translation by parsing	designers of statistical machine translation (smt) systems have begun trying to exploit treestructured syntactic information. this article offers a coherent algorithmic framework to facilitate such efforts. our main contribution is a generalization of the common notion of parsing. in an ordinary parser, the input is a single string, and the grammar ranges over strings. in order to use syntactic information, an smt system requires generalizations of ordinary parsing algorithms that allow the input to consist of string tuples and/or the grammar to range over string tuples. three particular generalizations, connected by some trivial glue, are all that is necessary for syntaxaware smt a synchronous parser is an algorithm that can infer the syntactic structure of each component text in a multitext and simultaneously infer the orrespondence relation between these structures. when a parser's input can have fewer dimensions than the parser's grammar, it is a translator. when a parser's grammar can have fewer dimensions than the parser's input, it is a synchronizer. this article offers a guided tour of these generalized parsing algorithms. it culminates with a recipe for using generalized parsing algorithms to train and apply a syntaxaware smt system.	-9	183
discriminative reranking for machine translation	this paper describes the application of discriminative reranking techniques to the problem of machine translation. for each sentence in the source language, we obtain from a baseline statistical machine translation system, a ranked n best list of candidate translations in the target language. we introduce two novel perceptroninspired reranking algorithms that improve on the quality of machine translation over the baseline system based on evaluation using the bleu metric. we provide experimental results on the nist 2003 chineseenglish large data track evaluation. we also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide stateoftheart performance in machine translation.	-9	183
synchronous binarization for machine translation	systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine transla tion output, but are often very computa tionally intensive.	-7	169
word-sense disambiguation for machine translation	in word sense disambiguation, a system attempts to determine the sense of a word from contextual fea tures. major barriers to building a highperforming word sense disambiguation system include the dif ficulty of labeling data for this task and of pre dicting finegrained sense distinctions. these is sues stem partly from the fact that the task is be ing treated in isolation from possible uses of au tomatically disambiguated data. in this paper, we consider the related task of word translation, where we wish to determine the correct translation of a word from context. we can use parallel language corpora as a large supply of partially labeled data for this task. we present algorithms for solving the word translation problem and demonstrate a signif icant improvement over a baseline system. we then show that the wordtranslation system can be used to improve performance on a simplified machine translation task and can effectively and accurately prune the set of candidate translations for a word.	-8	169
machine translation and telecommunications system using user id data to select dictionaries	a machine translation and telecommunications system includes a machine translation engine for translation of input text from a source language to a target language, a dictionary database including a core dictionary and a plurality of sublanguage (domain) dictionaries usable for translation from a source to a target language, a receiving interface for receiving text input from any of a plurality of users, each text input being accompanied by control information including user id data indicative of one or more sublanguages preferred by a particular user, an output interface, and a dictionary control module coupled to the receiving interface responsive to the user id data indicative of a sublanguage preference of a particular user for selecting a corresponding sublanguage dictionary of the dictionary database to be used by the machine translation engine along with the core dictionary for performing translation of the particular user's text input. user dictionaries can be maintained and selected to enhance translation accuracy in the same manner. the dictionary database encompassing core, sublanguage (domain), and user dictionaries is cumulated for greater capability over time through the use of dictionary maintenance utilities for updating the dictionaries.	-17	214
active learning and crowd-sourcing for machine translation.	in recent years, corpus based approaches to machine translation have become predominant, with statistical machine translation (smt) being the most actively progressing area. success of these approaches depends on the availability of parallel corpora. in this paper we propose active crowd translation (act), a new paradigm where active learning and crowdsourcing come together to enable automatic translation for lowresource language pairs. active learning aims at reducing cost of label acquisition by prioritizing the most informative data for annotation, while crowdsourcing reduces cost by using the power of the crowds to make do for the lack of expensive language experts. we experiment and compare our active learning strategies with strong baselines and see significant improvements in translation quality. similarly, our experiments with crowdsourcing on mechanical turk have shown that it is possible to create parallel corpora using nonexperts and with sufficient quality assurance, a translation system that is trained using this corpus approaches expert quality.	-3	133
hmm word and phrase alignment for statistical machine translation	estimation and alignment procedures for word and phrase alignment hidden markov models (hmms) are developed for the alignment of parallel text. the development of these models is motivated by an analysis of the desirable features of ibm model 4, one of the original and most effective models for word alignment. these models are formulated to capture the desirable aspects of model 4 in an hmm alignment formalism. alignment behavior is analyzed and compared to humangenerated reference alignments, and the ability of these models to capture different types of alignment phenomena is evaluated. in analyzing alignment performance, chineseenglish word alignments are shown to be comparable to those of ibm model 4 even when models are trained over large parallel texts. in translation performance, phrasebased statistical machine translation systems based on these hmm alignments can equal and exceed systems based on model 4 alignments, and this is shown in arabicenglish and chineseenglish translation. these alignment models can also be used to generate posterior statistics over collections of parallel text, and this is used to refine and extend phrase translation tables with a resulting improvement in translation quality.	-5	154
large-scale dictionary construction for foreign language tutoring and interlingual machine translation	this paper describes techniques for automatic construction of dictionaries for use in largescale foreign language tutoring (flt) and interlingual machine translation (mt) systems. the dictionaries are based on a languageindependent representation called “lexical conceptual structure” (lcs). a primary goal of the lcs research is to demonstrate that synonymous verb senses share distributional patterns. we show how the syntax–semantics relation can be used to develop a lexical acquisition approach that contributes both toward the enrichment of existing online resources and toward the development of lexicons containing more complete information than is provided in any of these resources alone. we start by describing the structure of the lcs and showing how this representation is used in flt and mt. we then focus on the problem of building lcs dictionaries for largescale flt and mt. first, we describe authoring tools for manual and semiautomatic construction of lcs dictionaries; we then present a more sophisticated approach that uses linguistic techniques for building word definitions automatically. these techniques have been implemented as part of a set of lexicondevelopment tools used in the milt flt project.	-16	202
machine translation: an introductory guide	the article provides insights for dental hygienists on using machine translation (mt). tips on using mt are enumerated, one of which is avoiding complex sentence to avoid confusing translation software. the methods through which mt operates include those based on dictionary entries and based statistical rules. also cited are popular and free mt sites such as yahoo! babel fish at http//translation2.paralink.com/ and http//www.systranet.com.	-19	315
machine translation and telecommunications system	a machine translation and telecommunications system automatically translates input text in a source language to output text in a target language using a dictionary database (22) containing core language dictionaries for general words, a plurality of sublanguage dictionaries for specialized words of different domains or user groups, and a plurality of user dictionaries for individualized words used by different users. the system includes a receiving interface (11) for receiving input from a sender, in the form of electronic text, facsimile (graphics) input, or page image data, and an output module (30) for sending translated output text to any designated recipient(s). the input text is accompanied by a cover page or header (50) identifying the sender, one or more recipients, their addresses, the source/target languages of the text, any sublanguage(s) applicable to the input text, and any formatting requirements for the output text. the system uses the cover page or header data to select the core language, sublanguage, and/or user dictionaries to be used for translation processing, to format the translated output text, and to send the output to the recipient(s) at the designated address(es).	-17	309
statistical machine translation for query expansion in answer retrieval	we present an approach to query expan sion in answer retrieval that uses statisti cal machine translation (smt) techniques to bridge the lexical gap between ques tions and answers. smtbased query ex pansion is done by i) using a fullsentence paraphraser to introduce synonyms in con text of the entire query, and ii) by trans lating query terms into answer terms us ing a fullsentence smt model trained on questionanswer pairs. we evaluate these global, contextaware query expansion tech niques on tfidf retrieval from 10 million questionanswer pairs extracted from faq pages. experimental results show that smt based expansion improves retrieval perfor mance over local expansion and over re trieval without expansion.	-5	235
loosely tree-based alignment for machine translation	we augment a model of translation based on reordering nodes in syntactic trees in order to allow alignments not conforming to the original tree structure, while keeping computational complexity polynomial in the sentence length. this is done by adding a new subtree cloning operation to either treetostring or treetotree alignment algorithms.	-10	279
chinese syntactic reordering for statistical machine translation	syntactic reordering approaches are an ef fective method for handling wordorder dif ferences between source and target lan guages in statistical machine translation (smt) systems. this paper introduces a re ordering approach for translation from chi nese to english. we describe a set of syntac tic reordering rules that exploit systematic differences between chinese and english word order. the resulting system is used as a preprocessor for both training and test sentences, transforming chinese sentences to be much closer to english in terms of their word order. we evaluated the reordering approach within the moses phrasebased smt system (koehn et al., 2007). the reordering approach improved the bleu score for the moses system from 28.52 to 30.86 on the nist 2006 evaluation data. we also conducted a series of experiments to an alyze the accuracy and impact of different types of reordering rules.	-6	241
manual and automatic evaluation of machine translation between european languages	we evaluated machine translation performance for six european language pairs that participated in a shared task translating french, german, spanish texts to english and back. evaluation was done automatically using the bleu score and manually on fluency and adequacy.	-7	246
a comparison of alignment models for statistical machine translation	in this paper, we present and compare various alignment models for statistical machine translation. we propose to measure the quality of an alignment model using the quality of the viterbi alignment compared to a manuallyproduced alignment and describe a rened annotation scheme to produce suitable reference alignments. the presented alignment models are then compared according to this error criterion. we also compare the impact of dierent alignment models on the translation quality of the alignment template system. 1 introduction in statistical machine translation (smt) it is necessary to model the translation probability p r(f j 1 je i 1 ). here f j 1 = f denotes the (french) source and e i 1 = e denotes the (english) target string. most smt models (brown et al., 1993; vogel et al., 1996) try to model wordtoword correspondences between source and target words using an alignment mapping from source position j to target position i = a j . formally, we can rewrite the pro...	-13	306
phrase-based joint probability model for statistical machine translation	a machine translation (mt) system utilizes a phrasebased joint probability model. the model is used to generate source and target language sentences simultaneously. in an embodiment, the model learns phrasetophrase alignments from wordtoword alignments generated by a wordtoword statistical mt system. the system utilizes the joint probability model for both sourcetotarget and targettosource translation applications.	-2	175
re-examining machine translation metrics for paraphrase identification	we propose to reexamine the hypothesis that automated metrics developed for mt evaluation can prove useful for paraphrase identification in light of the significant work on the development of new mt metrics over the last 4 years. we show that a metaclassifier trained using nothing but recent mt metrics outperforms all previous paraphrase identification approaches on the microsoft research paraphrase corpus. in addition, we apply our system to a second corpus developed for the task of plagiarism detection and obtain extremely positive results. finally, we conduct extensive error analysis and uncover the top systematic sources of error for a paraphrase identification approach relying solely on mt metrics. we release both the new dataset and the error analysis annotations for use by the community.	-1	91
recent advances in example-based machine translation	book review recent advances in examplebased machine translation michael carl and andy way (editors) (universitat des saarlandes and dublin city university) dordrecht  kluwer academic publishers (text, speech and language technology series, edited by nancy ide and jean veronis, volume 21), 2003 , xxxi+482 pp; hardbound, isbn 1402014007 , $173.00, f115.00, 180.00	-9	158
deeper sentiment analysis using machine translation technology	this paper proposes a new paradigm for sentiment analysis translation from text documents to a set of sentiment units. the techniques of deep language analysis for machine translation are applicable also to this kind of text mining task. we developed a highprecision sentiment analysis system at a low development cost, by making use of an existing transferbased machine translation engine.	-9	158
following directions using statistical machine translation	mobile robots that interact with humans in an intuitive way must be able to follow directions provided by humans in unconstrained natural language. in this work we investigate how statistical machine translation techniques can be used to bridge the gap between natural language route instructions and a map of an environment built by a robot. our approach uses training data to learn to translate from natural language instructions to an automaticallylabeled map. the complexity of the translation process is controlled by taking advantage of physical constraints imposed by the map. as a result, our technique can efficiently handle uncertainty in both map labeling and parsing. our experiments demonstrate the promising capabilities achieved by our approach.	-3	108
generation of word graphs in statistical machine translation	statistical machine translation systems usually compute the single sentence that has the highest probability according to the models that are trained on data. we describe a method for constructing a word graph to represent alternative hypotheses in an efficient way. the advantage is that these hypotheses can be rescored using a refined language or translation model.	-11	164
active learning and crowdsourcing for machine translation in low resource scenarios	corpus based approaches to automatic translation such as example based and statistical machine translation systems use large amounts of parallel data created by humans to train mathematical models for automatic language translation. large scale parallel data generation for new language pairs requires intensive human effort and availability of fluent bilinguals or expert translators. therefore it becomes immensely difficult and expensive to provide stateoftheart machine translation (mt) systems for rare languages.	-1	98
a comparative study on reordering constraints in statistical machine translation	in statistical machine translation, the generation of a translation hypothesis is computationally expensive. if arbitrary wordreorderings are permitted, the search problem is nphard. on the other hand, if we restrict the possible wordreorderings in an appropriate way, we obtain a polynomialtime search algorithm.in this paper, we compare two different reordering constraints, namely the itg constraints and the ibm constraints. this comparison includes a theoretical discussion on the permitted number of reorderings for each of these constraints. we show a connection between the itg constraints and the since 1870 known schröder numbers.we evaluate these constraints on two tasks the verbmobil task and the canadian hansards task. the evaluation consists of two parts first, we check how many of the viterbi alignments of the training corpus satisfy each of these constraints. second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.the experiments will show that the baseline itg constraints are not sufficient on the canadian hansards task. therefore, we present an extension to the itg constraints. these extended itg constraints increase the alignment coverage from about 87% to 96%.	-10	157